\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\citation{rp}
\citation{VasishthGelman2019}
\@writefile{toc}{\contentsline {schapter}{{List of illustrations}}{vii}{chapter*.2}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{Sturt2003}
\citation{CunningsFelser2013}
\@writefile{toc}{\contentsline {schapter}{List of tables}{xv}{chapter*.3}\protected@file@percent }
\@input{c00acksccp.aux}
\@input{c00forewordsccp.aux}
\@input{c00prefacesccp.aux}
\citation{LewisVasishth2005,EngelmannJaegerVasishth2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c00}{{1}{1}{Introduction}{chapter.1}{}}
\citation{Frazier1987}
\citation{PickeringVanGompel2006}
\citation{traxler2014trends}
\citation{MillerChomsky63}
\citation{MillerChomsky63}
\citation{MillerChomsky63}
\citation{yngve}
\citation{frazier85}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Working memory in theories of sentence comprehension}{2}{section.1.1}\protected@file@percent }
\newlabel{ungramCE}{{1}{2}{Working memory in theories of sentence comprehension}{Item.1}{}}
\citation{gibsonthomas97}
\citation{VasishthSuckowLewis2010}
\citation{VasishthSuckowLewis2010}
\citation{FrankTrompenaarsVasishth2015}
\citation{bader2016complex}
\citation{VasishthSuckowLewis2010}
\citation{FrankTrompenaarsVasishth2015}
\citation{levyfedgibsonRussian,levy2012processing,LevyKeller2013,VasishthMertzenJaegerGelman2018,linzenuncertainty}
\citation{SafaviEtAlFrontiers2016}
\citation{HusainEtAl2014}
\citation{Frazier79}
\citation{Frazier79}
\newlabel{ambiguity}{{2}{4}{Working memory in theories of sentence comprehension}{Item.4}{}}
\newlabel{ambiguitythat}{{3}{4}{Working memory in theories of sentence comprehension}{Item.5}{}}
\newlabel{ambiguity2}{{4}{4}{Working memory in theories of sentence comprehension}{Item.6}{}}
\citation{SwetsDesmetClifton2008}
\citation{FrazierRayner1982}
\citation{TraxlerPickeringClifton1998}
\citation{MalsburgVasishth2013}
\citation{Traxler2007}
\newlabel{swets}{{5}{5}{Working memory in theories of sentence comprehension}{Item.7}{}}
\citation{Gibson1998}
\citation{Gibson2000}
\citation{gibsonthomas97}
\citation{HusainVasishthNarayanan2015}
\citation{Jurafsky1996,Hale2001,Levy2008}
\citation{BostonHaleVasishth2011}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Prediction in sentence processing}{6}{section.1.2}\protected@file@percent }
\citation{MacDonaldChristiansen2002}
\citation{JustCarpenter1992}
\citation{DanemanCarpenter1980}
\citation{wellsetal}
\citation{brown,petersonpeterson,keppelunderwood,waughnorman}
\citation{lewis:magical,lewis:phd,Gibson2000,JustCarpenter1992}
\citation{philip92leftcorner}
\citation{Jurafsky1996}
\citation{Levy2008}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Working memory and prediction}{7}{section.1.3}\protected@file@percent }
\citation{FrazierRayner1982,TraxlerPickeringClifton1998,SwetsDesmetClifton2008,taboretal04}
\citation{Hale2001,Levy2008}
\citation{Gibson1998,Gibson2000,SafaviEtAlFrontiers2016,HusainEtAl2014,HusainVasishthNarayanan2015}
\citation{MacDonaldChristiansen2002,wellsetal}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Current beliefs about constraints on sentence comprehension}{8}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Some gaps in the sentence processing literature}{8}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}The relative scarcity of computationally implemented models}{8}{subsection.1.5.1}\protected@file@percent }
\citation{MacDonaldChristiansen2002,Frank2009,EngelmannVasishth2009,rabovsky2014simulating,linzen2018distinct}
\citation{McRaeSpiveyKnowltonTanenhaus1998}
\citation{Hale2001,Levy2008,rasmussen2017left}
\citation{vossekempen2000,taboretal04,cho2017incremental,SmithFranckTaborCogSci2018}
\citation{LogacevVasishthQJEP2016}
\citation{hammerly2019grammaticality,parker2019cue}
\citation{Gibson2000}
\citation{warrengibson05}
\citation{Gibson1998}
\citation{Gibson2000}
\citation{Gibson1998}
\citation{gibsonwu}
\citation{HsiaoGibson2003}
\citation{whymodel}
\citation{smaldino2017models}
\citation{laird2012soar}
\citation{AndersonEtAl2004}
\citation{Reichle2003,ReichleWarrenMcConnell2009}
\citation{EngbertNuthmannRichter2005,richteretal06,Rabe2019}
\citation{OberauerKliegl2006,LewandowskyGeigerOberauer2008}
\citation{justetal99,just2007organization,varma2016caps}
\citation{lee2014bayesian,busemeyer2010cognitive,lewiscogmodsym,farrell2018computational}
\citation{JustCarpenter1992,just2002haw}
\citation{kidd2018individual}
\citation{norm}
\citation{JustCarpenter1992,van2014low,MacDonaldChristiansen2002}
\citation{FrazierRayner1982}
\citation{VasishthMertzenJaegerGelman2018}
\citation{JaegerEngelmannVasishth2017,MertzenEtAlAMLaP2019,JaegerMertzenVanDykeVasishth2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}A focus on average behaviour and neglect of individual-level differences}{11}{subsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}The absence of high-precision studies}{11}{subsection.1.5.3}\protected@file@percent }
\citation{rp}
\citation{rp}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}Unclear desiderata for a good model fit}{12}{subsection.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Roberts and Pashler (2000) criteria}{12}{section*.7}\protected@file@percent }
\citation{rp}
\citation{rp}
\citation{rp}
\citation{pvals}
\citation{GelmanCarlin2014}
\citation{LevyKeller2013}
\citation{Hale2001,Levy2008}
\citation{VasishthMertzenJaegerGelman2018}
\@writefile{toc}{\contentsline {subsubsection}{Why is high uncertainty undesirable in the estimate from the data?}{13}{section*.8}\protected@file@percent }
\newlabel{typem}{{1.5.4}{13}{Why is high uncertainty undesirable in the estimate from the data?}{section*.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A schematic summary of the \cite  {rp} discussion regarding what constitutes a good fit of a model to data. The data are represented by the circle (the estimated mean) and the vertical uncertainty interval, and the model predictions by the diagonal parallel lines. If a model predicts a positive correlation between two variables $x$ and $y$, strong support for the model can only be argued for if both the data and the model predictions are highly constrained: the model must make predictions over a narrow range, and the data must have low uncertainty associated with it.}}{14}{figure.1.1}\protected@file@percent }
\newlabel{fig:rp}{{1.1}{14}{A schematic summary of the \cite {rp} discussion regarding what constitutes a good fit of a model to data. The data are represented by the circle (the estimated mean) and the vertical uncertainty interval, and the model predictions by the diagonal parallel lines. If a model predicts a positive correlation between two variables $x$ and $y$, strong support for the model can only be argued for if both the data and the model predictions are highly constrained: the model must make predictions over a narrow range, and the data must have low uncertainty associated with it}{figure.1.1}{}}
\citation{hoenigheisey}
\citation{stack2018failure}
\citation{cohen1962statistical}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A demonstration of Type M and S error. Low power studies will yield overestimates and/or incorrect signs whenever a result is significant.}}{15}{figure.1.2}\protected@file@percent }
\newlabel{fig:typemdemo}{{1.2}{15}{A demonstration of Type M and S error. Low power studies will yield overestimates and/or incorrect signs whenever a result is significant}{figure.1.2}{}}
\citation{VasishthGelman2019}
\citation{Freedman1984,spiegelhalter1994bayesian}
\citation{kruschke2014doing}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{VasishthGelman2019}
\citation{VasishthGelman2019}
\@writefile{toc}{\contentsline {subsubsection}{The Freedman-Spiegelhalter approach}{16}{section*.9}\protected@file@percent }
\citation{NicenboimVasishthStatMeth,NicenboimEtAlBayes2019}
\citation{LewisVasishth2005}
\citation{AndersonEtAl2004}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces The five possible outcomes when using the null region or  ``region of practical equivalence'' method for decision-making (Kruschke, 2015). Outcomes A and B are inconsistent with the quantitative predictions of the theory; C and D are inconclusive; and E is consistent with the quantitative theoretical prediction. Figure reproduced from \cite  {VasishthGelman2019}.}}{17}{figure.1.3}\protected@file@percent }
\newlabel{fig:rope}{{1.3}{17}{The five possible outcomes when using the null region or \index {region of practical equivalence} ``region of practical equivalence'' method for decision-making (Kruschke, 2015). Outcomes A and B are inconsistent with the quantitative predictions of the theory; C and D are inconclusive; and E is consistent with the quantitative theoretical prediction. Figure reproduced from \cite {VasishthGelman2019}}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}The goals of this book}{17}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Providing open source model code}{18}{subsection.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}Modelling average effects as well as individual differences}{18}{subsection.1.6.2}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{SmithFranckTaborCogSci2018,rasmussen2017left,cho2017incremental,parker2019cue}
\citation{bdactrbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.3}Developing a set of modelling and empirical benchmarks for future model comparison}{19}{subsection.1.6.3}\protected@file@percent }
\citation{PatilEtAl2016}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Looking ahead}{21}{section.1.7}\protected@file@percent }
\citation{anderson1974retrieval}
\citation{Dillon2011}
\citation{Nairne1988,gibsonetal96}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Dependencies in sentence comprehension}{22}{chapter.2}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c01}{{2}{22}{Dependencies in sentence comprehension}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Memory processes in sentence comprehension}{22}{section.2.1}\protected@file@percent }
\citation{WatkinsWatkins1975,keppelunderwood,lewis:magical}
\citation{patson2016misinterpretations}
\citation{VasishthLewis2006}
\citation{hofmeister07,hofmeister2011representational,HofmeisterVasishth2014}
\citation{Nairne1990,OberauerKliegl2006,VasishthEtAlICCM2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A schematic illustration of the fan effect. Searching for an object that is gray and a square (the target item) is more difficult when competing items have one or more features matching cues used for identifying the target item.}}{23}{figure.2.1}\protected@file@percent }
\newlabel{fig:faneffect}{{2.1}{23}{A schematic illustration of the fan effect. Searching for an object that is gray and a square (the target item) is more difficult when competing items have one or more features matching cues used for identifying the target item}{figure.2.1}{}}
\citation{McElreeForakerDyer2003}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Dependency completion in sentence processing}{24}{section.2.2}\protected@file@percent }
\citation{lewis:magical}
\citation{lewis:magical}
\citation{VanDykeMcElree2011}
\citation{WagersLauPhillips2009}
\newlabel{ex:proretrovandyke2011}{{8}{25}{Dependency completion in sentence processing}{Item.29}{}}
\newlabel{ex:proretroagrmt}{{9}{26}{Dependency completion in sentence processing}{Item.34}{}}
\citation{vandykemcelree06}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Subject-verb non-agreement dependencies}{27}{section.2.3}\protected@file@percent }
\newlabel{vd06}{{10}{27}{Subject-verb non-agreement dependencies}{Item.42}{}}
\citation{van2014low}
\citation{van2014low}
\citation{MertzenEtAlAMLaP2019}
\citation{MertzenEtAlAMLaP2019}
\citation{VanDyke2007}
\newlabel{vd07a}{{11}{28}{Subject-verb non-agreement dependencies}{Item.45}{}}
\newlabel{vd07b}{{12}{28}{Subject-verb non-agreement dependencies}{Item.48}{}}
\citation{VanDykeMcElree2011}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{AndersonEtAl2004}
\citation{raab1962division}
\citation{LogacevMultiple,NicenboimRetrieval2018}
\citation{CunningsSturt2018}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Inhibitory interference effects (sorted in increasing order by magnitude) in reading studies by Van Dyke and colleagues. The gray vertical lines show the 95\% credible interval for the meta-analysis estimate of the effect.}}{30}{figure.2.2}\protected@file@percent }
\newlabel{fig:jvddataplot}{{2.2}{30}{Inhibitory interference effects (sorted in increasing order by magnitude) in reading studies by Van Dyke and colleagues. The gray vertical lines show the 95\% credible interval for the meta-analysis estimate of the effect}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Distribution of power (paired, two-sided t-test) assuming that the effect has normal distribution with mean 13 and standard deviation 6, the standard deviation ranges from 75 to 100 ms, and subject sample size is 60.}}{31}{figure.2.3}\protected@file@percent }
\newlabel{fig:powerdistrnvandyke}{{2.3}{31}{Distribution of power (paired, two-sided t-test) assuming that the effect has normal distribution with mean 13 and standard deviation 6, the standard deviation ranges from 75 to 100 ms, and subject sample size is 60}{figure.2.3}{}}
\newlabel{ex:cunningssturtjml2017}{{13}{31}{Subject-verb non-agreement dependencies}{Item.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Visualization of two conditions in the Cunnings and Sturt (2018) experiment, and the predictions of the cue-based retrieval model. The verb \textit  {shattered} attempts to retrieve an item in memory that is a direct object and has the property ``is shatterable''. In both the (a) and (b) conditions shown, the direct object (which is the target noun that should be retrieved) matches the direct object retrieval cue. However, in (b) the distractor noun matches the ``is shatterable'' cue. As a consequence, in (b), both the target and distractor nouns enter into a race, and whichever item is non-deterministically retrieved is the winner of the race. This race process leads to a faster reading time at the verb \textit  {shattered} in (b) vs.\ (a).}}{32}{figure.2.4}\protected@file@percent }
\newlabel{fig:cunningssturt}{{2.4}{32}{Visualization of two conditions in the Cunnings and Sturt (2018) experiment, and the predictions of the cue-based retrieval model. The verb \textit {shattered} attempts to retrieve an item in memory that is a direct object and has the property ``is shatterable''. In both the (a) and (b) conditions shown, the direct object (which is the target noun that should be retrieved) matches the direct object retrieval cue. However, in (b) the distractor noun matches the ``is shatterable'' cue. As a consequence, in (b), both the target and distractor nouns enter into a race, and whichever item is non-deterministically retrieved is the winner of the race. This race process leads to a faster reading time at the verb \textit {shattered} in (b) vs.\ (a)}{figure.2.4}{}}
\citation{WagersLauPhillips2009}
\citation{SanfordSturt2002,FerreiraFerraroBailey2002}
\citation{Nairne1990}
\citation{VillataFranck}
\citation{Nairne1990}
\citation{VasishthEtAlICCM2017}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Subject-verb number agreement}{33}{section.2.4}\protected@file@percent }
\newlabel{example1}{{14a}{33}{Subject-verb number agreement}{Item.55}{}}
\newlabel{example2}{{14b}{33}{Subject-verb number agreement}{Item.56}{}}
\citation{EberhardCuttingBock2005}
\citation{hammerly2019grammaticality}
\citation{Ratcliff1978}
\citation{ALV2020}
\citation{PaapeEtAlMPT2020}
\citation{CunningsSturt2018}
\citation{TuckerIdrissiAlmeida2015}
\citation{ALV2020}
\citation{ALV2020}
\citation{WagersLauPhillips2009}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Subject-verb number agreement effects in ungrammatical sentences (reading studies). Shown are the means (sorted by increasing magnitude of the effect) and 95\% confidence intervals that were either computed from publicly available data, or derived from published estimates.}}{35}{figure.2.5}\protected@file@percent }
\newlabel{fig:agrmtattrnc01}{{2.5}{35}{Subject-verb number agreement effects in ungrammatical sentences (reading studies). Shown are the means (sorted by increasing magnitude of the effect) and 95\% confidence intervals that were either computed from publicly available data, or derived from published estimates}{figure.2.5}{}}
\citation{lago2015agreement}
\citation{Gibson2000,grodner,Bartek2011}
\newlabel{example2gr}{{15a}{36}{Subject-verb number agreement}{Item.58}{}}
\newlabel{example1gr}{{15b}{36}{Subject-verb number agreement}{Item.59}{}}
\citation{nicenboimexploratory}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The role of case marking in agreement attraction configurations. The figure is re-used here under a CC-BY4.0 license and is available from https://doi.org/10.6084/m9.figshare.11440854.v1.}}{37}{figure.2.6}\protected@file@percent }
\newlabel{fig:serinecase}{{2.6}{37}{The role of case marking in agreement attraction configurations. The figure is re-used here under a CC-BY4.0 license and is available from https://doi.org/10.6084/m9.figshare.11440854.v1}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Target match number agreement effects in reading studies.}}{38}{figure.2.7}\protected@file@percent }
\newlabel{fig:matchnumagrmt}{{2.7}{38}{Target match number agreement effects in reading studies}{figure.2.7}{}}
\newlabel{ex:brunoexp1}{{16}{38}{Subject-verb number agreement}{Item.60}{}}
\citation{Sturt2003}
\citation{chomsky1981lectures}
\newlabel{ex:brunoHI}{{16a}{39}{Subject-verb number agreement}{Item.61}{}}
\newlabel{ex:brunoLI}{{16b}{39}{Subject-verb number agreement}{Item.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Reflexives and reciprocals}{39}{section.2.5}\protected@file@percent }
\citation{VanDyke2007}
\citation{MertzenEtAlAMLaP2019}
\newlabel{reflpro}{{17a}{40}{Reflexives and reciprocals}{Item.64}{}}
\newlabel{reflretro}{{17b}{40}{Reflexives and reciprocals}{Item.65}{}}
\citation{DillonMishlerSloggett2013}
\newlabel{dillon13agrmt}{{18}{41}{Reflexives and reciprocals}{Item.66}{}}
\newlabel{dillon13refl}{{19}{41}{Reflexives and reciprocals}{Item.71}{}}
\citation{SchadEtAlcontrasts}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{LewisVasishth2005}
\citation{DillonMishlerSloggett2013}
\citation{CunningsSturt2018}
\citation{Sturt2003}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Nested contrast coding to investigate the effect of intrusion in grammatical and ungrammatical agreement and reflexive constructions. The contrast dep is the main effect of dependency type (agreement or reflexive). The abbreviation intr.au means intrusion (interference effect) in agreement dependencies, ungrammatical; intr.ag stands for intrusion (interference effect) in agreement dependencies, grammatical; intr.ru refers to intrusion (interference effect) in reflexive dependencies, ungrammatical; intr.rg stands for intrusion (interference effect) in reflexive dependencies, grammatical.}}{42}{table.2.1}\protected@file@percent }
\newlabel{dillon13nestedcoding}{{2.1}{42}{Nested contrast coding to investigate the effect of intrusion in grammatical and ungrammatical agreement and reflexive constructions. The contrast dep is the main effect of dependency type (agreement or reflexive). The abbreviation intr.au means intrusion (interference effect) in agreement dependencies, ungrammatical; intr.ag stands for intrusion (interference effect) in agreement dependencies, grammatical; intr.ru refers to intrusion (interference effect) in reflexive dependencies, ungrammatical; intr.rg stands for intrusion (interference effect) in reflexive dependencies, grammatical}{table.2.1}{}}
\citation{JaegerMertzenVanDykeVasishth2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Summary for total reading time of the Dillon et al.\ (2013) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 40 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals.}}{43}{figure.2.8}\protected@file@percent }
\newlabel{fig:dillonresults}{{2.8}{43}{Summary for total reading time of the Dillon et al.\ (2013) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 40 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals}{figure.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Summary for total reading time of the J{\"a}ger et al.\ (2020) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 181 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals.}}{44}{figure.2.9}\protected@file@percent }
\newlabel{fig:dillonrepresults}{{2.9}{44}{Summary for total reading time of the J{\"a}ger et al.\ (2020) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 181 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals}{figure.2.9}{}}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{LewisVasishth2005}
\citation{YadavEtAlAMLaP2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Individual-level effects in the Dillon et al.\ design}{45}{subsection.2.5.1}\protected@file@percent }
\citation{JaegerMertzenVanDykeVasishth2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}A sensitivity analysis on the ungrammatical agreement and reflexives conditions using informative priors}{46}{subsection.2.5.2}\protected@file@percent }
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{SchadEtAlWorkflow}
\citation{ohagan2006uncertain,OakleyOHagan}
\citation{spiegelhalter2004bayesian}
\citation{JaegerEngelmannVasishth2017}
\citation{EngelmannJaegerVasishth2019}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Summary of the sensitivity analysis, investigating the effect of incorporating prior knowledge from: mildly uninformative priors; a meta-analysis of existing reading data on ungrammatical agreement and reflexives; and the model predictions in Engelmann, J\"ager, and Vasishth, 2019. The dependent measure in the analysis is total fixation time and the posterior estimates are back-transformed to the ms scale from log ms. The priors are shown in the ms scales.}}{48}{table.2.2}\protected@file@percent }
\newlabel{tab:sensitivityanalysis}{{2.2}{48}{Summary of the sensitivity analysis, investigating the effect of incorporating prior knowledge from: mildly uninformative priors; a meta-analysis of existing reading data on ungrammatical agreement and reflexives; and the model predictions in Engelmann, J\"ager, and Vasishth, 2019. The dependent measure in the analysis is total fixation time and the posterior estimates are back-transformed to the ms scale from log ms. The priors are shown in the ms scales}{table.2.2}{}}
\citation{JaegerEngelmannVasishth2017}
\citation{VasishthMertzenJaegerGelman2018,nicenboimexploratory,JaegerMertzenVanDykeVasishth2019,NicenboimPreactivation2019}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Concluding remarks}{49}{section.2.6}\protected@file@percent }
\citation{rp}
\citation{WatkinsWatkins1975,AndersonLebiere1998,AndersonEtAl2004,Ratcliff1978}
\citation{McElree2000,McElreeForakerDyer2003,VanDykeLewis2003,LewisVasishth2005,VanDykeMcElree2011}
\citation{Sternberg1966,Sternberg1969,BerwickWeinberg1984}
\citation{Sturt2003}
\citation{VanDykeLewis2003}
\citation{LewisVasishth2005}
\citation{LewisVasishthVanDyke2006}
\citation{VasishthLewis2006}
\citation{LewisVasishth2005}
\citation{AndersonLebiere1998,AndersonEtAl2004}
\citation{McElree2006,Cowan2001,Miller1956}
\citation{Newell1973,Newell1978}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The core ACT-R-based model of retrieval processes}{51}{chapter.3}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c02}{{3}{51}{The core ACT-R-based model of retrieval processes}{chapter.3}{}}
\citation{LewisVasishth2005}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}ACT-R}{52}{section.3.1}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\newlabel{eq:base}{{3.1}{53}{ACT-R}{equation.3.1.1}{}}
\newlabel{eq:spread}{{3.2}{53}{ACT-R}{equation.3.1.2}{}}
\newlabel{eq:fan}{{3.3}{53}{ACT-R}{equation.3.1.3}{}}
\citation{LewisVasishth2005}
\citation{McElree2006,Ratcliff1978}
\citation{LewisVasishth2005}
\newlabel{eq:pm}{{3.4}{54}{ACT-R}{equation.3.1.4}{}}
\newlabel{eq:act}{{3.5}{54}{ACT-R}{equation.3.1.5}{}}
\newlabel{eq:rt}{{3.6}{54}{ACT-R}{equation.3.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Lewis \& Vasishth (2005) model}{54}{section.3.2}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{Chomsky1986}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\newlabel{ex:centeremb}{{20}{55}{The Lewis \& Vasishth (2005) model}{Item.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Figure\nobreakspace  {}1 of \cite  {LewisVasishth2005}. The figure shows the representation of chunks (maximal projections of phrases) that constitute a syntactic tree. The figure is coprighted by Wiley, and is reused with permission, license number 4782371233287.}}{55}{figure.3.1}\protected@file@percent }
\newlabel{fig:lv05chunks}{{3.1}{55}{Figure~1 of \cite {LewisVasishth2005}. The figure shows the representation of chunks (maximal projections of phrases) that constitute a syntactic tree. The figure is coprighted by Wiley, and is reused with permission, license number 4782371233287}{figure.3.1}{}}
\citation{VasishthLewis2006}
\citation{VasishthBruessowLewis2008}
\citation{PatilVasishthLewis2012,ParkerPhillips2014,JaegerEngelmannVasishth2015}
\citation{WagersLauPhillips2009,DillonMishlerSloggett2013}
\citation{PatilEtAl2016,MaetzigEtAltopics2018,LissonEtAl2020}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Figure\nobreakspace  {}2 of \cite  {LewisVasishth2005}. The figure shows the processing cycle of the parsing algorithm. The figure is copyrighted by Wiley, and is reused with permission, license number 4782380063983.}}{56}{figure.3.2}\protected@file@percent }
\newlabel{fig:lv05buffers}{{3.2}{56}{Figure~2 of \cite {LewisVasishth2005}. The figure shows the processing cycle of the parsing algorithm. The figure is copyrighted by Wiley, and is reused with permission, license number 4782380063983}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}A priori predictions of the model}{56}{subsection.3.2.1}\protected@file@percent }
\newlabel{lv05predictions}{{3.2.1}{56}{A priori predictions of the model}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Spreading activation according to ACT-R/LV05 in the four conditions shown in Example\nobreakspace  {}\ref  {ex:c03sturt03:exp2}. Line weights indicate the amount of  spreading activation from a cue to an item. Black oval boxes represent a feature match. Gray oval boxes indicate features matching an  `overloaded' cue (\texttt  {\uppercase {MASC}} in b), and white boxes indicate a mismatch. The figure is by Engelmann and Vasishth (2019); available at dx.doi.org/10.6084/m9.figshare.9305456 under a CC-BY4.0 license.}}{57}{figure.3.3}\protected@file@percent }
\newlabel{fig:c03ACTRpred}{{3.3}{57}{Spreading activation according to ACT-R/LV05 in the four conditions shown in Example~\ref {ex:c03sturt03:exp2}. Line weights indicate the amount of \index {spreading activation} spreading activation from a cue to an item. Black oval boxes represent a feature match. Gray oval boxes indicate features matching an \index {cue overload} `overloaded' cue (\actrcue {MASC} in b), and white boxes indicate a mismatch. The figure is by Engelmann and Vasishth (2019); available at dx.doi.org/10.6084/m9.figshare.9305456 under a CC-BY4.0 license}{figure.3.3}{}}
\newlabel{ex:c03sturt03:exp2}{{21}{57}{A priori predictions of the model}{Item.80}{}}
\citation{VasishthEtAlTiCS2019,JaegerMertzenVanDykeVasishth2019,YadavEtAlAMLaP2020}
\citation{WatkinsWatkins1975}
\@writefile{toc}{\contentsline {subsubsection}{Inhibitory interference through the fan effect}{58}{section*.10}\protected@file@percent }
\newlabel{eq:bl}{{3.7}{58}{Inhibitory interference through the fan effect}{equation.3.2.7}{}}
\newlabel{eq:spread2}{{3.8}{58}{Inhibitory interference through the fan effect}{equation.3.2.8}{}}
\citation{anderson1974retrieval}
\citation{McElree2006}
\citation{McElree1993}
\citation{McElree2006}
\citation{NicenboimRetrieval2018,LissonEtAl2020}
\citation{raab1962division}
\citation{LogacevVasishth2015}
\newlabel{eq:assoc}{{3.9}{59}{Inhibitory interference through the fan effect}{equation.3.2.9}{}}
\newlabel{eq:rtrep}{{3.10}{59}{Inhibitory interference through the fan effect}{equation.3.2.10}{}}
\citation{rp}
\@writefile{toc}{\contentsline {subsubsection}{Facilitatory interference through a race process}{60}{section*.11}\protected@file@percent }
\citation{R2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces An illustration of a race process involving two distributions that represent retrieval time distributions of two items. When the two distributions have similar means (Figure A), the distribution of the retrieval times of the winner (which may differ from trial to trial) will have a distribution with a mean that is lower than the mean of the two distributions involved in the race (statistical facilitation). When one distribution has a much smaller mean than the other distribution's mean (Figure B), the distribution of the winner's retrieval times will have the same mean as that of the distribution of the item with the smaller mean.}}{61}{figure.3.4}\protected@file@percent }
\newlabel{fig:raceproc}{{3.4}{61}{An illustration of a race process involving two distributions that represent retrieval time distributions of two items. When the two distributions have similar means (Figure A), the distribution of the retrieval times of the winner (which may differ from trial to trial) will have a distribution with a mean that is lower than the mean of the two distributions involved in the race (statistical facilitation). When one distribution has a much smaller mean than the other distribution's mean (Figure B), the distribution of the winner's retrieval times will have the same mean as that of the distribution of the item with the smaller mean}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Comparison of the LV05 prediction space with the results of the J\"ager et al.\ meta-analysis}{61}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Methods}{61}{section*.12}\protected@file@percent }
\newlabel{sec:generalmethods}{{3.2.2}{61}{Methods}{section*.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Prediction space for the interference effect in ACT-R in target-match (circles, solid line) and target-mismatch configurations (triangles, broken line). Interference is plotted in terms of the difference in mean retrieval latencies between the interference (labelled distractor-match) and the no-interference (labelled distractor-mismatch) condition, and as a function of the latency factor $F$. Positive values indicate longer mean retrieval latencies in the interference condition (\emph  {inhibitory interference}) due to cue-overload (fan effect) from a partially matching distractor; negative values indicate shorter mean retrieval latencies in the interference condition (\emph  {facilitatory interference}) due to retrievals of the partially matching distractor on trials where the distractor is highly activated and hence fast. Each individual data point represents the mean interference effect of 6,000 iterations with one out of 10,980 different parameter settings (each in target-match and target-mismatch configurations; i.e., there are 21,960 data points plotted in total). Each parameter setting is a combination of the following parameter values: latency factor $F \in \{0, 0.01, ..., 0.6\}$, noise parameter $\textit {ANS} \in \{0.1, 0.2, 0.3\}$, maximum associative strength $\textit {MAS} \in \{1,2,3,4\}$, mismatch penalty $\textit {MP} \in \{0,1,2\}$, retrieval threshold $\tau \in \{-2,-1.5,...,0\}$.}}{62}{figure.3.5}\protected@file@percent }
\newlabel{fig:lv05plots}{{3.5}{62}{Prediction space for the interference effect in ACT-R in target-match (circles, solid line) and target-mismatch configurations (triangles, broken line). Interference is plotted in terms of the difference in mean retrieval latencies between the interference (labelled distractor-match) and the no-interference (labelled distractor-mismatch) condition, and as a function of the latency factor $F$. Positive values indicate longer mean retrieval latencies in the interference condition (\emph {inhibitory interference}) due to cue-overload (fan effect) from a partially matching distractor; negative values indicate shorter mean retrieval latencies in the interference condition (\emph {facilitatory interference}) due to retrievals of the partially matching distractor on trials where the distractor is highly activated and hence fast. Each individual data point represents the mean interference effect of 6,000 iterations with one out of 10,980 different parameter settings (each in target-match and target-mismatch configurations; i.e., there are 21,960 data points plotted in total). Each parameter setting is a combination of the following parameter values: latency factor $\protect F \in \{0, 0.01, ..., 0.6\}$, noise parameter $\protect \textit {ANS} \in \{0.1, 0.2, 0.3\}$, maximum associative strength $\protect \textit {MAS} \in \{1,2,3,4\}$, mismatch penalty $\protect \textit {MP} \in \{0,1,2\}$, retrieval threshold $\protect \tau \in \{-2,-1.5,...,0\}$}{figure.3.5}{}}
\citation{JaegerEngelmannVasishth2017}
\citation{Gelman14}
\citation{JaegerEngelmannVasishth2017}
\citation{WagersLauPhillips2009,Pearlmutter1999}
\citation{VanDyke2007,VanDykeMcElree2011}
\citation{JaegerEngelmannVasishth2017}
\@writefile{toc}{\contentsline {subsubsection}{Results}{63}{section*.13}\protected@file@percent }
\citation{nicenboimexploratory,JaegerEngelmannVasishth2017,VasishthMertzenJaegerGelman2018,JaegerMertzenVanDykeVasishth2019}
\citation{parker2017reflexive}
\citation{CunningsSturt2018}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{DillonMishlerSloggett2013}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Results of the J\"ager et al.\ (2017) meta-analysis showing mean effect estimates $\mathaccentV {bar}016{b}$ with Bayesian 95\% credible intervals in the Estimates column. The range specified by a 95\% credible interval contains the true value of the estimated parameter with 95\% certainty, given the model and the data. A positive interference effect means inhibition, a negative one facilitation. Results are compared with the predictions of cue-based retrieval as implemented in the LV05 ACT-R model, and the additional contributions of the extensions  \emph  {item prominence} (IP) and  \emph  {multi-associative cues} (MAC), which are discussed in Chapter\nobreakspace  {}\ref  {c02prominence}.}}{64}{table.3.1}\protected@file@percent }
\newlabel{tab:resultsMeta1}{{3.1}{64}{Results of the J\"ager et al.\ (2017) meta-analysis showing mean effect estimates $\bar {b}$ with Bayesian 95\% credible intervals in the Estimates column. The range specified by a 95\% credible interval contains the true value of the estimated parameter with 95\% certainty, given the model and the data. A positive interference effect means inhibition, a negative one facilitation. Results are compared with the predictions of cue-based retrieval as implemented in the LV05 ACT-R model, and the additional contributions of the extensions \index {prominence} \emph {item prominence} (IP) and \index {multi-associative cues} \emph {multi-associative cues} (MAC), which are discussed in Chapter~\ref {c02prominence}}{table.3.1}{}}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\citation{NicenboimRetrieval2018,LissonEtAl2020}
\citation{YadavEtAlAMLaP2020}
\citation{VasishthMethodsX2019}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}A more principled approach to parameter estimation}{67}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Bayesian parameter estimation}{67}{subsection.3.3.1}\protected@file@percent }
\citation{blitzstein2014introduction}
\citation{blitzstein2014introduction}
\citation{lunn2012bugs,Gelman14}
\citation{lunn2012bugs,NicenboimEtAlBayes2019}
\citation{SissonABC}
\citation{SissonABC,palestro2018likelihood}
\citation{DillonMishlerSloggett2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Approximate Bayesian Computation}{70}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Step 1: Define a prior distribution for the parameter}{70}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces A Beta(2,6) prior on the latency factor.}}{70}{figure.3.6}\protected@file@percent }
\newlabel{fig:betaprior}{{3.6}{70}{A Beta(2,6) prior on the latency factor}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{The estimates from data for ungrammatical conditions}{71}{section*.15}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces ABC using rejection sampling. Shown is the case where we need to sample posterior values for a single parameter $\theta $. Each iteration of the algorithm consists of drawing a single random sample from a prior distribution for the parameter (here, $Beta(2,6)$), and then generating the predicted mean effect from the model using that sampled parameter value. If the predicted mean effect is near the observed data (in our implementation, if the predicted effect lies within one standard error of the mean effect of interest), then accept the sampled parameter value; otherwise reject that sampled value. This process is repeated until we have sufficient samples from the posterior distribution of the parameter. These samples therefore constitute the posterior distribution of the parameter.}}{71}{algocf.1}\protected@file@percent }
\newlabel{alg:abcrejection}{{1}{71}{The estimates from data for ungrammatical conditions}{algocf.1}{}}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{DillonMishlerSloggett2013}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{DillonMishlerSloggett2013}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{YadavEtAlAMLaP2020}
\@writefile{toc}{\contentsline {subsubsection}{Step 2: Compute posterior distributions of the latency factor using ABC rejection sampling}{72}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Step 3: Generate posterior predicted data}{72}{section*.17}\protected@file@percent }
\citation{rp}
\citation{VasishthMertzenJaegerGelman2018,JaegerMertzenVanDykeVasishth2019,MertzenEtAlAMLaP2019}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The posterior distributions of the latency factor parameters for agreement and reflexive conditions using the original Dillon et al.\ (2013) data (40 participants, 48 items) and our own J\IeC {\"a}ger et al.\ (2019) replication data (181 participants, 48 items).}}{73}{figure.3.7}\protected@file@percent }
\newlabel{fig:lfvalues}{{3.7}{73}{The posterior distributions of the latency factor parameters for agreement and reflexive conditions using the original Dillon et al.\ (2013) data (40 participants, 48 items) and our own JÃ¤ger et al.\ (2019) replication data (181 participants, 48 items)}{figure.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Concluding remarks}{73}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The posterior predictive distributions of the facilitatory interference in ungrammatical agreement and reflexive conditions, derived using the posterior distributions of the latency factor parameter.}}{74}{figure.3.8}\protected@file@percent }
\newlabel{fig:ppmeansvalues}{{3.8}{74}{The posterior predictive distributions of the facilitatory interference in ungrammatical agreement and reflexive conditions, derived using the posterior distributions of the latency factor parameter}{figure.3.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Extension: Prominence and multi-associative cues}{75}{chapter.4}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c02prominence}{{4}{75}{Extension: Prominence and multi-associative cues}{chapter.4}{}}
\citation{EngelmannJaegerVasishth2019}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Incorporating prominence and multi-associative cues}{76}{section.4.1}\protected@file@percent }
\newlabel{ex:sturt03:exp2}{{22}{76}{Incorporating prominence and multi-associative cues}{Item.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Predictions of ACT-R for the four conditions shown in Example\nobreakspace  {}(\ref  {ex:sturt03:exp2}). Line weights indicate the amount of spreading activation from a cue to an item. Black oval boxes represent a feature match. Gray oval boxes indicate features matching an `overloaded' cue (\texttt  {\uppercase {MASC}} in b), and white boxes indicate a mismatch.}}{77}{figure.4.1}\protected@file@percent }
\newlabel{fig:ACTRpred}{{4.1}{77}{Predictions of ACT-R for the four conditions shown in Example~(\ref {ex:sturt03:exp2}). Line weights indicate the amount of spreading activation from a cue to an item. Black oval boxes represent a feature match. Gray oval boxes indicate features matching an `overloaded' cue (\actrcue {MASC} in b), and white boxes indicate a mismatch}{figure.4.1}{}}
\citation{Ariel1990,Arnold2007,Brennan1995,Chafe1976,DuBois2003,GroszJoshiWeinstein1995,KeenanComrie1977}
\citation{Arnold2001}
\citation{CowlesWalenskiKluender2007}
\citation{GernsbacherHargreaves1988}
\citation{FukumuraVanGompel2011}
\citation{VanDykeMcElree2011,CunningsFelser2013,PatilVasishthLewis2016,Sturt2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Item prominence}{78}{subsection.4.1.1}\protected@file@percent }
\newlabel{sec:prominence}{{4.1.1}{78}{Item prominence}{subsection.4.1.1}{}}
\newlabel{prominenceimplementationpageref}{{4.1.1}{79}{Item prominence}{subsection.4.1.1}{}}
\citation{raab1962division}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Predicted target-match and target-mismatch interference effects (distractor-match minus distractor-mismatch) as a function of distractor prominence ($p\_{distr}$ ranging from $\{-3,\dots  ,5\}$ when target prominence is zero (mean of 10,000 iterations with parameters F=0.2, \textit  {ANS}=0.2, \textit  {MAS}=2, \textit  {MP}=0). Positive values indicate longer mean retrieval latencies (inhibition) in the interference condition due to  cue overload  (fan effect). Negative values indicate shorter mean retrieval latencies (facilitation) in the interference condition due to retrievals of the distractor on trials where the distractor is highly activated and hence fast. The points where the vertical line intersects with the curves represent standard LV05 predictions.}}{80}{figure.4.2}\protected@file@percent }
\newlabel{fig:prominenceNew}{{4.2}{80}{Predicted target-match and target-mismatch interference effects (distractor-match minus distractor-mismatch) as a function of distractor prominence ($\protect p\_{distr}$ ranging from $\protect \{-3,\dots ,5\}$ when target prominence is zero (mean of 10,000 iterations with parameters F=0.2, \textit {ANS}=0.2, \textit {MAS}=2, \textit {MP}=0). Positive values indicate longer mean retrieval latencies (inhibition) in the interference condition due to \index {cue overload} cue overload \index {fan effect} (fan effect). Negative values indicate shorter mean retrieval latencies (facilitation) in the interference condition due to retrievals of the distractor on trials where the distractor is highly activated and hence fast. The points where the vertical line intersects with the curves represent standard LV05 predictions}{figure.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Predictions in target-mismatch configurations}{80}{section*.18}\protected@file@percent }
\newlabel{promexpl}{{4.1.1}{80}{Predictions in target-mismatch configurations}{section*.18}{}}
\citation{LogacevVasishth2015}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Mechanisms underlying the effect of distractor prominence in target-mismatch configurations. X-axis in each panel shows increasing distractor prominence (with target prominence $=0$). The panels from top left are: 1) Mean activation of target and distractor at retrieval event in interference (distractor-match) and no-interference (distractor-mismatch) condition (the sign of the activation value --- negative or positive --- has no special meaning in ACT-R). 2) Proportion of distractor retrievals over multiple iterations (retrieval probability). Values above $0.5$ indicate higher retrieval probability for the distractor than the target (misretrievals). 3) Mean retrieval latencies (of most activated item at retrieval). 4) Mean interference effect as the difference in retrieval latencies between interference and no-interference condition. Positive values mean inhibitory interference (longer latencies when distractor matches); negative values mean facilitatory interference (short latencies due to misretrievals when distractor mismatches). The vertical lines mark locations of (a) low interference due to low prominence; (b) LV05 equivalence at prominence $=0$ (equal activation of target and distractor in interference condition); (c) maximal facilitatory interference effect due to misretrievals; (d) low interference due to latencies close to zero. }}{82}{figure.4.3}\protected@file@percent }
\newlabel{fig:promEnsMismatch}{{4.3}{82}{Mechanisms underlying the effect of distractor prominence in target-mismatch configurations. X-axis in each panel shows increasing distractor prominence (with target prominence $=0$). The panels from top left are: 1) Mean activation of target and distractor at retrieval event in interference (distractor-match) and no-interference (distractor-mismatch) condition (the sign of the activation value --- negative or positive --- has no special meaning in ACT-R). 2) Proportion of distractor retrievals over multiple iterations (retrieval probability). Values above $0.5$ indicate higher retrieval probability for the distractor than the target (misretrievals). 3) Mean retrieval latencies (of most activated item at retrieval). 4) Mean interference effect as the difference in retrieval latencies between interference and no-interference condition. Positive values mean inhibitory interference (longer latencies when distractor matches); negative values mean facilitatory interference (short latencies due to misretrievals when distractor mismatches). The vertical lines mark locations of (a) low interference due to low prominence; (b) LV05 equivalence at prominence $=0$ (equal activation of target and distractor in interference condition); (c) maximal facilitatory interference effect due to misretrievals; (d) low interference due to latencies close to zero}{figure.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Predictions in target-match configurations}{83}{section*.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Mechanisms underlying the effect of distractor prominence in target-match configurations. X-axis in each panel shows increasing distractor prominence (with target prominence $=0$). The panels from top left are: 1) Mean activation of target and distractor at retrieval event in interference (distractor-match) and no-interference (distractor-mismatch) condition (the sign of the activation value --- negative or positive --- has no special meaning in ACT-R). 2) Proportion of distractor retrievals over multiple iterations (retrieval probability). Values above $0.5$ indicate higher retrieval probability for the distractor than the target (misretrievals). 3) Mean retrieval latencies (of most activated item at retrieval). 4) Mean interference effect as the difference in retrieval latencies between interference and no-interference condition. Positive values mean inhibitory interference (longer latencies when distractor matches); negative values mean facilitatory interference (short latencies due to misretrievals when distractor mismatches). The vertical lines mark locations of (a) low interference due to low prominence; (b) maximal inhibitory interference effect due to increased fan; (c) equal activation of target and distractor in interference condition: lower fan effect due to statistical facilitation; (d) zero interference effect because of equal strength of fan effect and facilitation due to misretrievals of the highly-activated distractor; (e) maximal facilitatory interference effect due to misretrievals; (f) low interference due to latencies close to zero. }}{84}{figure.4.4}\protected@file@percent }
\newlabel{fig:promEnsMatch}{{4.4}{84}{Mechanisms underlying the effect of distractor prominence in target-match configurations. X-axis in each panel shows increasing distractor prominence (with target prominence $=0$). The panels from top left are: 1) Mean activation of target and distractor at retrieval event in interference (distractor-match) and no-interference (distractor-mismatch) condition (the sign of the activation value --- negative or positive --- has no special meaning in ACT-R). 2) Proportion of distractor retrievals over multiple iterations (retrieval probability). Values above $0.5$ indicate higher retrieval probability for the distractor than the target (misretrievals). 3) Mean retrieval latencies (of most activated item at retrieval). 4) Mean interference effect as the difference in retrieval latencies between interference and no-interference condition. Positive values mean inhibitory interference (longer latencies when distractor matches); negative values mean facilitatory interference (short latencies due to misretrievals when distractor mismatches). The vertical lines mark locations of (a) low interference due to low prominence; (b) maximal inhibitory interference effect due to increased fan; (c) equal activation of target and distractor in interference condition: lower fan effect due to statistical facilitation; (d) zero interference effect because of equal strength of fan effect and facilitation due to misretrievals of the highly-activated distractor; (e) maximal facilitatory interference effect due to misretrievals; (f) low interference due to latencies close to zero}{figure.4.4}{}}
\citation{VanDykeMcElree2011}
\citation{PatilVasishthLewis2016}
\citation{Sturt2003}
\citation{VanDykeMcElree2011}
\citation{JaegerEngelmannVasishth2015}
\@writefile{toc}{\contentsline {paragraph}{A: Target-match inhibition}{86}{section*.20}\protected@file@percent }
\newlabel{ex:vandyke11subjobj}{{23}{86}{A: Target-match inhibition}{Item.90}{}}
\newlabel{ex:patil}{{24}{86}{A: Target-match inhibition}{Item.91}{}}
\newlabel{ex:sturt:exp2}{{25}{86}{A: Target-match inhibition}{Item.92}{}}
\citation{Sturt2003}
\citation{CunningsFelser2013}
\citation{VanDykeMcElree2011,PatilVasishthLewis2016,JaegerEngelmannVasishth2015}
\citation{CunningsFelser2013,Sturt2003}
\citation{JaegerEngelmannVasishth2017}
\@writefile{toc}{\contentsline {paragraph}{B: Target-match facilitation}{87}{section*.21}\protected@file@percent }
\newlabel{ex:cf13:ex2}{{26}{87}{B: Target-match facilitation}{Item.93}{}}
\newlabel{ex:cf13:ex2baseline}{{27}{87}{B: Target-match facilitation}{Item.94}{}}
\citation{bybee2006usage,langacker1987foundations,tomasello2003constructing}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Multi-associative cues}{88}{subsection.4.1.2}\protected@file@percent }
\newlabel{sec:cueconf}{{4.1.2}{88}{Multi-associative cues}{subsection.4.1.2}{}}
\citation{RescorlaWagner1972}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Possible feature combinations exhibited by correct antecedents of English reflexives, reciprocals, and Chinese \textit  {ziji}.}}{89}{table.4.1}\protected@file@percent }
\newlabel{tbl:featurecombinations}{{4.1}{89}{Possible feature combinations exhibited by correct antecedents of English reflexives, reciprocals, and Chinese \textit {ziji}}{table.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Spreading activation in conditions labelled distractor-match (c) and distractor-mismatch (d) conditions in target-mismatch configurations when cues are cross-associated. Line weight and box shading indicate the amount of spreading activation added to an item due to a feature match. Dashed lines represent spreading activation to a cross-associated feature.}}{90}{figure.4.5}\protected@file@percent }
\newlabel{fig:newmodelcueconf}{{4.5}{90}{Spreading activation in conditions labelled distractor-match (c) and distractor-mismatch (d) conditions in target-mismatch configurations when cues are cross-associated. Line weight and box shading indicate the amount of spreading activation added to an item due to a feature match. Dashed lines represent spreading activation to a cross-associated feature}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Predicted target-match and target-mismatch interference effects (distractor-match minus distractor-mismatch) as a function of the cross-association level c. Lines and shaded area show mean and range of the effect, respectively, for parameter values of the latency factor F ranging from 0.2 to 0.4, and distractor prominence ranging from -0.5, 0, 0.5, running 5,000 iterations each; other parameters were fixed as \textit  {ANS}$=0.2$, \textit  {MAS}$=2$, \textit  {MP}$=0$. Positive values indicate longer mean retrieval latencies (inhibition) in the interference condition due to cue-overload (fan effect). Negative values indicate shorter mean retrieval latencies (facilitation) in the interference condition due to misretrievals of the distractor.}}{91}{figure.4.6}\protected@file@percent }
\newlabel{fig:cueconf}{{4.6}{91}{Predicted target-match and target-mismatch interference effects (distractor-match minus distractor-mismatch) as a function of the cross-association level c. Lines and shaded area show mean and range of the effect, respectively, for parameter values of the latency factor F ranging from 0.2 to 0.4, and distractor prominence ranging from -0.5, 0, 0.5, running 5,000 iterations each; other parameters were fixed as \textit {ANS}$\protect =0.2$, \textit {MAS}$\protect =2$, \textit {MP}$\protect =0$. Positive values indicate longer mean retrieval latencies (inhibition) in the interference condition due to cue-overload (fan effect). Negative values indicate shorter mean retrieval latencies (facilitation) in the interference condition due to misretrievals of the distractor}{figure.4.6}{}}
\citation{KushPhillips2014}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\newlabel{eq:cmetric}{{4.1}{92}{Multi-associative cues}{equation.4.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Implementation of item prominence and multi-associative cues}{93}{subsection.4.1.3}\protected@file@percent }
\newlabel{sec:impl}{{4.1.3}{93}{Implementation of item prominence and multi-associative cues}{subsection.4.1.3}{}}
\citation{SchneiderAnderson2012}
\newlabel{eq:newfan}{{4.4}{94}{Implementation of item prominence and multi-associative cues}{equation.4.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Multi-associative cues}{94}{subsection.4.1.4}\protected@file@percent }
\newlabel{eq:Qji}{{4.5}{95}{Multi-associative cues}{equation.4.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Standard target-mismatch/distractor-match condition without cross-associated cues.}}{95}{figure.4.7}\protected@file@percent }
\newlabel{fig:implFig1}{{4.7}{95}{Standard target-mismatch/distractor-match condition without cross-associated cues}{figure.4.7}{}}
\newlabel{eq:newfannoxassoc2}{{4.6}{95}{Multi-associative cues}{equation.4.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Target-mismatch/distractor-match condition when cues are cross-associated.}}{96}{figure.4.8}\protected@file@percent }
\newlabel{fig:implFig2}{{4.8}{96}{Target-mismatch/distractor-match condition when cues are cross-associated}{figure.4.8}{}}
\newlabel{eq:newfannoxassoc3}{{4.12}{96}{Multi-associative cues}{equation.4.1.12}{}}
\newlabel{eq:newfannoxassoc4}{{4.15}{97}{Multi-associative cues}{equation.4.1.15}{}}
\newlabel{crossasspageref}{{{\rm  (ii)}}{98}{Multi-associative cues}{equation.4.1.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Prominence}{98}{subsection.4.1.5}\protected@file@percent }
\newlabel{eq:bl2}{{4.19}{98}{Prominence}{equation.4.1.19}{}}
\newlabel{eq:Qji2}{{4.20}{98}{Prominence}{equation.4.1.20}{}}
\citation{JaegerEngelmannVasishth2017}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}A simulation of the meta-analysis studies}{99}{section.4.2}\protected@file@percent }
\newlabel{sec:sims}{{4.2}{99}{A simulation of the meta-analysis studies}{section.4.2}{}}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Data}{100}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Method}{100}{subsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Number of studies included in the \cite  {JaegerEngelmannVasishth2017} meta-analysis and in the simulations, grouped by dependency type and distractor prominence status (studies are listed in Table\nobreakspace  {}\ref  {tab:exps} in the Appendix).}}{101}{figure.4.9}\protected@file@percent }
\newlabel{fig:datasummary}{{4.9}{101}{Number of studies included in the \cite {JaegerEngelmannVasishth2017} meta-analysis and in the simulations, grouped by dependency type and distractor prominence status (studies are listed in Table~\ref {tab:exps} in the Appendix)}{figure.4.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Parameter estimation}{101}{section*.22}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Results}{102}{subsection.4.2.3}\protected@file@percent }
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Root-mean-square deviation between modelling results and observed data, averaged within dependency type and model (best values in bold). The superscript no dec means that the decay parameter is set to 0.}}{103}{table.4.2}\protected@file@percent }
\newlabel{tab:simfit}{{4.2}{103}{Root-mean-square deviation between modelling results and observed data, averaged within dependency type and model (best values in bold). The superscript no dec means that the decay parameter is set to 0}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Estimated values for prominence parameter in the LV05+IP+MAC model with decay for three prominence levels.}}{103}{table.4.3}\protected@file@percent }
\newlabel{tab:promtab}{{4.3}{103}{Estimated values for prominence parameter in the LV05+IP+MAC model with decay for three prominence levels}{table.4.3}{}}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{JaegerEngelmannVasishth2017}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Mean interference effects from simulations with LV05 and the extended model, labelled LV05+IP+MAC, for target-match and target-mismatch configurations of the meta-analysis, grouped by dependency type (studies are listed in Table\nobreakspace  {}\ref  {tab:exps} in the Appendix). The behavioural data is shown as mean effect estimates with 95\% credible intervals as reported in \cite  {JaegerEngelmannVasishth2017}.}}{104}{figure.4.10}\protected@file@percent }
\newlabel{fig:simresultsBayesMeans}{{4.10}{104}{Mean interference effects from simulations with LV05 and the extended model, labelled LV05+IP+MAC, for target-match and target-mismatch configurations of the meta-analysis, grouped by dependency type (studies are listed in Table~\ref {tab:exps} in the Appendix). The behavioural data is shown as mean effect estimates with 95\% credible intervals as reported in \cite {JaegerEngelmannVasishth2017}}{figure.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Mean interference effects from simulations with LV05 and the extended model, labelled LV05+IP+MAC, for target-match (top panel) and target-mismatch configurations (bottom panel) in the \cite  {JaegerEngelmannVasishth2017} meta-analysis, grouped by distractor prominence level within dependency types (studies are listed in Table\nobreakspace  {}\ref  {tab:exps} in the Appendix). The behavioural data is shown as raw means with additional smaller points representing individual studies. The target-mismatch plot in non-agreement subject-verb dependencies does not contain data because no data were available at the time of the meta-analysis. However, \cite  {CunningsSturt2018} have recently found evidence consistent with the predictions of the model; in two experiments, they obtained an estimated mean of $-22$ ms with a 95\% credible interval of $[-4,-42]$, and in a second experiment, a mean of $-19$ ms, $[-40,1]$. }}{105}{figure.4.11}\protected@file@percent }
\newlabel{fig:simresults}{{4.11}{105}{Mean interference effects from simulations with LV05 and the extended model, labelled LV05+IP+MAC, for target-match (top panel) and target-mismatch configurations (bottom panel) in the \cite {JaegerEngelmannVasishth2017} meta-analysis, grouped by distractor prominence level within dependency types (studies are listed in Table~\ref {tab:exps} in the Appendix). The behavioural data is shown as raw means with additional smaller points representing individual studies. The target-mismatch plot in non-agreement subject-verb dependencies does not contain data because no data were available at the time of the meta-analysis. However, \cite {CunningsSturt2018} have recently found evidence consistent with the predictions of the model; in two experiments, they obtained an estimated mean of $-22$ ms with a 95\% credible interval of $[-4,-42]$, and in a second experiment, a mean of $-19$ ms, $[-40,1]$}{figure.4.11}{}}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{Sturt2003}
\citation{CunningsFelser2013}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{Sturt2003}
\citation{CunningsFelser2013}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{CunningsFelser2013}
\citation{Sturt2003}
\citation{CunningsFelser2013}
\citation{CunningsFelser2013}
\citation{LewisVasishth2005}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Reading time data and simulation results of LV05 and the extended model, labelled LV05+IP+MAC, for interference effects in target-match and target-mismatch configurations of four individual studies: \cite  {KushPhillips2014}; \cite  [][Exp.\ 1]{JaegerEngelmannVasishth2015}; \cite  [][Exp.\ 1]{Sturt2003}; and \cite  [][Exp.\ 2, participants with low working memory]{CunningsFelser2013}. }}{107}{figure.4.12}\protected@file@percent }
\newlabel{fig:simresultsSlct}{{4.12}{107}{Reading time data and simulation results of LV05 and the extended model, labelled LV05+IP+MAC, for interference effects in target-match and target-mismatch configurations of four individual studies: \cite {KushPhillips2014}; \cite [][Exp.\ 1]{JaegerEngelmannVasishth2015}; \cite [][Exp.\ 1]{Sturt2003}; and \cite [][Exp.\ 2, participants with low working memory]{CunningsFelser2013}}{figure.4.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Discussion}{107}{section.4.3}\protected@file@percent }
\citation{rp}
\citation{CunningsFelser2013}
\citation{CunningsFelser2013}
\citation{OberauerLewandowsky2014,OberauerLewandowsky2013,berman2009search}
\citation{JaegerEngelmannVasishth2017}
\citation{GelmanCarlin2014}
\citation{DillonMishlerSloggett2013}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{VasishthMertzenJaegerGelman2018}
\citation{JaegerEngelmannVasishth2017}
\citation{CunningsSturt2018}
\citation{JaegerMertzenVanDykeVasishth2019}
\citation{CunningsSturt2018}
\newlabel{ex:CunningsSturt2018}{{28}{111}{Discussion}{Item.97}{}}
\citation{VanDykeMcElree2011}
\citation{Chafe1976,KeenanComrie1977,grosz95,Brennan1995}
\citation{Arnold2001}
\citation{CowlesWalenskiKluender2007}
\citation{GernsbacherHargreaves1988}
\citation{FukumuraVanGompel2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Distractor prominence}{112}{subsection.4.3.1}\protected@file@percent }
\citation{BaayenMilinDJurdjevic2011}
\citation{RescorlaWagner1972}
\citation{JaegerEngelmannVasishth2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Multi-associative cues}{113}{subsection.4.3.2}\protected@file@percent }
\newlabel{learningprocesspageref}{{4.3.2}{113}{Multi-associative cues}{subsection.4.3.2}{}}
\newlabel{ex:cueconf}{{29}{113}{Multi-associative cues}{Item.98}{}}
\citation{KushPhillips2014}
\citation{JaegerEngelmannVasishth2015}
\citation{JaegerEngelmannVasishth2017}
\citation{JaegerEngelmannVasishth2015}
\citation{VanDyke2006}
\citation{SwetsDesmetClifton2008,LogacevVasishth2015}
\citation{Traxler2007,MalsburgVasishth2013,NicenboimEtAlFrontiers2016Capacity}
\citation{FerreiraFerraroBailey2002}
\citation{CunningsFelser2013}
\citation{CunningsFelser2013}
\citation{Nicol1988,Sturt2003,VanDyke2007,VanDykeMcElree2011}
\citation{VanDyke2006}
\citation{CarminatiNella2005}
\@writefile{toc}{\addvspace {10pt}Appendices}
\@writefile{toc}{\contentsline {section}{\numberline {4.A}Key terms and concepts}{117}{section.a.4.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Shown here is the terminology used in the present chapter in relation to cue-based retrieval and interference in dependency resolution.}}{117}{table.4.4}\protected@file@percent }
\newlabel{tab:definitionsCBR}{{4.4}{117}{Shown here is the terminology used in the present chapter in relation to cue-based retrieval and interference in dependency resolution}{table.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Shown here is the terminology used in the extension of the cue-based retrieval model (continued from previous page).}}{118}{table.4.5}\protected@file@percent }
\newlabel{tab:definitionsEXT2}{{4.5}{118}{Shown here is the terminology used in the extension of the cue-based retrieval model (continued from previous page)}{table.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.B}List of experiments included in the simulations}{119}{section.a.4.B}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces List of experiments included in the simulations.}}{119}{table.4.6}\protected@file@percent }
\newlabel{tab:exps}{{4.6}{119}{List of experiments included in the simulations}{table.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces List of experiments included in the simulations (continued from previous page).}}{120}{table.4.7}\protected@file@percent }
\newlabel{tab:exps2}{{4.7}{120}{List of experiments included in the simulations (continued from previous page)}{table.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.C}Model specifications}{121}{section.a.4.C}\protected@file@percent }
\newlabel{sec:modelappendix}{{4.C}{121}{Model specifications}{section.a.4.C}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Model parameters, their default values, and the values used in the simulation of the studies in the meta-analysis.}}{121}{table.4.8}\protected@file@percent }
\newlabel{tbl:params}{{4.8}{121}{Model parameters, their default values, and the values used in the simulation of the studies in the meta-analysis}{table.4.8}{}}
\newlabel{eqnoise}{{4.21}{122}{Model specifications}{equation.a.4.C.21}{}}
\newlabel{eqmp}{{4.22}{122}{Model specifications}{equation.a.4.C.21}{}}
\newlabel{eqbaselevel3}{{4.23}{122}{Model specifications}{equation.a.4.C.21}{}}
\newlabel{eqrt2}{{4.24}{122}{Model specifications}{equation.a.4.C.21}{}}
\newlabel{eqnoisert}{{4.25}{122}{Model specifications}{equation.a.4.C.21}{}}
\citation{BicknellLevy2010a,EngbertEtAl2002,Engbert2005,Legge2002,Reichle1998,Nilsson2010,Reichle2006,Reilly2006}
\citation{Reichle2006}
\citation{Engbert2005}
\citation{Engelmanna}
\citation{vanDyke2003,FrazierRayner1982,MalsburgVasishth2011,MalsburgVasishth2012,Meseguer2002,MitchellEtAl2008,Weger2007}
\citation{BicknellLevy2010a}
\citation{Binder2001,Elman:2005p2,Hale2011,JustCarpenter1992,Konieczny2003,Budiu2004,LewisVasishth2005,MacDonaldChristiansen2002,SpiveyTanenhaus1998,VasishthBruessowLewis2008}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Extension: Eye-movement control and parsing}{123}{chapter.5}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c02emma}{{5}{123}{Extension: Eye-movement control and parsing}{chapter.5}{}}
\citation{ReichleWarrenMcConnell2009}
\citation{ReichleWarrenMcConnell2009}
\citation{LewisVasishth2005}
\citation{Hale2001,Levy2008}
\citation{Demberg2008,Konieczny2000,Vasishth2011,Staub2010a}
\citation{jemrsurprisal,BostonHaleVasishth2011,Patil2009,VasishthLewis2006}
\citation{Salvucci2001}
\citation{Reichle1998,ReichleWarrenMcConnell2009,Salvucci2001}
\citation{Schilling1998}
\citation{Kliegl2004}
\citation{Salvucci2001}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}The EMMA/ACT-R reading model}{125}{section.5.1}\protected@file@percent }
\newlabel{sec:emma}{{5.1}{125}{The EMMA/ACT-R reading model}{section.5.1}{}}
\citation{Salvucci2001}
\citation{Schilling1998}
\citation{Salvucci2001}
\citation{Reichle1998}
\citation{Francis1982}
\citation{Salvucci2001}
\citation{R2012}
\citation{Reichle1998}
\citation{Salvucci2001}
\citation{Reichle1998}
\citation{Salvucci2001}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Replication of Salvucci (2001)}{127}{section.5.2}\protected@file@percent }
\newlabel{sec:salvucci}{{5.2}{127}{Replication of Salvucci (2001)}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Data}{127}{subsection.5.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Frequency classes used in the analyses of the Schilling Corpus (SC) and Potsdam Sentence Corpus (PSC).}}{127}{table.5.1}\protected@file@percent }
\newlabel{classtable}{{5.1}{127}{Frequency classes used in the analyses of the Schilling Corpus (SC) and Potsdam Sentence Corpus (PSC)}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Model}{127}{subsection.5.2.2}\protected@file@percent }
\newlabel{RF1}{128}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Fit and parameter estimates for all simulations. The interpretation of the data are discussed in the results and discussion section.}}{128}{table.5.2}\protected@file@percent }
\newlabel{simtable}{{5.2}{128}{Fit and parameter estimates for all simulations. The interpretation of the data are discussed in the results and discussion section}{table.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Replication of Salvucci (2001) on the Schilling Corpus. Effects of word frequency on gaze, first, and single fixation duration, and on the rate of skipping a word, fixating it once and fixating it more than once. Grey solid lines represent experimental data, black dotted lines show Salvucci's simulation results, and black dashed lines show the replication results. Lexical frequency is divided into classes 1 (lowest) to 5 (highest).}}{129}{figure.5.1}\protected@file@percent }
\newlabel{fig:src-fstat}{{5.1}{129}{Replication of Salvucci (2001) on the Schilling Corpus. Effects of word frequency on gaze, first, and single fixation duration, and on the rate of skipping a word, fixating it once and fixating it more than once. Grey solid lines represent experimental data, black dotted lines show Salvucci's simulation results, and black dashed lines show the replication results. Lexical frequency is divided into classes 1 (lowest) to 5 (highest)}{figure.5.1}{}}
\citation{Salvucci2001}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Analysis}{130}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Results}{130}{subsection.5.2.4}\protected@file@percent }
\citation{Salvucci2001}
\citation{ReichleWarrenMcConnell2009}
\citation{MitchellEtAl2008}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Discussion}{131}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}The extended EMMA/ACT-R model}{131}{section.5.3}\protected@file@percent }
\newlabel{sec:extensionemmaparser}{{5.3}{131}{The extended EMMA/ACT-R model}{section.5.3}{}}
\citation{LewisVasishth2005}
\citation{Hale2001,Levy2008}
\citation{Hale2001,Levy2008}
\citation{Konieczny2000}
\citation{Hale2001}
\citation{Frank2009}
\citation{BostonHaleVasishth2011}
\citation{Staub2010a,Vasishth2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Surprisal}{132}{subsection.5.3.1}\protected@file@percent }
\citation{Kliegl2004}
\citation{jemrsurprisal}
\citation{BostonHaleVasishth2011}
\citation{Baayen1993}
\citation{Kliegl2004}
\citation{Salvucci2001}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Simulations on the Potsdam Sentence Corpus}{133}{section.5.4}\protected@file@percent }
\newlabel{sec:topics:psc}{{5.4}{133}{Simulations on the Potsdam Sentence Corpus}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Data}{133}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Potsdam Sentence Corpus}{133}{section*.23}\protected@file@percent }
\citation{BostonHaleVasishth2011}
\citation{BostonHaleVasishth2011}
\citation{jemrsurprisal}
\citation{Levy2008}
\citation{Salvucci2001}
\citation{jemrsurprisal}
\@writefile{toc}{\contentsline {paragraph}{Retrieval}{134}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Surprisal}{134}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Model}{134}{subsection.5.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A schematic figure illustrating the time out mechanism in the case of object vs.\ subject relatives. In an object relative, if the integration of the relative clause verb is still in progress while the encoding of the word following it has already completed, time-out initiates an attention shift to the word to the left of the currently fixated one (Time Out regression). Once the integration of the relative clause verb has finished, the \texttt  {exit-time-out} rule returns the model into the state of continuing fixating in the reading direction.}}{135}{figure.5.2}\protected@file@percent }
\newlabel{fig:timeout}{{5.2}{135}{A schematic figure illustrating the time out mechanism in the case of object vs.\ subject relatives. In an object relative, if the integration of the relative clause verb is still in progress while the encoding of the word following it has already completed, time-out initiates an attention shift to the word to the left of the currently fixated one (Time Out regression). Once the integration of the relative clause verb has finished, the \texttt {exit-time-out} rule returns the model into the state of continuing fixating in the reading direction}{figure.5.2}{}}
\citation{Kliegl2004}
\newlabel{eq:emma+s}{{5.2}{136}{Model}{equation.5.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Results}{136}{subsection.5.4.3}\protected@file@percent }
\newlabel{RF2}{137}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Shown are the predictions of Model 2 (EMMA, dotted lines) vs. Model 7 (EMMA+rs$_2$, dashed lines) vs. experimental data (grey solid lines) for the Potsdam Sentence Corpus. The figure shows means of early (first row) and late measures (second row) as a function of frequency class. Each row shows reading time durations on the left and probabilities on the right side.}}{137}{figure.5.3}\protected@file@percent }
\newlabel{fig:psc}{{5.3}{137}{Shown are the predictions of Model 2 (EMMA, dotted lines) vs. Model 7 (EMMA+rs$\protect _2$, dashed lines) vs. experimental data (grey solid lines) for the Potsdam Sentence Corpus. The figure shows means of early (first row) and late measures (second row) as a function of frequency class. Each row shows reading time durations on the left and probabilities on the right side}{figure.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{PSC vs. SC}{138}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Influence of parsing difficulty}{138}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Discussion}{139}{subsection.5.4.4}\protected@file@percent }
\citation{Salvucci2001}
\citation{MitchellEtAl2008}
\citation{LewisVasishth2005,VasishthLewis2006,VasishthBruessowLewis2008}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}General Discussion}{140}{section.5.5}\protected@file@percent }
\citation{ReichleWarrenMcConnell2009}
\citation{ReichleWarrenMcConnell2009}
\citation{Rayner2000}
\citation{Warren2007}
\citation{Budiu2004}
\citation{ReichleWarrenMcConnell2009}
\citation{FrazierRayner1982}
\citation{LewisVasishth2005}
\citation{Reichle1998}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Comparison with E-Z Reader}{141}{subsection.5.5.1}\protected@file@percent }
\citation{Budiu2004}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\citation{FrazierRayner1982,MalsburgVasishth2011,MalsburgVasishth2012,Meseguer2002}
\citation{Booth2013,Inhoff:2005p140,MitchellEtAl2008,Weger2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Future prospects}{142}{subsection.5.5.2}\protected@file@percent }
\citation{Reichle1998}
\citation{Salvucci2001}
\citation{Reichle1998}
\citation{Reichle1998}
\citation{Salvucci2001}
\citation{R2012}
\citation{BostonHaleVasishth2011}
\citation{BostonHaleVasishth2011}
\citation{BostonHaleVasishth2011}
\citation{BostonHaleVasishth2011}
\citation{BostonHaleVasishth2011}
\@writefile{toc}{\addvspace {10pt}Appendices}
\@writefile{toc}{\contentsline {section}{\numberline {5.A}Root-mean-square deviation}{145}{section.b.5.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.B}Linear regression analysis}{145}{section.b.5.B}\protected@file@percent }
\newlabel{eq:lm}{{5.4}{145}{Linear regression analysis}{equation.b.5.B.4}{}}
\newlabel{RF3}{147}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Linear regression results for predictors retrieval and surprisal}}{147}{table.5.3}\protected@file@percent }
\newlabel{lmtable}{{5.3}{147}{Linear regression results for predictors retrieval and surprisal}{table.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Coefficients and 95\% confidence intervals for predictors surprisal and retrieval estimated by linear regression. Predictors were log frequency, length, log retrieval, and surprisal. Coefficients are plotted along the y-axis for surprisal on the left side and retrieval on the right side. Regressions were carried out on the simulated data of all six EMMA models (shown on the x-axis). 95\% confidence intervals that do not cross 0 indicate statistical significance at $\alpha = 0.05.$}}{148}{figure.5.4}\protected@file@percent }
\newlabel{fig:pred}{{5.4}{148}{Coefficients and 95\% confidence intervals for predictors surprisal and retrieval estimated by linear regression. Predictors were log frequency, length, log retrieval, and surprisal. Coefficients are plotted along the y-axis for surprisal on the left side and retrieval on the right side. Regressions were carried out on the simulated data of all six EMMA models (shown on the x-axis). 95\% confidence intervals that do not cross 0 indicate statistical significance at $\alpha = 0.05.$}{figure.5.4}{}}
\citation{LewisVasishth2005}
\citation{Salvucci2001}
\citation{Kliegl2004}
\citation{BostonHaleVasishth2011}
\citation{LewisVasishth2005}
\citation{ReichleWarrenMcConnell2009}
\citation{Staub2010a}
\citation{engelmann:phd}
\citation{BaddeleyHitch1974,Baddeley2003}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Reanalysis and underspecification}{149}{chapter.6}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c04}{{6}{149}{Reanalysis and underspecification}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{149}{section.6.1}\protected@file@percent }
\citation{Staub2010a}
\citation{Staub2010a}
\citation{KingJust1991,GibsonDesmetGrodner2005,TraxlerMorrisSeely2002,SchriefersFriedericiKuhn1995,Frazier1987a,KwonGordonLee2010}
\citation{carreiras2010subject}
\citation{VasishthLewis2006}
\citation{HsiaoGibson2003}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces ACT-R/EMMA parameter values.}}{150}{table.6.1}\protected@file@percent }
\newlabel{tab:params}{{6.1}{150}{ACT-R/EMMA parameter values}{table.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Modelling reanalysis}{150}{section.6.2}\protected@file@percent }
\newlabel{sec:sim:II}{{6.2}{150}{Modelling reanalysis}{section.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Memory and Expectation in Relative Clauses}{150}{subsection.6.2.1}\protected@file@percent }
\newlabel{ex:staub10}{{32}{150}{Memory and Expectation in Relative Clauses}{Item.101}{}}
\citation{Gibson1998,Gibson2000,grodner,LewisVasishth2005,LewisVasishthVanDyke2006,McElreeForakerDyer2003}
\citation{Hale2001,Levy2008,GennariMacDonald2009,MitchellCuetosCorley1995}
\citation{gibsonwu,LinBever2006,HsiaoMacDonald2013,VasishthChenLi2013,JagerChenLi2015,WuKaiserVasishth2017}
\citation{Vasishth:MScStatistics}
\citation{Staub2010a}
\citation{Staub2010a}
\citation{Staub2010a}
\citation{FrazierRayner1982}
\citation{LewisVasishth2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Simulation: Modelling the Staub (2010) data}{152}{subsection.6.2.2}\protected@file@percent }
\citation{ReichleWarrenMcConnell2009}
\citation{ReichleWarrenMcConnell2009}
\citation{ReichleWarrenMcConnell2009}
\citation{MalsburgVasishth2011,MalsburgEtAl2015}
\citation{Meseguer2002,greenmitchellJML06}
\citation{Staub2010a}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Results}{153}{subsection.6.2.3}\protected@file@percent }
\citation{Staub2010a}
\citation{Staub2010a}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Model predictions for reading times in subject- and object-relative clauses.}}{154}{figure.6.1}\protected@file@percent }
\newlabel{fig:staubmodel:rt}{{6.1}{154}{Model predictions for reading times in subject- and object-relative clauses}{figure.6.1}{}}
\citation{ReichleWarrenMcConnell2009}
\citation{Staub2010a}
\citation{EngbertNuthmannRichter2005}
\citation{Rabe2019}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Predicted first-pass regressions from the model for subject- and object-relative clauses.}}{155}{figure.6.2}\protected@file@percent }
\newlabel{fig:staubmodel:reg}{{6.2}{155}{Predicted first-pass regressions from the model for subject- and object-relative clauses}{figure.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Discussion}{155}{subsection.6.2.4}\protected@file@percent }
\citation{BaddeleyHitch1974,Baddeley2003}
\citation{engelmann:phd}
\citation{Traxler2007}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Modelling underspecification}{157}{section.6.3}\protected@file@percent }
\newlabel{sec:sim:III}{{6.3}{157}{Modelling underspecification}{section.6.3}{}}
\citation{FerreiraFerraroBailey2002,SanfordSturt2002}
\citation{TraxlerPickeringClifton1998}
\citation{Traxler2007}
\citation{Traxler2007}
\citation{Traxler2007}
\citation{JustCarpenter1992}
\citation{macdonald1992working}
\citation{KemperCrowKemtes2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Good-Enough Parsing}{158}{subsection.6.3.1}\protected@file@percent }
\newlabel{ex:traxler07}{{33}{158}{Good-Enough Parsing}{Item.104}{}}
\newlabel{ex:kemper04}{{34}{158}{Good-Enough Parsing}{Item.108}{}}
\citation{KemperCrowKemtes2004}
\citation{CarreirasClifton1993,FrazierClifton1997}
\citation{Frazier1987}
\citation{FrazierClifton1997}
\citation{FerreiraFerraroBailey2002,SanfordSturt2002}
\citation{SwetsDesmetClifton2008}
\citation{TraxlerPickeringClifton1998}
\citation{Traxler2007}
\citation{SwetsDesmetClifton2008}
\citation{SwetsDesmetClifton2008}
\citation{LogacevMultiple,LogacevVasishthQJEP2016}
\newlabel{ex:swets08}{{35}{159}{Good-Enough Parsing}{Item.113}{}}
\citation{MalsburgVasishth2013}
\citation{Meseguer2002}
\citation{MalsburgVasishth2011}
\newlabel{ex:malsburg13preamble}{{36}{160}{Good-Enough Parsing}{Item.117}{}}
\newlabel{ex:malsburg13}{{37}{160}{Good-Enough Parsing}{Item.118}{}}
\citation{Traxler2007}
\citation{Traxler2007}
\citation{MalsburgVasishth2013}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Proportions of sentence rereading by working memory capacity in the data of von der Malsburg and Vasishth (2013).}}{161}{figure.6.3}\protected@file@percent }
\newlabel{fig:mv13data:rer}{{6.3}{161}{Proportions of sentence rereading by working memory capacity in the data of von der Malsburg and Vasishth (2013)}{figure.6.3}{}}
\citation{FrazierClifton1997}
\citation{DailyEtAl2001}
\citation{LovettRederLebiere1999}
\citation{VanRijVanRijnHendriks2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Simulation: Modelling the von der Malsburg and Vasishth (2013) experiment}{162}{subsection.6.3.2}\protected@file@percent }
\citation{LewisVasishth2005}
\citation{MalsburgVasishth2013}
\citation{SwetsDesmetClifton2008}
\citation{MalsburgVasishth2013}
\citation{LewisVasishth2005}
\citation{DailyEtAl2001}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Results}{164}{subsection.6.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Predicted gaze durations by source activation at ambiguous and unambiguous attachments.}}{164}{figure.6.4}\protected@file@percent }
\newlabel{fig:mv13model:rt}{{6.4}{164}{Predicted gaze durations by source activation at ambiguous and unambiguous attachments}{figure.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Predicted time out proportions by source activation at ambiguous and unambiguous attachments.}}{164}{figure.6.5}\protected@file@percent }
\newlabel{fig:mv13model:timeout}{{6.5}{164}{Predicted time out proportions by source activation at ambiguous and unambiguous attachments}{figure.6.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Predicted proportions of sentence rereading by source activation at ambiguous and unambiguous attachments.}}{165}{figure.6.6}\protected@file@percent }
\newlabel{fig:mv13model:rer}{{6.6}{165}{Predicted proportions of sentence rereading by source activation at ambiguous and unambiguous attachments}{figure.6.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Predicted attachment proportions by source activation at ambiguous and unambiguous attachments.}}{166}{figure.6.7}\protected@file@percent }
\newlabel{fig:mv13model:att}{{6.7}{166}{Predicted attachment proportions by source activation at ambiguous and unambiguous attachments}{figure.6.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Discussion}{166}{subsection.6.3.4}\protected@file@percent }
\citation{MalsburgVasishth2013}
\citation{SwetsDesmetClifton2008}
\citation{Staub2010a}
\citation{MalsburgVasishth2013}
\newlabel{eq:utility}{{6.1}{168}{Discussion}{equation.6.3.1}{}}
\citation{Staub2010a}
\citation{MalsburgVasishth2013}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}General Discussion}{169}{section.6.4}\protected@file@percent }
\citation{just2002haw,varma2016caps}
\citation{Jurafsky1996,BostonHaleVasishth2011}
\citation{McElree2000,McElree2006}
\citation{LewisVasishthVanDyke2006,parkervandykeshvartsman2017}
\citation{NicenboimRetrieval2018}
\citation{McElree2000,VanDyke2006,McElree2006}
\citation{McElree1993}
\citation{VasishthEtAlTiCS2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Competing accounts of interference in sentence processing}{171}{chapter.7}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c05}{{7}{171}{Competing accounts of interference in sentence processing}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}The direct-access model}{171}{section.7.1}\protected@file@percent }
\citation{LewisVasishthVanDyke2006}
\citation{NicenboimRetrieval2018}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces A schematic illustration of the direct-access model. For sentences like (\ref  {ex:vandyke07}a), the model assumes that once a search is initiated in memory using a set of retrieval cues (here, subject and animate), one of two events can happen. Either the correct item is retrieved from memory, or the incorrect item, which matches some of the retrieval cues, is misretrieved. In the case of a misretrieval, either processing ends with a misretrieval, or a reanalysis step is initiated that leads to a correct retrieval. This reanalysis step costs time, and therefore leads to slowdowns in processing on average.}}{172}{figure.7.1}\protected@file@percent }
\newlabel{fig:da}{{7.1}{172}{A schematic illustration of the direct-access model. For sentences like (\ref {ex:vandyke07}a), the model assumes that once a search is initiated in memory using a set of retrieval cues (here, subject and animate), one of two events can happen. Either the correct item is retrieved from memory, or the incorrect item, which matches some of the retrieval cues, is misretrieved. In the case of a misretrieval, either processing ends with a misretrieval, or a reanalysis step is initiated that leads to a correct retrieval. This reanalysis step costs time, and therefore leads to slowdowns in processing on average}{figure.7.1}{}}
\newlabel{ex:vandyke07}{{38}{172}{The direct-access model}{Item.125}{}}
\citation{mclachlan2004finite,fruhwirth2006finite}
\citation{NicenboimRetrieval2018}
\citation{NicenboimRetrieval2018}
\citation{NicenboimRetrieval2018}
\citation{stan:2017}
\citation{nicenboimexploratory}
\newlabel{eq:mixmodsr2}{{7.1}{174}{The direct-access model}{equation.7.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Comparing the predictive performance of the models}{174}{section.7.2}\protected@file@percent }
\newlabel{nicenboiminhint}{{7.2}{174}{Comparing the predictive performance of the models}{section.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Inhibitory interference}{174}{subsection.7.2.1}\protected@file@percent }
\newlabel{ex:exp1}{{39}{174}{Inhibitory interference}{Item.126}{}}
\newlabel{ex:HI}{{39a}{174}{Inhibitory interference}{Item.127}{}}
\newlabel{ex:LI}{{39b}{174}{Inhibitory interference}{Item.128}{}}
\citation{nicenboimexploratory}
\citation{NicenboimRetrieval2018}
\citation{vehtari2012survey,vehtari2016LOOwaic}
\citation{nicenboimexploratory}
\newlabel{ex:multip-q}{{40}{175}{Inhibitory interference}{Item.129}{}}
\newlabel{ex:answers}{{41}{175}{Inhibitory interference}{Item.133}{}}
\citation{NicenboimRetrieval2018}
\citation{nicenboimexploratory}
\citation{grodner}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Relative clauses in Chinese}{176}{subsection.7.2.2}\protected@file@percent }
\newlabel{rchinese}{{7.2.2}{176}{Relative clauses in Chinese}{subsection.7.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces A comparison of observed sample means with the posterior predictive distributions of the activation-based model, and the direct-access model. The figure is adapted from the online materials available from StanCon 2017 conference talk by Bruno Nicenboim and Shravan Vasishth, which are under a CC-BY 4.0 licence.}}{177}{figure.7.2}\protected@file@percent }
\newlabel{fig:daactcomparison}{{7.2}{177}{A comparison of observed sample means with the posterior predictive distributions of the activation-based model, and the direct-access model. The figure is adapted from the online materials available from StanCon 2017 conference talk by Bruno Nicenboim and Shravan Vasishth, which are under a CC-BY 4.0 licence}{figure.7.2}{}}
\newlabel{ex:EnglishRCs}{{42}{177}{Relative clauses in Chinese}{Item.135}{}}
\citation{Gibson2000}
\citation{HsiaoGibson2003}
\citation{gibsonwu}
\citation{VasishthChenLi2013}
\citation{VasishthChenLi2013,WuKaiserVasishth2017,JagerChenLi2015}
\citation{gibsonwu}
\citation{VasishthChenLi2013}
\citation{HsiaoGibson2003}
\citation{VasishthChopinRyderNicenboimCogSci2017}
\newlabel{ex:chineseRCs}{{43}{178}{Relative clauses in Chinese}{Item.138}{}}
\citation{VasishthChopinRyderNicenboimCogSci2017}
\citation{gibsonwu}
\citation{gibsonwu}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Model comparison using K-fold cross-validation for the Gibson and Wu 2013 data. Shown are the differences in $\mathaccent "0362\relax {elpd}$, along with standard errors of the differences. In a comparison between a model A vs B, a positive $\Delta \mathaccent "0362\relax {elpd}$ favours model A.}}{179}{table.7.1}\protected@file@percent }
\newlabel{tab:modcompgibsonwu}{{7.1}{179}{Model comparison using K-fold cross-validation for the Gibson and Wu 2013 data. Shown are the differences in $\widehat {elpd}$, along with standard errors of the differences. In a comparison between a model A vs B, a positive $\Delta \widehat {elpd}$ favours model A}{table.7.1}{}}
\citation{VasishthChenLi2013}
\citation{LissonEtAl2020}
\citation{VasishthEtAlTiCS2019}
\citation{NicenboimRetrieval2018}
\citation{VillataFranck}
\citation{VasishthEtAlICCM2017}
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces Model comparison using k-fold cross-validation for the Vasishth et al.\ (2013) replication of the Gibson and Wu (2013) study.}}{180}{table.7.2}\protected@file@percent }
\newlabel{tab:modcompgibsonwurep}{{7.2}{180}{Model comparison using k-fold cross-validation for the Vasishth et al.\ (2013) replication of the Gibson and Wu (2013) study}{table.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Discussion}{180}{subsection.7.2.3}\protected@file@percent }
\citation{JaegerEngelmannVasishth2017}
\citation{patson2016misinterpretations}
\citation{WagersLauPhillips2009}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Encoding interference in agreement attraction}{181}{section.7.3}\protected@file@percent }
\newlabel{encint}{{7.3}{181}{Encoding interference in agreement attraction}{section.7.3}{}}
\newlabel{c07example1}{{44a}{181}{Encoding interference in agreement attraction}{Item.142}{}}
\newlabel{c07example2}{{44b}{181}{Encoding interference in agreement attraction}{Item.143}{}}
\citation{VillataFranck}
\citation{Nairne1990}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}An evaluation of the Nairne proposal}{183}{subsection.7.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Model comparison}{184}{subsection.7.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7.3}{\ignorespaces Comparison of the 10 sets of hierarchical models. Shown are the differences in $\mathaccent "0362\relax {elpd}$ between (a) the standard hierarchical model and the homogeneous variance mixture model; (b) the feature percolation model and the homogeneous variance mixture model; and (c) the homogeneous vs.\ heterogeneous variance mixture model. Also shown are standard errors for each comparison. If the difference in $\mathaccent "0362\relax {elpd}$ is positive, this is evidence in favour of the second model. The pairwise model comparisons are transitive. These comparisons show that the heterogeneous variance mixture model has the best predictive performance.}}{185}{table.7.3}\protected@file@percent }
\newlabel{tab:allcomparisons}{{7.3}{185}{Comparison of the 10 sets of hierarchical models. Shown are the differences in $\widehat {elpd}$ between (a) the standard hierarchical model and the homogeneous variance mixture model; (b) the feature percolation model and the homogeneous variance mixture model; and (c) the homogeneous vs.\ heterogeneous variance mixture model. Also shown are standard errors for each comparison. If the difference in $\widehat {elpd}$ is positive, this is evidence in favour of the second model. The pairwise model comparisons are transitive. These comparisons show that the heterogeneous variance mixture model has the best predictive performance}{table.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}Discussion}{185}{subsection.7.3.3}\protected@file@percent }
\citation{VillataFranck}
\citation{nicenboimexploratory}
\citation{JaegerEngelmannVasishth2017}
\citation{taboretal04}
\citation{SwetsDesmetClifton2008,MalsburgVasishth2013}
\citation{CunningsSturt2018}
\@writefile{toc}{\contentsline {subsubsection}{Some limitations}{186}{section*.28}\protected@file@percent }
\citation{ALV2020,JaegerMertzenVanDykeVasishth2019}
\citation{PaapeEtAlMPT2020}
\citation{platt1964strong}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Summary}{187}{section.7.4}\protected@file@percent }
\citation{PatilEtAl2016}
\citation{Caplan:2009}
\citation{Grodzinsky:1995,Grodzinsky:2000,Grodzinsky:2006a}
\citation{Beretta:1998,Hickok:1995,Mauner:1993}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Modelling sentence comprehension deficits in aphasia}{188}{chapter.8}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c06}{{8}{188}{Modelling sentence comprehension deficits in aphasia}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Theories and models of sentence comprehension deficits}{189}{section.8.1}\protected@file@percent }
\newlabel{alternativeexplanations}{{8.1}{189}{Theories and models of sentence comprehension deficits}{section.8.1}{}}
\citation{Haarmann-Kolk-1991}
\citation{Kolk-vanGrunsven-1985}
\citation{Haarmann-Kolk-1991}
\citation{Schwartz-EtAl-1980}
\citation{Kolk-vanGrunsven-1985}
\citation{Haarmann-EtAl-1997}
\citation{Just1980}
\citation{Miyake-EtAl-1994}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Timing deficit}{190}{subsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Reduction in memory}{190}{subsection.8.1.2}\protected@file@percent }
\citation{Caplan-Et-Al-1985}
\citation{Kolk-vanGrunsven-1985}
\citation{Gigley-1986}
\citation{Kempen-Vosse-1989,vossekempen2000}
\citation{Crescentini-Stocco-2005}
\citation{Haarmann-EtAl-1997}
\citation{Caplan:2007}
\citation{Caplan:2003,Caplan:1995}
\citation{hanneetal11}
\citation{Choy:2010,Dickey2009,Dickey:2007a,hanneetal11,Meyer2012,ThompsonChoy-2009}
\citation{Cho2010,Lee2011a,Lee2011}
\citation{Dickey:2007a,Thompson2004}
\citation{Dickey:2007a}
\citation{Avrutin:2006}
\citation{Dickey:2007a}
\citation{Dickey2006,Dickey2009}
\citation{BurkhardtEtAl2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Intermittent deficiency}{192}{subsection.8.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Weakened syntax}{192}{subsection.8.1.4}\protected@file@percent }
\citation{hanneetal11}
\citation{Meyer2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}Slow syntax}{193}{subsection.8.1.5}\protected@file@percent }
\citation{ThompsonChoy-2009}
\citation{hagoort1996lexical}
\citation{SwaabEtAl-1997}
\citation{Prather:1997}
\citation{Zurif1994}
\citation{Swinney1996,Love2001}
\citation{Love:2008}
\citation{Love:2008}
\citation{Ferrill2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}Lexical integration deficit}{194}{subsection.8.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.7}Lexical access deficits}{194}{subsection.8.1.7}\protected@file@percent }
\citation{ThompsonChoy-2009,Choy:2010,Meyer2012}
\citation{ThompsonChoy-2009}
\citation{Choy:2010}
\citation{Dickey:2007a}
\citation{ThompsonChoy-2009}
\citation{Love:2008}
\citation{Dickey:2007a}
\citation{Yee2008}
\citation{Blumstein1998}
\citation{vandykelewis03}
\citation{JustCarpenter1992}
\citation{taboretal04,VasishthSuckowLewis2010,FrankTrompenaarsVasishth2015}
\citation{WagersLauPhillips2009,BadeckerStraub2002,VasishthBruessowLewis2008,CunningsFelser2013,PatilVasishthLewis2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.8}A comparison of theories of impaired processing, and their relation to theories of unimpaired processing}{196}{subsection.8.1.8}\protected@file@percent }
\citation{Hale2001,Levy2008}
\citation{clark12}
\citation{DanemanCarpenter1980,JustCarpenter1992}
\citation{CaplanWaters2005}
\citation{novick2005cognitive}
\citation{MaetzigEtAltopics2018}
\citation{PatilEtAl2016}
\citation{hanneetal11}
\citation{hanneetal11}
\citation{hanneetal11}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces A matrix showing how the models relate to each other along dimensions of the three working-memory related events---delays, forgetting (or failure to retrieve), mis-retrieval---that have been investigated in sentence comprehension research.}}{198}{table.8.1}\protected@file@percent }
\newlabel{modelcomparison}{{8.1}{198}{A matrix showing how the models relate to each other along dimensions of the three working-memory related events---delays, forgetting (or failure to retrieve), mis-retrieval---that have been investigated in sentence comprehension research}{table.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Modelling individual-level differences}{198}{section.8.2}\protected@file@percent }
\citation{BurkhardtEtAl2003}
\citation{CaplanEtAl2015}
\citation{Caplan2012}
\citation{LewisVasishth2005}
\citation{PatilEtAl2016}
\citation{LewisVasishth2005}
\citation{hanneetal11}
\citation{PatilEtAl2016}
\citation{CaplanEtAl2015}
\citation{PatilEtAl2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Mapping ACT-R parameters to sources of deficits}{200}{subsection.8.2.1}\protected@file@percent }
\newlabel{eq:1}{{8.1}{200}{Mapping ACT-R parameters to sources of deficits}{equation.8.2.1}{}}
\citation{DailyEtAl2001}
\newlabel{eq:2}{{8.2}{201}{Mapping ACT-R parameters to sources of deficits}{equation.8.2.2}{}}
\citation{CaplanEtAl2015}
\citation{CaplanEtAl2015}
\citation{JustCarpenter1992}
\citation{LewisVasishth2005}
\citation{LewisVasishth2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Simulations}{202}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Materials}{202}{section*.29}\protected@file@percent }
\newlabel{caplanmaterials}{{8.2.2}{202}{Materials}{section*.29}{}}
\citation{CaplanEtAl2015}
\@writefile{toc}{\contentsline {subsubsection}{Parameter estimation}{203}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Results}{203}{subsection.8.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Marginal distributions of each of the three parameters for subject relatives in controls (solid lines) vs.\ IWA (dotted lines). The vertical line shows the default setting for the respective parameter.}}{204}{figure.8.1}\protected@file@percent }
\newlabel{fig:margSR}{{8.1}{204}{Marginal distributions of each of the three parameters for subject relatives in controls (solid lines) vs.\ IWA (dotted lines). The vertical line shows the default setting for the respective parameter}{figure.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Marginal distributions of each of the three parameters for object relatives in controls (solid lines) vs.\ IWA (dotted lines). The vertical line shows the default setting for the respective parameter.}}{204}{figure.8.2}\protected@file@percent }
\newlabel{fig:margOR}{{8.2}{204}{Marginal distributions of each of the three parameters for object relatives in controls (solid lines) vs.\ IWA (dotted lines). The vertical line shows the default setting for the respective parameter}{figure.8.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Distribution of parameter value estimates}{204}{section*.31}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8.2}{\ignorespaces The number of participants in subject / object relatives (SR/OR) for which non-default parameter values were predicted, in the subject vs.\ object relative tasks, respectively; for goal activation (GA), default action time (DAT) and noise (ANS) parameters.}}{204}{table.8.2}\protected@file@percent }
\newlabel{table:normsettingsSO}{{8.2}{204}{The number of participants in subject / object relatives (SR/OR) for which non-default parameter values were predicted, in the subject vs.\ object relative tasks, respectively; for goal activation (GA), default action time (DAT) and noise (ANS) parameters}{table.8.2}{}}
\citation{friedman2001elements}
\citation{CaplanEtAl2015}
\@writefile{toc}{\contentsline {paragraph}{Cluster analysis}{205}{section*.32}\protected@file@percent }
\citation{MaetzigEtAltopics2018}
\citation{PatilEtAl2016}
\citation{PatilEtAl2016}
\@writefile{lot}{\contentsline {table}{\numberline {8.3}{\ignorespaces Discrimination ability of hierarchical clustering on the combined data for subject / object relatives. Numbers in bold show the number of correctly clustered data points. The bottom row shows the percentage accuracy.}}{206}{table.8.3}\protected@file@percent }
\newlabel{table:hclustSO}{{8.3}{206}{Discrimination ability of hierarchical clustering on the combined data for subject / object relatives. Numbers in bold show the number of correctly clustered data points. The bottom row shows the percentage accuracy}{table.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Discussion}{206}{subsection.8.2.4}\protected@file@percent }
\citation{CaplanEtAl2015}
\citation{PreglaTR,PreglaBL}
\citation{NicenboimRetrieval2018}
\citation{PatilEtAl2016}
\citation{CaplanEtAl2015}
\citation{CaplanEtAl2015}
\citation{LewisVasishth2005}
\citation{CaplanEtAl2015}
\citation{LissonEtAl2020}
\citation{CaplanEtAl2015}
\citation{CaplanEtAl2015}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Competing models of retrieval in aphasia}{209}{section.8.3}\protected@file@percent }
\newlabel{c06:competing}{{8.3}{209}{Competing models of retrieval in aphasia}{section.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Materials}{209}{subsection.8.3.1}\protected@file@percent }
\newlabel{ex-caplan}{{8.3.1}{209}{Materials}{subsection.8.3.1}{}}
\newlabel{SR}{{45a}{209}{Materials}{Item.156}{}}
\newlabel{OR}{{45b}{209}{Materials}{Item.157}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.2}Results and discussion}{209}{subsection.8.3.2}\protected@file@percent }
\citation{CaplanEtAl2015}
\citation{MaetzigEtAltopics2018}
\citation{LissonEtAl2020}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces Shown are the differences between the two models in expected pointwise log density for each data-point. Points above the zero line show an advantage for the activation-based model, and points below the zero line an advantage for the direct-access model. The darkness in the hexagons represents density, with darker hexagons representing more dense data-points. The figure is under a CC by 4.0 license, doi:10.6084/m9.figshare.12114075.v1.}}{210}{figure.8.3}\protected@file@percent }
\newlabel{fig:paulaplot}{{8.3}{210}{Shown are the differences between the two models in expected pointwise log density for each data-point. Points above the zero line show an advantage for the activation-based model, and points below the zero line an advantage for the direct-access model. The darkness in the hexagons represents density, with darker hexagons representing more dense data-points. The figure is under a CC by 4.0 license, doi:10.6084/m9.figshare.12114075.v1}{figure.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Concluding remarks}{210}{section.8.4}\protected@file@percent }
\citation{bdactrbook}
\citation{YadavEtAlAMLaP2020}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Future directions}{212}{chapter.9}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c09}{{9}{212}{Future directions}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Developing implemented computational models}{212}{section.9.1}\protected@file@percent }
\citation{JaegerMertzenVanDykeVasishth2019,VasishthMertzenJaegerGelman2018,Mertzenretro,Mertzenproretro,MertzenEtAlAMLaP2019}
\citation{JaegerEngelmannVasishth2017,BuerkiEtAl2020}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}An excessive focus on average behaviour}{213}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Creating higher-precision benchmark data-sets for model evaluation and comparison}{213}{section.9.3}\protected@file@percent }
\citation{rp}
\citation{NicenboimRetrieval2018,LissonEtAl2020}
\citation{SmithFranckTaborCogSci2018}
\citation{smith2019smithvasishthfeatures}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Developing better criteria for evaluating model fit}{214}{section.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.5}In closing}{214}{section.9.5}\protected@file@percent }
\bibdata{sccpcorrected}
\bibcite{anderson1974retrieval}{{1}{1974}{{Anderson}}{{}}}
\bibcite{AndersonEtAl2004}{{2}{2004}{{Anderson {et~al.}}}{{}}}
\bibcite{AndersonLebiere1998}{{3}{1998}{{Anderson and Lebiere}}{{}}}
\bibcite{Ariel1990}{{4}{1990}{{Ariel}}{{}}}
\bibcite{Arnold2007}{{5}{2007}{{Arnold}}{{}}}
\bibcite{Arnold2001}{{6}{2001}{{Arnold}}{{}}}
\bibcite{ALV2020}{{7}{2020}{{Avetisyan {et~al.}}}{{}}}
\bibcite{Avrutin:2006}{{8}{2006}{{Avrutin}}{{}}}
\bibcite{Baayen1993}{{9}{1993}{{Baayen {et~al.}}}{{}}}
\bibcite{BaayenMilinDJurdjevic2011}{{10}{2011}{{Baayen {et~al.}}}{{}}}
\bibcite{Baddeley2003}{{11}{2003}{{Baddeley}}{{}}}
\bibcite{BaddeleyHitch1974}{{12}{1974}{{Baddeley and Hitch}}{{}}}
\bibcite{BadeckerStraub2002}{{13}{2002}{{Badecker and Straub}}{{}}}
\bibcite{bader2016complex}{{14}{2016}{{Bader}}{{}}}
\bibcite{Bartek2011}{{15}{2011}{{Bartek {et~al.}}}{{}}}
\@writefile{toc}{\setcounter {tocdepth}{0}}
\@writefile{toc}{\vspace  {\baselineskip }}
\@writefile{toc}{\contentsline {section}{Bibliography}{217}{section.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {schapter}{Bibliography}{217}{appendix*.33}\protected@file@percent }
\bibcite{Beretta:1998}{{16}{1998}{{Beretta and Munn}}{{}}}
\bibcite{berman2009search}{{17}{2009}{{Berman {et~al.}}}{{}}}
\bibcite{BerwickWeinberg1984}{{18}{1984}{{Berwick and Weinberg}}{{}}}
\bibcite{BicknellLevy2010a}{{19}{2010}{{Bicknell and Levy}}{{}}}
\bibcite{Binder2001}{{20}{2001}{{Binder {et~al.}}}{{}}}
\bibcite{norm}{{21}{2014}{{Blastland and Spiegelhalter}}{{}}}
\bibcite{blitzstein2014introduction}{{22}{2014}{{Blitzstein and Hwang}}{{}}}
\bibcite{Blumstein1998}{{23}{1998}{{Blumstein {et~al.}}}{{}}}
\bibcite{Booth2013}{{24}{2013}{{Booth and Weger}}{{}}}
\bibcite{jemrsurprisal}{{25}{2008}{{Boston {et~al.}}}{{}}}
\bibcite{BostonHaleVasishth2011}{{26}{2011}{{Boston {et~al.}}}{{}}}
\bibcite{bdactrbook}{{27}{2020}{{Brasoveanu and Dotla{\v c}il}}{{}}}
\bibcite{Brennan1995}{{28}{1995}{{Brennan}}{{}}}
\bibcite{brown}{{29}{1958}{{Brown}}{{}}}
\bibcite{Budiu2004}{{30}{2004}{{Budiu and Anderson}}{{}}}
\bibcite{BurkhardtEtAl2003}{{31}{2003}{{Burkhardt {et~al.}}}{{}}}
\bibcite{BuerkiEtAl2020}{{32}{2020}{{B{\"u}rki {et~al.}}}{{}}}
\bibcite{busemeyer2010cognitive}{{33}{2010}{{Busemeyer and Diederich}}{{}}}
\bibcite{bybee2006usage}{{34}{2006}{{Bybee}}{{}}}
\bibcite{Caplan:2009}{{35}{2009}{{Caplan}}{{}}}
\bibcite{Caplan2012}{{36}{2012}{{Caplan}}{{}}}
\bibcite{Caplan:2003}{{37}{2003}{{Caplan and Waters}}{{}}}
\bibcite{CaplanWaters2005}{{38}{2005}{{Caplan and Waters}}{{}}}
\bibcite{Caplan:1995}{{39}{1995}{{Caplan and Waters}}{{}}}
\bibcite{Caplan-Et-Al-1985}{{40}{1985}{{Caplan {et~al.}}}{{}}}
\bibcite{Caplan:2007}{{41}{2007}{{Caplan {et~al.}}}{{}}}
\bibcite{CaplanEtAl2015}{{42}{2015}{{Caplan {et~al.}}}{{}}}
\bibcite{CarminatiNella2005}{{43}{2005}{{Carminati}}{{}}}
\bibcite{stan:2017}{{44}{2016}{{Carpenter {et~al.}}}{{}}}
\bibcite{CarreirasClifton1993}{{45}{1993}{{Carreiras and Clifton}}{{}}}
\bibcite{carreiras2010subject}{{46}{2010}{{Carreiras {et~al.}}}{{}}}
\bibcite{Chafe1976}{{47}{1976}{{Chafe}}{{}}}
\bibcite{cho2017incremental}{{48}{2017}{{Cho {et~al.}}}{{}}}
\bibcite{Cho2010}{{49}{2010}{{Cho and Thompson}}{{}}}
\bibcite{chomsky1981lectures}{{50}{1981}{{Chomsky}}{{}}}
\bibcite{Chomsky1986}{{51}{1986}{{Chomsky}}{{}}}
\bibcite{Choy:2010}{{52}{2010}{{Choy and Thompson}}{{}}}
\bibcite{clark12}{{53}{2012}{{Clark}}{{}}}
\bibcite{cohen1962statistical}{{54}{1962}{{Cohen}}{{}}}
\bibcite{Cowan2001}{{55}{2001}{{Cowan}}{{}}}
\bibcite{CowlesWalenskiKluender2007}{{56}{2007}{{Cowles {et~al.}}}{{}}}
\bibcite{Crescentini-Stocco-2005}{{57}{2005}{{Crescentini and Stocco}}{{}}}
\bibcite{CunningsFelser2013}{{58}{2013}{{Cunnings and Felser}}{{}}}
\bibcite{CunningsSturt2018}{{59}{2018}{{Cunnings and Sturt}}{{}}}
\bibcite{DailyEtAl2001}{{60}{2001}{{Daily {et~al.}}}{{}}}
\bibcite{DanemanCarpenter1980}{{61}{1980}{{Daneman and Carpenter}}{{}}}
\bibcite{Demberg2008}{{62}{2008}{{Demberg and Keller}}{{}}}
\bibcite{Dickey2006}{{63}{2006}{{Dickey and Thompson}}{{}}}
\bibcite{Dickey2009}{{64}{2009}{{Dickey and Thompson}}{{}}}
\bibcite{Dickey:2007a}{{65}{2007}{{Dickey {et~al.}}}{{}}}
\bibcite{Dillon2011}{{66}{2011}{{Dillon}}{{}}}
\bibcite{DillonMishlerSloggett2013}{{67}{2013}{{Dillon {et~al.}}}{{}}}
\bibcite{DuBois2003}{{68}{2003}{{Du Bois}}{{}}}
\bibcite{EberhardCuttingBock2005}{{69}{2005}{{Eberhard {et~al.}}}{{}}}
\bibcite{Elman:2005p2}{{70}{2004}{{Elman {et~al.}}}{{}}}
\bibcite{EngbertEtAl2002}{{71}{2002}{{Engbert {et~al.}}}{{}}}
\bibcite{EngbertNuthmannRichter2005}{{72}{2005a}{{Engbert {et~al.}}}{{}}}
\bibcite{Engbert2005}{{73}{2005b}{{Engbert {et~al.}}}{{}}}
\bibcite{engelmann:phd}{{74}{2016}{{Engelmann}}{{}}}
\bibcite{EngelmannVasishth2009}{{75}{2009}{{Engelmann and Vasishth}}{{}}}
\bibcite{Engelmanna}{{76}{2013}{{Engelmann {et~al.}}}{{}}}
\bibcite{EngelmannJaegerVasishth2019}{{77}{2020}{{Engelmann {et~al.}}}{{}}}
\bibcite{whymodel}{{78}{2008}{{Epstein}}{{}}}
\bibcite{farrell2018computational}{{79}{2018}{{Farrell and Lewandowsky}}{{}}}
\bibcite{FerreiraFerraroBailey2002}{{80}{2002}{{Ferreira {et~al.}}}{{}}}
\bibcite{Ferrill2012}{{81}{2012}{{Ferrill {et~al.}}}{{}}}
\bibcite{Francis1982}{{82}{1982}{{Francis and Kucera}}{{}}}
\bibcite{Frank2009}{{83}{2009}{{Frank}}{{}}}
\bibcite{FrankTrompenaarsVasishth2015}{{84}{2015}{{Frank {et~al.}}}{{}}}
\bibcite{Frazier79}{{85}{1979}{{Frazier}}{{}}}
\bibcite{frazier85}{{86}{1985}{{Frazier}}{{}}}
\bibcite{Frazier1987}{{87}{1987a}{{Frazier}}{{}}}
\bibcite{Frazier1987a}{{88}{1987b}{{Frazier}}{{}}}
\bibcite{FrazierClifton1997}{{89}{1997}{{Frazier and Clifton}}{{}}}
\bibcite{FrazierRayner1982}{{90}{1982}{{Frazier and Rayner}}{{}}}
\bibcite{Freedman1984}{{91}{1984}{{Freedman {et~al.}}}{{}}}
\bibcite{friedman2001elements}{{92}{2001}{{Friedman {et~al.}}}{{}}}
\bibcite{fruhwirth2006finite}{{93}{2006}{{Fr{\"u}hwirth-Schnatter}}{{}}}
\bibcite{FukumuraVanGompel2011}{{94}{2011}{{Fukumura and {van Gompel}}}{{}}}
\bibcite{GelmanCarlin2014}{{95}{2014}{{Gelman and Carlin}}{{}}}
\bibcite{Gelman14}{{96}{2014}{{Gelman {et~al.}}}{{}}}
\bibcite{GennariMacDonald2009}{{97}{2009}{{Gennari and MacDonald}}{{}}}
\bibcite{GernsbacherHargreaves1988}{{98}{1988}{{Gernsbacher and Hargreaves}}{{}}}
\bibcite{Gibson1998}{{99}{1998}{{Gibson}}{{}}}
\bibcite{Gibson2000}{{100}{2000}{{Gibson}}{{}}}
\bibcite{gibsonthomas97}{{101}{1997}{{Gibson and Thomas}}{{}}}
\bibcite{gibsonwu}{{102}{2013}{{Gibson and Wu}}{{}}}
\bibcite{gibsonetal96}{{103}{1996}{{Gibson {et~al.}}}{{}}}
\bibcite{GibsonDesmetGrodner2005}{{104}{2005}{{Gibson {et~al.}}}{{}}}
\bibcite{Gigley-1986}{{105}{1986}{{Gigley}}{{}}}
\bibcite{greenmitchellJML06}{{106}{2006}{{Green and Mitchell}}{{}}}
\bibcite{grodner}{{107}{2005}{{Grodner and Gibson}}{{}}}
\bibcite{Grodzinsky:1995}{{108}{1995}{{Grodzinsky}}{{}}}
\bibcite{Grodzinsky:2000}{{109}{2000}{{Grodzinsky}}{{}}}
\bibcite{Grodzinsky:2006a}{{110}{2006}{{Grodzinsky}}{{}}}
\bibcite{GroszJoshiWeinstein1995}{{111}{1995a}{{Grosz {et~al.}}}{{}}}
\bibcite{grosz95}{{112}{1995b}{{Grosz {et~al.}}}{{}}}
\bibcite{Haarmann-Kolk-1991}{{113}{1991}{{Haarmann and Kolk}}{{}}}
\bibcite{Haarmann-EtAl-1997}{{114}{1997}{{Haarmann {et~al.}}}{{}}}
\bibcite{hagoort1996lexical}{{115}{1996}{{Hagoort {et~al.}}}{{}}}
\bibcite{Hale2001}{{116}{2001}{{Hale}}{{}}}
\bibcite{Hale2011}{{117}{2011}{{Hale}}{{}}}
\bibcite{hammerly2019grammaticality}{{118}{2019}{{Hammerly {et~al.}}}{{}}}
\bibcite{hanneetal11}{{119}{2011}{{Hanne {et~al.}}}{{}}}
\bibcite{Hickok:1995}{{120}{1995}{{Hickok and Avrutin}}{{}}}
\bibcite{hoenigheisey}{{121}{2001}{{Hoenig and Heisey}}{{}}}
\bibcite{hofmeister07}{{122}{2007}{{Hofmeister}}{{}}}
\bibcite{hofmeister2011representational}{{123}{2011}{{Hofmeister}}{{}}}
\bibcite{HofmeisterVasishth2014}{{124}{2014}{{Hofmeister and Vasishth}}{{}}}
\bibcite{HsiaoGibson2003}{{125}{2003}{{Hsiao and Gibson}}{{}}}
\bibcite{HsiaoMacDonald2013}{{126}{2013}{{Hsiao and MacDonald}}{{}}}
\bibcite{HusainEtAl2014}{{127}{2014}{{Husain {et~al.}}}{{}}}
\bibcite{HusainVasishthNarayanan2015}{{128}{2015}{{Husain {et~al.}}}{{}}}
\bibcite{Inhoff:2005p140}{{129}{2005}{{Inhoff and Weger}}{{}}}
\bibcite{JaegerEngelmannVasishth2015}{{130}{2015}{{J\"{a}ger {et~al.}}}{{}}}
\bibcite{JagerChenLi2015}{{131}{2015}{{J{\"a}ger {et~al.}}}{{}}}
\bibcite{JaegerEngelmannVasishth2017}{{132}{2017}{{J{\"a}ger {et~al.}}}{{}}}
\bibcite{JaegerMertzenVanDykeVasishth2019}{{133}{2020}{{J\"ager {et~al.}}}{{}}}
\bibcite{Jurafsky1996}{{134}{1996}{{Jurafsky}}{{}}}
\bibcite{Just1980}{{135}{1980}{{Just and Carpenter}}{{}}}
\bibcite{JustCarpenter1992}{{136}{1992}{{Just and Carpenter}}{{}}}
\bibcite{just2002haw}{{137}{2002}{{Just and Varma}}{{}}}
\bibcite{justetal99}{{138}{1999}{{Just {et~al.}}}{{}}}
\bibcite{just2007organization}{{139}{2007}{{Just and Varma}}{{}}}
\bibcite{KeenanComrie1977}{{140}{1977}{{Keenan and Comrie}}{{}}}
\bibcite{Kempen-Vosse-1989}{{141}{1989}{{Kempen and Vosse}}{{}}}
\bibcite{KemperCrowKemtes2004}{{142}{2004}{{Kemper {et~al.}}}{{}}}
\bibcite{keppelunderwood}{{143}{1962}{{Keppel and Underwood}}{{}}}
\bibcite{kidd2018individual}{{144}{2018}{{Kidd {et~al.}}}{{}}}
\bibcite{KingJust1991}{{145}{1991}{{King and Just}}{{}}}
\bibcite{Kliegl2004}{{146}{2004}{{Kliegl {et~al.}}}{{}}}
\bibcite{Kolk-vanGrunsven-1985}{{147}{1985}{{Kolk and Van~Grunsven}}{{}}}
\bibcite{Konieczny2000}{{148}{2000}{{Konieczny}}{{}}}
\bibcite{Konieczny2003}{{149}{2003}{{Konieczny and D\"{o}ring}}{{}}}
\bibcite{kruschke2014doing}{{150}{2014}{{Kruschke}}{{}}}
\bibcite{KushPhillips2014}{{151}{2014}{{Kush and Phillips}}{{}}}
\bibcite{KwonGordonLee2010}{{152}{2010}{{Kwon {et~al.}}}{{}}}
\bibcite{lago2015agreement}{{153}{2015}{{Lago {et~al.}}}{{}}}
\bibcite{laird2012soar}{{154}{2012}{{Laird}}{{}}}
\bibcite{langacker1987foundations}{{155}{1987}{{Langacker}}{{}}}
\bibcite{Lee2011a}{{156}{2011a}{{Lee and Thompson}}{{}}}
\bibcite{Lee2011}{{157}{2011b}{{Lee and Thompson}}{{}}}
\bibcite{lee2014bayesian}{{158}{2014}{{Lee and Wagenmakers}}{{}}}
\bibcite{Legge2002}{{159}{2002}{{Legge {et~al.}}}{{}}}
\bibcite{Levy2008}{{160}{2008}{{Levy}}{{}}}
\bibcite{LevyKeller2013}{{161}{2013}{{Levy and Keller}}{{}}}
\bibcite{levy2012processing}{{162}{2012}{{Levy {et~al.}}}{{}}}
\bibcite{levyfedgibsonRussian}{{163}{2013}{{Levy {et~al.}}}{{}}}
\bibcite{LewandowskyGeigerOberauer2008}{{164}{2008}{{Lewandowsky {et~al.}}}{{}}}
\bibcite{lewis:phd}{{165}{1993}{{Lewis}}{{}}}
\bibcite{lewis:magical}{{166}{1996}{{Lewis}}{{}}}
\bibcite{lewiscogmodsym}{{167}{2000}{{Lewis}}{{}}}
\bibcite{LewisVasishth2005}{{168}{2005}{{Lewis and Vasishth}}{{}}}
\bibcite{LewisVasishthVanDyke2006}{{169}{2006}{{Lewis {et~al.}}}{{}}}
\bibcite{LinBever2006}{{170}{2006}{{Lin and Bever}}{{}}}
\bibcite{linzenuncertainty}{{171}{2016}{{Linzen and Jaeger}}{{}}}
\bibcite{linzen2018distinct}{{172}{2018}{{Linzen and Leonard}}{{}}}
\bibcite{LissonEtAl2020}{{173}{2021}{{Liss{\'o}n {et~al.}}}{{}}}
\bibcite{LogacevMultiple}{{174}{2015}{{Loga{\v c}ev and Vasishth}}{{}}}
\bibcite{LogacevVasishthQJEP2016}{{175}{2016}{{Loga{\v c}ev and Vasishth}}{{}}}
\bibcite{LogacevVasishth2015}{{176}{2015}{{Loga\v {c}ev and Vasishth}}{{}}}
\bibcite{Love2001}{{177}{2001}{{Love {et~al.}}}{{}}}
\bibcite{Love:2008}{{178}{2008}{{Love {et~al.}}}{{}}}
\bibcite{LovettRederLebiere1999}{{179}{1999}{{Lovett {et~al.}}}{{}}}
\bibcite{lunn2012bugs}{{180}{2012}{{Lunn {et~al.}}}{{}}}
\bibcite{MacDonaldChristiansen2002}{{181}{2002}{{MacDonald and Christiansen}}{{}}}
\bibcite{macdonald1992working}{{182}{1992}{{MacDonald {et~al.}}}{{}}}
\bibcite{MalsburgVasishth2012}{{183}{2012}{{{\Dutchvon {Malsburg}{von der Malsburg}} and Vasishth}}{{}}}
\bibcite{MaetzigEtAltopics2018}{{184}{2018}{{M{\"a}tzig {et~al.}}}{{}}}
\bibcite{Mauner:1993}{{185}{1993}{{Mauner {et~al.}}}{{}}}
\bibcite{McElree1993}{{186}{1993}{{McElree}}{{}}}
\bibcite{McElree2000}{{187}{2000}{{McElree}}{{}}}
\bibcite{McElree2006}{{188}{2006}{{McElree}}{{}}}
\bibcite{McElreeForakerDyer2003}{{189}{2003}{{McElree {et~al.}}}{{}}}
\bibcite{mclachlan2004finite}{{190}{2004}{{McLachlan and Peel}}{{}}}
\bibcite{McRaeSpiveyKnowltonTanenhaus1998}{{191}{1998}{{McRae {et~al.}}}{{}}}
\bibcite{MertzenEtAlAMLaP2019}{{192}{2020a}{{Mertzen {et~al.}}}{{}}}
\bibcite{Mertzenretro}{{193}{2020b}{{Mertzen {et~al.}}}{{}}}
\bibcite{Mertzenproretro}{{194}{2020c}{{Mertzen {et~al.}}}{{}}}
\bibcite{Meseguer2002}{{195}{2002}{{Meseguer {et~al.}}}{{}}}
\bibcite{Meyer2012}{{196}{2012}{{Meyer {et~al.}}}{{}}}
\bibcite{Miller1956}{{197}{1956}{{Miller}}{{}}}
\bibcite{MillerChomsky63}{{198}{1963}{{Miller and Chomsky}}{{}}}
\bibcite{MitchellCuetosCorley1995}{{199}{1995}{{Mitchell {et~al.}}}{{}}}
\bibcite{MitchellEtAl2008}{{200}{2008}{{Mitchell {et~al.}}}{{}}}
\bibcite{Miyake-EtAl-1994}{{201}{1994}{{Miyake {et~al.}}}{{}}}
\bibcite{Nairne1988}{{202}{1988}{{Nairne}}{{}}}
\bibcite{Nairne1990}{{203}{1990}{{Nairne}}{{}}}
\bibcite{Newell1973}{{204}{1973}{{Newell}}{{}}}
\bibcite{Newell1978}{{205}{1978}{{Newell}}{{}}}
\bibcite{NicenboimVasishthStatMeth}{{206}{2016}{{Nicenboim and Vasishth}}{{}}}
\bibcite{NicenboimRetrieval2018}{{207}{2018}{{Nicenboim and Vasishth}}{{}}}
\bibcite{NicenboimEtAlFrontiers2016Capacity}{{208}{2016}{{Nicenboim {et~al.}}}{{}}}
\bibcite{nicenboimexploratory}{{209}{2018}{{Nicenboim {et~al.}}}{{}}}
\bibcite{NicenboimPreactivation2019}{{210}{2020}{{Nicenboim {et~al.}}}{{}}}
\bibcite{NicenboimEtAlBayes2019}{{211}{2021}{{Nicenboim {et~al.}}}{{}}}
\bibcite{Nicol1988}{{212}{1988}{{Nicol}}{{}}}
\bibcite{Nilsson2010}{{213}{2010}{{Nilsson and Nivre}}{{}}}
\bibcite{novick2005cognitive}{{214}{2005}{{Novick {et~al.}}}{{}}}
\bibcite{OakleyOHagan}{{215}{2010}{{Oakley and O'Hagan}}{{}}}
\bibcite{OberauerKliegl2006}{{216}{2006}{{Oberauer and Kliegl}}{{}}}
\bibcite{OberauerLewandowsky2013}{{217}{2013}{{Oberauer and Lewandowsky}}{{}}}
\bibcite{OberauerLewandowsky2014}{{218}{2014}{{Oberauer and Lewandowsky}}{{}}}
\bibcite{ohagan2006uncertain}{{219}{2006}{{O'Hagan {et~al.}}}{{}}}
\bibcite{PaapeEtAlMPT2020}{{220}{2020}{{Paape {et~al.}}}{{}}}
\bibcite{palestro2018likelihood}{{221}{2018}{{Palestro {et~al.}}}{{}}}
\bibcite{parker2019cue}{{222}{2019}{{Parker}}{{}}}
\bibcite{ParkerPhillips2014}{{223}{2014}{{Parker and Phillips}}{{}}}
\bibcite{parker2017reflexive}{{224}{2017}{{Parker and Phillips}}{{}}}
\bibcite{parkervandykeshvartsman2017}{{225}{2017}{{Parker {et~al.}}}{{}}}
\bibcite{Patil2009}{{226}{2009}{{Patil {et~al.}}}{{}}}
\bibcite{PatilVasishthLewis2012}{{227}{2012}{{Patil {et~al.}}}{{}}}
\bibcite{PatilEtAl2016}{{228}{2016a}{{Patil {et~al.}}}{{}}}
\bibcite{PatilVasishthLewis2016}{{229}{2016b}{{Patil {et~al.}}}{{}}}
\bibcite{patson2016misinterpretations}{{230}{2016}{{Patson and Husband}}{{}}}
\bibcite{Pearlmutter1999}{{231}{1999}{{Pearlmutter {et~al.}}}{{}}}
\bibcite{petersonpeterson}{{232}{1959}{{Peterson and Peterson}}{{}}}
\bibcite{PickeringVanGompel2006}{{233}{2006}{{Pickering and {Van Gompel}}}{{}}}
\bibcite{platt1964strong}{{234}{1964}{{Platt}}{{}}}
\bibcite{Prather:1997}{{235}{1997}{{Prather {et~al.}}}{{}}}
\bibcite{PreglaTR}{{236}{2020a}{{Pregla {et~al.}}}{{}}}
\bibcite{PreglaBL}{{237}{2020b}{{Pregla {et~al.}}}{{}}}
\bibcite{R2012}{{238}{2012}{{R Core Team}}{{}}}
\bibcite{R2016}{{239}{2016}{{R Core Team}}{{}}}
\bibcite{raab1962division}{{240}{1962}{{Raab}}{{}}}
\bibcite{Rabe2019}{{241}{2020}{{Rabe {et~al.}}}{{}}}
\bibcite{rabovsky2014simulating}{{242}{2014}{{Rabovsky and McRae}}{{}}}
\bibcite{rasmussen2017left}{{243}{2017}{{Rasmussen and Schuler}}{{}}}
\bibcite{Ratcliff1978}{{244}{1978}{{Ratcliff}}{{}}}
\bibcite{Rayner2000}{{245}{2000}{{Rayner {et~al.}}}{{}}}
\bibcite{Reichle1998}{{246}{1998}{{Reichle {et~al.}}}{{}}}
\bibcite{Reichle2003}{{247}{2003}{{Reichle {et~al.}}}{{}}}
\bibcite{Reichle2006}{{248}{2006}{{Reichle {et~al.}}}{{}}}
\bibcite{ReichleWarrenMcConnell2009}{{249}{2009}{{Reichle {et~al.}}}{{}}}
\bibcite{Reilly2006}{{250}{2006}{{Reilly and Radach}}{{}}}
\bibcite{RescorlaWagner1972}{{251}{1972}{{Rescorla and Wagner}}{{}}}
\bibcite{philip92leftcorner}{{252}{1992}{{Resnik}}{{}}}
\bibcite{richteretal06}{{253}{2006}{{Richter {et~al.}}}{{}}}
\bibcite{rp}{{254}{2000}{{Roberts and Pashler}}{{}}}
\bibcite{SafaviEtAlFrontiers2016}{{255}{2016}{{Safavi {et~al.}}}{{}}}
\bibcite{Salvucci2001}{{256}{2001}{{Salvucci}}{{}}}
\bibcite{SanfordSturt2002}{{257}{2002}{{Sanford and Sturt}}{{}}}
\bibcite{SchadEtAlcontrasts}{{258}{2020a}{{Schad {et~al.}}}{{}}}
\bibcite{SchadEtAlWorkflow}{{259}{2020b}{{Schad {et~al.}}}{{}}}
\bibcite{Schilling1998}{{260}{1998}{{Schilling {et~al.}}}{{}}}
\bibcite{SchneiderAnderson2012}{{261}{2012}{{Schneider and Anderson}}{{}}}
\bibcite{SchriefersFriedericiKuhn1995}{{262}{1995}{{Schriefers {et~al.}}}{{}}}
\bibcite{Schwartz-EtAl-1980}{{263}{1980}{{Schwartz {et~al.}}}{{}}}
\bibcite{SissonABC}{{264}{2019}{{Sisson {et~al.}}}{{}}}
\bibcite{smaldino2017models}{{265}{2017}{{Smaldino}}{{}}}
\bibcite{smith2019smithvasishthfeatures}{{266}{2020}{{Smith and Vasishth}}{{}}}
\bibcite{SmithFranckTaborCogSci2018}{{267}{2018}{{Smith {et~al.}}}{{}}}
\bibcite{spiegelhalter1994bayesian}{{268}{1994}{{Spiegelhalter {et~al.}}}{{}}}
\bibcite{spiegelhalter2004bayesian}{{269}{2004}{{Spiegelhalter {et~al.}}}{{}}}
\bibcite{SpiveyTanenhaus1998}{{270}{1998}{{Spivey and Tanenhaus}}{{}}}
\bibcite{stack2018failure}{{271}{2018}{{Stack {et~al.}}}{{}}}
\bibcite{Staub2010a}{{272}{2010}{{Staub}}{{}}}
\bibcite{Sternberg1966}{{273}{1966}{{Sternberg}}{{}}}
\bibcite{Sternberg1969}{{274}{1969}{{Sternberg}}{{}}}
\bibcite{Sturt2003}{{275}{2003}{{Sturt}}{{}}}
\bibcite{SwaabEtAl-1997}{{276}{1997}{{Swaab {et~al.}}}{{}}}
\bibcite{SwetsDesmetClifton2008}{{277}{2008}{{Swets {et~al.}}}{{}}}
\bibcite{Swinney1996}{{278}{1996}{{Swinney {et~al.}}}{{}}}
\bibcite{taboretal04}{{279}{2004}{{Tabor {et~al.}}}{{}}}
\bibcite{ThompsonChoy-2009}{{280}{2009}{{Thompson and Choy}}{{}}}
\bibcite{Thompson2004}{{281}{2004}{{Thompson {et~al.}}}{{}}}
\bibcite{tomasello2003constructing}{{282}{2003}{{Tomasello}}{{}}}
\bibcite{Traxler2007}{{283}{2007}{{Traxler}}{{}}}
\bibcite{traxler2014trends}{{284}{2014}{{Traxler}}{{}}}
\bibcite{TraxlerPickeringClifton1998}{{285}{1998}{{Traxler {et~al.}}}{{}}}
\bibcite{TraxlerMorrisSeely2002}{{286}{2002}{{Traxler {et~al.}}}{{}}}
\bibcite{TuckerIdrissiAlmeida2015}{{287}{2015}{{Tucker {et~al.}}}{{}}}
\bibcite{VanDyke2007}{{288}{2007}{{Van~Dyke}}{{}}}
\bibcite{VanDykeLewis2003}{{289}{2003}{{Van~Dyke and Lewis}}{{}}}
\bibcite{vanDyke2003}{{290}{2003}{{{Van Dyke} and Lewis}}{{}}}
\bibcite{vandykelewis03}{{291}{2003}{{{Van~Dyke} and Lewis}}{{}}}
\bibcite{vandykemcelree06}{{292}{2006}{{{Van~Dyke} and McElree}}{{}}}
\bibcite{VanDyke2006}{{293}{2006}{{{Van Dyke} and McElree}}{{}}}
\bibcite{VanDykeMcElree2011}{{294}{2011}{{Van~Dyke and McElree}}{{}}}
\bibcite{van2014low}{{295}{2014}{{Van~Dyke {et~al.}}}{{}}}
\bibcite{VanRijVanRijnHendriks2013}{{296}{2013}{{{van~Rij} {et~al.}}}{{}}}
\bibcite{varma2016caps}{{297}{2016}{{Varma}}{{}}}
\bibcite{Vasishth:MScStatistics}{{298}{2015}{{Vasishth}}{{}}}
\bibcite{VasishthMethodsX2019}{{299}{2020}{{Vasishth}}{{}}}
\bibcite{Vasishth2011}{{300}{2011}{{Vasishth and Drenhaus}}{{}}}
\bibcite{VasishthGelman2019}{{301}{2019}{{Vasishth and Gelman}}{{}}}
\bibcite{VasishthLewis2006}{{302}{2006}{{Vasishth and Lewis}}{{}}}
\bibcite{VasishthBruessowLewis2008}{{303}{2008}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthSuckowLewis2010}{{304}{2010}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthChenLi2013}{{305}{2013}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthEtAlICCM2017}{{306}{2017a}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthChopinRyderNicenboimCogSci2017}{{307}{2017b}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthMertzenJaegerGelman2018}{{308}{2018}{{Vasishth {et~al.}}}{{}}}
\bibcite{VasishthEtAlTiCS2019}{{309}{2019}{{Vasishth {et~al.}}}{{}}}
\bibcite{vehtari2012survey}{{310}{2012}{{Vehtari {et~al.}}}{{}}}
\bibcite{vehtari2016LOOwaic}{{311}{2017}{{Vehtari {et~al.}}}{{}}}
\bibcite{VillataFranck}{{312}{2016}{{Villata and Franck}}{{}}}
\bibcite{MalsburgVasishth2011}{{313}{2011}{{{von~der~Malsburg} and Vasishth}}{{}}}
\bibcite{MalsburgVasishth2013}{{314}{2013}{{von~der Malsburg and Vasishth}}{{}}}
\bibcite{MalsburgEtAl2015}{{315}{2015}{{von~der Malsburg {et~al.}}}{{}}}
\bibcite{vossekempen2000}{{316}{2000}{{Vosse and Kempen}}{{}}}
\bibcite{WagersLauPhillips2009}{{317}{2009}{{Wagers {et~al.}}}{{}}}
\bibcite{Warren2007}{{318}{2007}{{Warren and McConnell}}{{}}}
\bibcite{warrengibson05}{{319}{2005}{{Warren and Gibson}}{{}}}
\bibcite{pvals}{{320}{2016}{{Wasserstein and Lazar}}{{}}}
\bibcite{WatkinsWatkins1975}{{321}{1975}{{Watkins and Watkins}}{{}}}
\bibcite{waughnorman}{{322}{1965}{{Waugh and Norman}}{{}}}
\bibcite{Weger2007}{{323}{2007}{{Weger and Inhoff}}{{}}}
\bibcite{wellsetal}{{324}{2009}{{Wells {et~al.}}}{{}}}
\bibcite{WuKaiserVasishth2017}{{325}{2017}{{Wu {et~al.}}}{{}}}
\bibcite{YadavEtAlAMLaP2020}{{326}{2020}{{Yadav {et~al.}}}{{}}}
\bibcite{Yee2008}{{327}{2008}{{Yee {et~al.}}}{{}}}
\bibcite{yngve}{{328}{1960}{{Yngve}}{{}}}
\bibcite{Zurif1994}{{329}{1994}{{Zurif {et~al.}}}{{}}}
\bibstyle{cambridgeauthordate}
\newlabel{refs}{{9.5}{235}{In closing}{appendix*.33}{}}
\@writefile{toc}{\contentsline {schapter}{Index}{237}{appendix*.33}\protected@file@percent }
