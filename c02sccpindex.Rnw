
\chapter{Dependency completion in sentence comprehension} \label{c01}

\section{Memory processes in sentence comprehension}

\index{cognitive psychology} \index{memory processes}
 Cognitive psychology has a rich history of investigating human memory processes. A typical experiment in cognitive psychology might involve getting participants to study pairs of words in succession, and then asking them to recall the second word given the first, or to recall the first word given the second.  Using such experimental paradigms, psychologists have  developed many   theories about how human memory works. For sentence processing, especially interesting are theories explaining why we forget material that we have previously seen.  
 
 \index{interference}
 A dominant explanation for forgetting is interference:  the association between multiple items in memory leads to competition among them and the subsequent inability to retrieve the correct item. \cite{anderson1974retrieval} suggested that interference is affected by the total number of associated links in memory; he refers to this number as the fan. The larger the fan, the greater the interference. We will refer to the processing difficulty arising from the \index{fan effect} fan effect as \index{inhibitory interference} \textit{inhibitory interference}.
Figure~\ref{fig:faneffect}  shows a schematic illustration of the fan effect. Suppose an experiment is carried out where a participant is shown a gray circle, triangle, and square, and the participant's task is to identify the gray square. The participant initiates a search, looking for an object that is gray and a square; these are the cues used for a search. Because there are three items that match the cue gray, the fan is three. Here, identifying the target object (the gray square) will be slower compared to a case where the circle and triangle are not gray. 

\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{figures/spreadingactivation}
\caption{A schematic illustration of the fan effect. Searching for an object that is gray and a square (the target item) is more difficult when competing items have one or more features matching cues used for identifying the target item.}\label{fig:faneffect}
\end{figure}
 
Apart from interference arising from the fan effect, many other interesting generalisations have emerged from the study of memory in psychology. Some that seem to be important for sentence processing are the following: 
 
 \begin{enumerate}
\item Recency and primacy effects \citep{Nairne1988,gibsonetal96}
\index{proactive interference} \index{retroactive interference}
\item Pro- and retroactive interference \citep{WatkinsWatkins1975,keppelunderwood,lewis:magical}
\index{misretrieval}
\item  Misretrieval of items from memory \citep{patson2016misinterpretations}
\index{reactivation}
\item Reactivation of the memorial representation  due to repeated accesses from memory \citep{VasishthLewis2006} 
\index{encoding} \index{prominence}
\item Richer encoding of an item in memory leading to easier access, due to increased prominence \citep{hofmeister07,hofmeister2011representational,HofmeisterVasishth2014}
\item Shared features between multiple items in memory degrading memory representations \citep{Nairne1990,OberauerKliegl2006,VasishthEtAlICCM2017}. 
\end{enumerate}

Despite this apparently rich connection between sentence processing and the findings of cognitive psychology, it  is still reasonable to question whether these generalisations  from psychology have anything to do with constraints on sentence processing. A priori, the answer  could well be: not much. Unlike memorising unrelated items in a psychology experiment, the words that appear in a sentence occur in a particular context: syntax, semantics, pragmatics, discourse, gesture, prosody, and possibly also facial expressions together impose structure and add context in a way that cannot be compared to  simple list memorisation and recall.
  For example, consider  a task where a participant is asked to memorise word pairs  like
  
\begin{exe}
\ex
  reporter-hired, editor-admitted, article-write
\end{exe}

The word associations that the participant would build up reading these words without any surrounding context will be quite different from the situation when one reads them in a full sentence:
  
\begin{exe}
\ex
The editor who hired the reporter to write the article admitted his mistake
\end{exe}

What is similar between word pair memorisation and the above sentence is that associations between the same sets of words need to be built. But the differences from word pair memorisation stand out: the nature of the associations  between the words in the sentence is much richer  and more constrained compared to the association in the word pair context.  The word associations  within a sentence are clearly grounded in a lifetime of experience with the real world and  with the grammar of the language in question. 
  
Seen in this way, a priori it seems unlikely that generalisations about memory derived from having participants memorise random lists of words could apply to a structured information processing task such as sentence comprehension.  Nevertheless, psycholinguists have investigated the possibility that these generalisations about memory processes also come into play in sentence parsing.
 Under this view, some, but not all, aspects of the memory system are assumed to affect syntactic structure building  and interpretation.  
 
In the next section, we survey the literature on how constraints on memory might play a role in the formation of dependencies between words in a sentence context. 
 
 \section{Dependency completion in sentence processing} 

Who did what is a central component of comprehending the meaning of a sentence. We will refer to the process of connecting co-dependents for interpretation as \index{dependency completion} dependency completion.  This can be seen as a word-association process not unlike the one studied in memory research in psychology, but with the crucial difference that the associations lead to the construction of structured representations. 

 Completing a dependency crucially involves retrieving a codependent element that resides in memory in a heightened state of activation, usually because it has been read or heard in the recent past. 
 \index{retrieval}
  This retrieval process is widely assumed to be driven by a \index{cue-based search} cue-based, \index{content-addressable search}  content-addressable search \citep{McElreeForakerDyer2003}. For example, the verb \textit{slept} would  generally require an animate subject; one retrieval cue here would therefore be animacy. Another example is number marking on the auxiliary verb; the sentence \textit{The key is on the table} has a singular-marked auxiliary verb which, due to subject-verb agreement requirements in English, needs a singular-marked subject. 
  
In such retrieval situations, if more than one noun is present that has a feature that matches the retrieval cue, retrieving the correct noun has been argued to become more difficult.  Here, we will refer to the correct target for retrieval as the target noun, and the interfering noun or nouns as the distractor(s). 
  
As discussed by \cite{lewis:magical},  there are in principle two possible serial order configurations for the target and the distractor(s): the distractor  noun can intervene between the target and the verb, or the distractor can precede the target noun.
Following the terminology from memory research in cognitive psychology, \cite{lewis:magical} refers to these configurations  as \index{proactive interference} proactive  and retroactive interference, respectively. \index{retroactive interference}
As an example, consider the eye-tracking study by
\cite{VanDykeMcElree2011}.
As shown in example \ref{ex:proretrovandyke2011}, the critical region is the verb \textit{compromised}.
Assuming that this verb takes an animate noun as subject, 
at the verb the animate subject \textit{attorney} must be retrieved. In 
(\ref{ex:proretrovandyke2011}b), the animate distractor noun \textit{witness} appears before the target noun, leading to a proactive interference configuration. The baseline condition here is (\ref{ex:proretrovandyke2011}a), which has an inanimate distractor noun \textit{motion}.   
Retroactive interference arises in (\ref{ex:proretrovandyke2011}d) because the distractor \textit{witness} appears between the target noun and the verb; the baseline condition here is (\ref{ex:proretrovandyke2011}c).


\begin{exe}
\ex \label{ex:proretrovandyke2011}
\begin{xlist}
\item Proactive interference: Low interference\\
The judge / who had declared that / the \textbf{motion} / was inappropriate / realised that the \textbf{attorney} / in the case / \textbf{compromised} \dots
\item Proactive interference: High interference\\
The judge / who had declared that / the \textbf{witness} / was inappropriate / realised that the \textbf{attorney} / in the case / \textbf{compromised} \dots
\item Retroactive interference: Low interference \\
The \textbf{attorney} / who the judge realised / had declared that / the \textbf{motion} / was inappropriate / \textbf{compromised} \dots
\item Retroactive interference: High interference \\
The \textbf{attorney} / who the judge realised / had declared that / the \textbf{witness} / was inappropriate / \textbf{compromised} \dots
\end{xlist}
\end{exe}

In the above example, interference is argued to lead to slowdowns at the verb.
Pro- and retroactive configurations can also lead to facilitatory effects, if there is a partial match with a proper subset of the retrieval cues triggered at a verb.  An example is the study by \cite{WagersLauPhillips2009}. The authors investigated ungrammatical sentences that can lead to illusions of grammaticality due to a partial feature match between plural number marking on the distractor noun and the verb's plural feature.
The distractor \textit{musicians} (in the proactive interference condition \ref{ex:proretroagrmt}b) and \textit{cells} (in the retroactive condition \ref{ex:proretroagrmt}d) can lead to an illusion of grammaticality, leading to faster reading times at the auxiliary (relative to the respective baseline conditions).

\begin{exe}
\ex \label{ex:proretroagrmt}
\begin{xlist}
\item Proactive interference, distractor mismatch\\
*The musician who the reviewer praise so highly will \dots
\item Proactive interference, distractor match\\
*The musicians who the reviewer praise so highly will \dots
\item Retroactive interference, distractor mismatch\\
*The key to the cell (unsurprisingly) were rusty from many years of disuse 
\item Retroactive interference, distractor match\\
*The key to the cells (unsurprisingly) were rusty from many years of disuse
\end{xlist}
\end{exe}

\index{proactive interference} \index{retroactive interference}
Apart from the work mentioned above,pro- and retroactive interference configurations have not been systematically studied in sentence processing; this is an important gap in the literature on interference.  

We turn next to a typology of linguistic dependencies have been investigated in the reading literature. We limit the discussion to work on reading (self-paced readind and eyetracking) because the mapping between  reading time and the predictions of the models under consideration in this book is relatively straightforward to define.

\section{Subject-verb non-agreement dependencies}

\index{inhibitory interference}
Julie Van Dyke has carried out a comprehensive set of experiments which suggest that inhibitory interference effects arise when a grammatical subject needs to be connected to a verb and one or more other nouns in memory share certain features with the subject noun.

 As an example, consider the self-paced reading study  carried out by \cite{vandykemcelree06}.  They  showed participants sentences like (\ref{vd06}). Before  participants saw the target sentence, they were either asked to memorise three words, here \textit{table}, \textit{sink}, \textit{truck} (memory-load condition) or not asked to memorise any words (no-memory-load condition). Every sentence was followed by a question like \textit{Did the guy live by the sea?}
 
 \begin{exe}
\ex \label{vd06}
\begin{xlist}
\item No-interference condition\\
It was the boat that the guy who lived by the sea sailed in two sunny days.
\item Interference condition \\
It was the boat that the guy who lived by the sea fixed in two sunny days.
\end{xlist}
\end{exe}

In the memory-load condition, participants showed longer reading times at the word \textit{fixed} vs.\ \textit{sailed}; by comparison, in the no-load condition, no difference was seen between the two words. Van Dyke and McElree's conclusion was that this effect was due to increased \index{similarity-based interference} similarity-based interference at the verb \textit{fixed}: the reader had to retrieve the subject \textit{boat}, but also had three interfering words in memory (\textit{table}, \textit{sink}, \textit{truck}) that could potentially be subjects of the verb \textit{fixed}. These interfering words cause slowdowns in the dependency-completion at the verb. As the authors put it (p.\ 163): ``Reading times for \dots the locus of the interference manipulation \dots provided the critical test of our retrieval interference hypothesis. We found clear support for retrieval interference from the significant effect of interference and the significant interaction in this region, which revealed that the interference effect was linked to the difference between the two sentence types in the Load conditions.''

One difficulty here is that
the claim above is based on a statistically non-significant result (min F$'$(1,68) = 1.44, p = 0.23; 56 participants), 
%to-do: give page reference, am I referring to the interaction here?
and the interaction between load and interference also failed to show an effect in a subsequent attempt by \cite{van2014low} (estimate -10 ms, SE 15; 65 participants). 
%to-do: give page number where I got this from
In the \cite{van2014low} paper, there isn't enough information to determine whether the direction of the effect is identical to that of the original study. In a recent larger-sample replication attempt involving English \citep{MertzenEtAlAMLaP2019}, we failed to find an interaction between load and interference in total reading time, although we do see some evidence for the interaction in first-pass reading time. \cite{MertzenEtAlAMLaP2019} also carried out eyetracking experiments in parallel on  German and Russian, but these languages didn't show any evidence of the expected interaction in any eyetracking dependent measure. 

 In subsequent work, \cite{VanDyke2007} conducted eye-tracking reading studies in which sentences like (\ref{vd07a},   \ref{vd07b}) were shown. The labels on each sentence type are explained below.

\begin{exe}
\ex \label{vd07a}
\begin{xlist}
\item LoSyn, LoSem\\
The worker was surprised that the resident who was living near the dangerous warehouse was complaining about the investigation.
\item HiSyn, HiSem\\
The worker was surprised that the resident who said that the neighbour was dangerous was complaining about the investigation.
\end{xlist}
\end{exe}

\begin{exe}
\ex\label{vd07b}
\begin{xlist}
\item HiSyn, LoSem\\
The worker was surprised that the resident who said that the warehouse was dangerous was complaining about the investigation.
\item LoSyn, HiSem\\
The worker was surprised that the resident who was living near the dangerous neighbour was complaining about the investigation.
\end{xlist}
\end{exe}

This experiment had a $2\times 2$ factorial design which varied whether a noun (\textit{warehouse}/\textit{neighbour})  that appears between a subject-verb dependency (\textit{resident}-\textit{was complaining}) was a grammatical subject (High Syntactic interference) or not (Low Syntactic interference), and was animate (High Semantic interference) or not (Low Semantic interference).  The research question was the following: when a subject-verb dependency is to be completed at the verb phrase \textit{was complaining}, can a distractor noun (such as \textit{neighbour}) that overlaps in syntactic and semantic features with the grammatical subject (\textit{resident}) cause greater difficulty in completing the dependency at the verb?
Van Dyke found that syntactic interference effects occurred earlier than semantic interference effects: when the distractor noun was in subject position inside the relative clause (compared to non-subject position), an interference effect showed up earlier compared to the case where the distractor noun was animate. This suggests that syntactic cues may have priority or may be weighted more heavily than semantic cues.

As mentioned above, \cite{VanDykeMcElree2011} also investigated interference in \index{proactive} proactive and \index{retroactive} retroactive configurations (see examples \ref{ex:proretrovandyke2011} above), and argued that \index{retroactive interference} retroactive interference effects are stronger than \index{proactive interference} proactive interference effects.

<<jvdmetaanalysis,echo=FALSE,cache=TRUE>>=
dat<-read.csv("data/MetaAnalysisData.csv",header=TRUE,sep=";")

## reorder by increasing y:
dat<-dat[with(dat,order(Effect)),]

#unique(dat$Cue)
# Retrieval cue that is manipulated:
## gend: gender (masculin vs feminin)
## num: number (singular vs plural)
## subj: subject (being a subject or not)
## anim: animacy (animate vs inanimate)
## ccom: c-comand (being a c-commander or not of the reflexive)
## sem: semantic cue (matching or mismatching the semantic requirements of a verb with respect to its subject)

#unique(dat$DepType) 
# Dependency Type:
## agreement: subject-verb number agreement dependency
## nonagreement: subject-verb non-agreement dependency
## refl: reflexive-antecedent dependency
## reci: reciprocal-antecedent dependency

#unique(dat$IntType) 
# Interference type:
## pro: proactive interference
## retro: retroactive interference

# Contrast coding of the covariates

# Interference type: sum contrasts
dat$proretro<-ifelse(dat$IntType=="pro",0.5,-0.5)

## Distractor prominence: sliding contrasts
dat$contrOR2<-ifelse(dat$Prominence2=="subj_OR_topic",0.5,
                     ifelse(dat$Prominence2=="other",-0.5,0))
dat$contrAND2<-ifelse(dat$Prominence2=="subj_AND_topic",0.5,
                      ifelse(dat$Prominence2=="subj_OR_topic",
                             -0.5,0))

MatchDat<-subset(dat,TargetType=="Match")
MismatchDat<-subset(dat,TargetType=="Mismatch")


## will do separate analyses on these subsets of data:
MatchNonAgrmt<-subset(dat,DepType=="nonagreement" & TargetType=="Match")
nMatchNonAgrmt<-dim(MatchNonAgrmt)[1] #12 studies

MatchAgrmt<-subset(dat,DepType=="agreement" & TargetType=="Match")
nMatchAgrmt <- dim(MatchAgrmt)[1] # 18 studies

MismatchAgrmt<-subset(dat,DepType=="agreement" & TargetType=="Mismatch")
nMismatchAgrmt<-dim(MismatchAgrmt)[1] # 13 studies

MatchReflReci<-subset(dat,DepType%in%c("refl","reci") & TargetType=="Match")
MismatchReflReci<-subset(dat,DepType%in%c("refl","reci") & TargetType=="Mismatch")
nMatchReflReci<-dim(MatchReflReci)[1] #21 studies
nMismatchReflReci<-dim(MismatchReflReci)[1] # 13 studies

#JEV data: to-do, add Cunnings and Sturt data?
datMatchNonAgrmt<-list(y=MatchNonAgrmt$Effect,
                       s=MatchNonAgrmt$SE,
                       n=dim(MatchNonAgrmt)[1],
                       pred=MatchNonAgrmt$proretro)

fit <- stan(file='StanModels/rema2.stan', data=datMatchNonAgrmt,
            iter=2000, chains=4, seed=987654321,
            control = list(adapt_delta = 0.99))

paramnames<-c("mu","tau")
#print(fit,pars=paramnames)

params<-extract(fit,pars=paramnames)

mu_targetmatch<-round(c(mean(params$mu),quantile(params$mu,prob=c(0.025,0.975))))
@

<<powerloweruppervandyke,echo=FALSE>>=
powerlower<-power.t.test(d=mu_targetmatch[2],sd=75,n=60,alternative="two.sided",type="one.sample",strict=TRUE)$power
powerupper<-power.t.test(d=mu_targetmatch[3],sd=75,n=60,alternative="two.sided",type="one.sample",strict=TRUE)$power

powerlower48<-power.t.test(d=mu_targetmatch[2],sd=75,n=48,alternative="two.sided",type="one.sample",strict=TRUE)$power
powerupper48<-power.t.test(d=mu_targetmatch[3],sd=75,n=48,alternative="two.sided",type="one.sample",strict=TRUE)$power
@
All the experiments by Van Dyke and colleagues investigated sentences with a subject-verb dependency, where the retrieval cues were either syntactic or semantic in nature:  in other words, the target noun was either a grammatical subject or object,  or animate or inanimate. \cite{JaegerEngelmannVasishth2017} assembled the estimates and standard errors for all the studies carried out by Van Dyke and colleagues. As shown in Figure~\ref{fig:jvddataplot}, these studies tend to show a consistent pattern: with some exceptions, when a distractor noun is present that has features matching the retrieval cues of the verb, an increase in processing time (reading time) is observed. 
We can summarise these results by computing the posterior distribution of the effect, using a random effects \index{meta-analysis} meta-analysis; see \cite{JaegerEngelmannVasishth2017} for details. The meta-analysis shows that the presence of a distractor increases reading time at the verb by \Sexpr{mu_targetmatch[1]} ms, with a 95\% credible interval of [\Sexpr{mu_targetmatch[2]},\Sexpr{mu_targetmatch[3]}] ms. Note, however, that a recent pair of eye-tracking experiments by \cite{CunningsSturt2018} investigating fan effects found no evidence  for inhibitory interference. \index{fan effects} \index{inhibitory interference}

Such a failure to find interference effects is no surprise; if the true effect really is in the range [\Sexpr{mu_targetmatch[2]},\Sexpr{mu_targetmatch[3]}] ms, as Van Dyke's work suggests, then, assuming a standard deviation of 75 ms for reading times (eye-tracking or self-paced reading), and a sample size of 60 participants, power is in the range from \Sexpr{round(100*powerlower)}\% to \Sexpr{round(100*powerupper)}\% (see Figure~\ref{fig:powerdistrnvandyke} for the power distribution, assuming that standard deviation ranges from 75 to 100 ms, and subject sample size is 60). Given that sample sizes are often much lower than 60 participants, power is probably much lower. 
For example, Cunnings and Sturt had 48 participants; such a sample size would result in  power in the range \Sexpr{round(100*powerlower48)}\% and \Sexpr{round(100*powerupper48)}\% for a standard deviation of 75.
Thus, with such small sample sizes, an absence of an interference effect is not possible to interpret.

\begin{figure}[!htbp]
\centering
<<jvddataplot,echo=FALSE>>=

MatchNonAgrmt$id<-factor(1:length(MatchNonAgrmt$Publication))

MatchNonAgrmt[order(MatchNonAgrmt$Effect),]<-MatchNonAgrmt[order(MatchNonAgrmt$Effect),]
MatchNonAgrmt$Publication<-factor(MatchNonAgrmt$Publication,
                     levels=as.character(MatchNonAgrmt$Publication))

pd<-position_dodge(0.6)
p_meansJVD<-ggplot(MatchNonAgrmt, aes(x=Publication, 
                               y=Effect,
                               group=Publication)) +
    geom_errorbar(aes(ymin=Effect-2*SE, 
                      ymax=Effect+2*SE),
                  width=.25, size=.5, position=pd) +
      annotate("rect", 
             xmin = 0, 
             xmax = 13, 
             ymin = mu_targetmatch[2], 
             ymax = mu_targetmatch[3],
             color = "black",alpha=0.2)+
#    geom_hline(yintercept=mean_mu,
#               color="black")+
    labs(title="Van Dyke et al data") +
    xlab("Study")+
    ylab("Estimate (ms)")+
    geom_hline(yintercept=0,col="gray")+
    geom_point(position=pd, size=2)+
    theme_bw()+
    magnifytext()
p_meansJVD+coord_flip()
@
\caption{Inhibitory interference effects (sorted in increasing order by magnitude) in reading studies by Van Dyke and colleagues. The gray vertical lines show the 95\%  credible interval for the meta-analysis estimate  of the effect.}\label{fig:jvddataplot}
\end{figure}

\begin{figure}[!htbp]
\centering
<<powercalcintvandyke,echo=FALSE,fig.width=3,fig.height=3>>=
n<-100000
powvals<-rep(NA,n)
for(i in 1:n){
	powvals[i]<-power.t.test(d=rnorm(1,mean=13,sd=6),
	sd=runif(1,min=75,max=100),
	n=60,
	alternative="two.sided",type="one.sample",strict=TRUE)$power
}

powervals<-data.frame(power=powvals)

ggplot(powervals, aes(x=power)) +
  geom_density(adjust=5, position="stack")+   scale_y_continuous(expand = c(0, 0))+
  ylim(c(0,3))
@
\caption{Distribution of power (paired, two-sided t-test) assuming that the effect has normal distribution  with mean 13 and standard deviation 6, the standard deviation ranges from 75 to 100 ms, and subject sample size is 60.}\label{fig:powerdistrnvandyke}
\end{figure} 


A widely accepted explanation  for  the inhibitory interference effects  is that the retrieval cue cannot uniquely identify the target noun,  and this leads to increased processing difficulty due to \index{spreading activation} spreading activation; this is the so-called \index{fan effect} fan effect \citep{AndersonEtAl2004}. 

Interestingly, in certain situations, subject-verb dependency configurations can also show facilitatory interference. One plausible explanation for this is a so-called \index{race process} race process \citep{raab1962division} triggered by a \index{partial feature match} partial feature match: a subset of the retrieval cues triggered at the verb match with a distractor noun and another subset of cues match with the target, leading to a race process that results in an occasional \index{misretrieval} misretrieval of the distractor \citep{LogacevMultiple,NicenboimRetrieval2018}. The race process is discussed further in section \ref{core03predictions}.

For example, evidence for such a facilitatory interference effect in grammatical subject-verb dependencies comes from \cite{CunningsSturt2018}. They conducted 
 two eyetracking (reading) studies  in which they manipulated the plausibility of the correct dependent of the verb, and the plausibility of the distractor noun. They showed that when the correct dependent is implausible,  the distractor's plausibility influences reading time at the verb is faster when the distractor is a plausible subject of the verb. 
Faster total reading times are observed at the verb \textit{shattered} in (\ref{ex:cunningssturtjml2017}a) compared to (\ref{ex:cunningssturtjml2017}b). In their experiment 1, the facilitation effect at the verb was estimated to be  
$-22 [-4,-42]$ ms,  and in experiment 2, it was $-19 [1,-40]$ ms.


\begin{exe}
\ex \label{ex:cunningssturtjml2017}
\begin{xlist}
\item
 What Sue remembered was the letter that the butler with the cup accidently shattered today in the dining room.
 \item
 What Sue remembered was the letter that the butler with the tie accidently shattered today in the dining room.
\end{xlist}
\end{exe}
 
One explanation for this facilitation is in terms of a \index{lognormal race} lognormal race (although this is not how Cunnings and Sturt explain it): The verb \textit{shattered} searches for a subject noun with the property ``can be shattered'', and in some trials ends up incorrectly retrieving the noun \textit{cup} as the subject; the correct subject is \textit{letter}. Thus, the observed facilitation could be explained by assuming occasional  misretrievals of the distractor due to a partial feature match.  The process of \index{partial matching} partial matching leading to occasional \index{misretrieval} misretrievals is graphically summarized in Figure~\ref{fig:cunningssturt}. 

 \begin{figure}[!htbp]
\centering
\includegraphics[width=10cm]{figures/c02cs2018implausible.pdf}
\caption{Visualization of two conditions in the Cunnings and Sturt 2018 experiment, and the predictions of the cue-based retrieval model. The verb \textit{shattered} attempts to retrieve an item in memory that is a direct object and has the property ``is shatterable''. In both the (a) and (b) conditions shown, the direct object (which is the  target noun that should be retrieved) matches the direct object retrieval cue. However, in (b) the distractor noun matches the ``is shatterable'' cue. As a consequence, in (b), both  the target and distractor nouns enter into a race, and whichever item is non-deterministically retrieved is the winner of the race. This race process leads to a faster reading time at the verb \textit{shattered} in (b) vs.\ (a). See Section \ref{core03predictions} for more discussion about the assumed race process.} \label{fig:cunningssturt}
\end{figure}

Subject-verb dependencies have also been investigated in the context of  number agreement. Here, the retrieval cue of interest is number marking: at least in English, the subject must agree in number with the verb. Dependencies involving number agreement exhibit some interesting peculiarities, as we discuss next.

\section{Subject-verb number agreement} 

It is well-known that sentences such as (\ref{example1}) 
can lead to an illusion of grammaticality.  The sentence is \index{illusion of grammaticality}
ungrammatical because of the lack of number agreement between \index{number agreement}
the subject \textit{key} and the auxiliary \textit{are}.
Note that the second noun, \textit{cabinets}, and the auxiliary \textit{are} agree in number, but no syntactic agreement is possible between these two elements.

\begin{exe} 
\ex
\begin{xlist}
\item \label{example1}
*The key to the cabinets are on the table.
\item \label{example2}
*The key to the cabinet are on the table.
\end{xlist}
\end{exe}

Many sentence comprehension studies have shown that the illusion has the effect that the auxiliary \textit{are} is read faster in (\ref{example1}) compared to the equally ungrammatical sentence (\ref{example2}); in the latter case, the second noun (\textit{cabinet}) is singular and does not agree with the auxilary in number.

In sentence comprehension, one explanation for the \index{agreement attraction} agreement attraction effect is in terms of \index{cue-based retrieval} cue-based retrieval.  \cite{WagersLauPhillips2009} suggested that when the parser encounters the verb, the mismatch between the expected number on the verb and the actual number marking triggers a retrieval process. In the above example, the verb triggers a search for a plural-marked noun that is the subject of the verb. This leads to occasional misretrievals of the only plural marked noun in the sentence, \textit{cabinets}. An obvious problem with this account is that it seems unlikely that the reader interprets the sentence to mean that the cabinets are  on the table; of course, such an objection assumes that the reader is engaged in fully interpreting the sentence, which itself may be a questionable assumption \citep{SanfordSturt2002,FerreiraFerraroBailey2002}; we return to the question of \index{underspecification} underspecification later (chapter \ref{c04}). Note that the explanation for subject-verb \index{number agreement} number agreement conditions is the same as that for Cunnings and Sturt's  data for their  sentences (\ref{ex:cunningssturtjml2017} above). One important difference between the  Wagers et al.\  design and  that of Cunnings and Sturt  is that in the  latter it is very plausible that the reader incorrectly retrieves the distractor as a subject (although Cunnings and Sturt did not check whether readers did in fact misinterpret the sentence). It is not clear whether such a \index{misretrieval} misretrieval occurs in subject-verb number agreement.
  
Another possible explanation for the agreement attraction effect is in terms of the \index{feature overwriting} feature overwriting model of \cite{Nairne1990}. In example~(\ref{example2}),
both the nouns are marked singular, whereas in example~(\ref{example1}) the nouns have different number marking. 
As discussed in \cite{VillataFranck},
the similarity in number of the two nouns in (\ref{example2}) could be the underlying cause for increased processing difficulty, compared to (\ref{example1}).
The identical number marking in (\ref{example2}) could lead to increased \index{confusability} confusability between the two nouns, leading to longer reading times at the moment when a subject noun is to be accessed at the auxiliary verb. 
The feature overwriting model of \cite{Nairne1990} formalizes this idea. To quote (p.\ 252):
``\textit{An individual feature of a primary memory trace is assumed to be overwritten, with probability $F$, if that feature is matched in a subsequently occurring event. Interference occurs on a feature-by-feature basis, so that, if feature $b$ matches feature $a$, the latter will be lost with probability $F$}.''
 This proposal can be formalized as a hierarchical mixture model \citep{VasishthEtAlICCM2017}, as we discuss in section \ref{encint}.

A third explanation for agreement attraction is in terms of the \index{Marking and Morphing} Marking and Morphing (hereafter, MM) model; this model is intended to explain effects in production rather than comprehension.  Under the MM model, attraction effects arise due to ambiguous encoding of the number marking on a subject phrase \citep[e.g.,][]{EberhardCuttingBock2005}. In MM, number is considered to be a continuum and not a binary value. The feature ``plural'' from the distractor noun (i.e., the attractor) spreads activation to the root node of the subject noun phrase, causing it to become more ``plural''. The extent to which the subject noun phrase becomes plural depends on factors such as the number of distractor nouns with the plural feature, and how near they are to the subject noun phrase's root node in the syntactic tree. \cite{hammerly2019grammaticality} provide a recent implementation of MM that seeks to explain grammaticality judgement data in terms of a \index{drift diffusion process} drift diffusion process \citep{Ratcliff1978}. In the Hammerly  et al.\ implementation, the basic explanation for ungrammatical agreement attraction configurations being judged grammatical erroneously is a slower rate of evidence accumulation in favour of the correct and incorrect dependency completion. This model has not yet been extended to explain reading times,  and it is not clear whether under this model attraction is limted to retroactive interference designs and not proactive \citep{ALV2020},  but is an interesting proposal that needs further development.

 These different theories/explanations for the agreement attraction effect are not necessarily mutually exclusive; any combination of these theories, or possibly all of them, could together explain the data. Such hybrid models have not yet been developed or tested; developing them is an interesting direction for future research.
  
 <<agrmtattrn,echo=FALSE>>=
datMismatchAgrmt<-list(y=MismatchAgrmt$Effect,
                       s=MismatchAgrmt$SE,
                       n=dim(MismatchAgrmt)[1])

fit <- stan(file='StanModels/rema2.stan', data=datMismatchAgrmt,
            iter=2000, chains=4, seed=987654321,
            control = list(adapt_delta = 0.99))

paramnames<-c("mu","tau")
params<-extract(fit,pars=paramnames)

#print(fit,pars=paramnames)
mu_targetmismatch<-round(c(mean(params$mu),quantile(params$mu,prob=c(0.025,0.975))))
@

\begin{figure}[!htbp]
\centering
<<mismatchplot,echo=FALSE>>=
plotmeanSE(d=MismatchAgrmt,title="Agreement attraction data")+geom_hline(yintercept=mu_targetmismatch[2],color="gray")+geom_hline(yintercept=mu_targetmismatch[3],color="gray")+magnifytext()
@
\caption{Subject-verb number agreement effects in ungrammatical sentences (reading studies). Shown are the means (sorted by increasing magnitude of the effect) and 95\% confidence intervals from publicly available data.}\label{fig:agrmtattrnc01}
\end{figure} 

 As shown in Figure~\ref{fig:agrmtattrnc01}, there is some variability in agreement attraction data, but the posterior distribution of the effect has mean \Sexpr{mu_targetmismatch[1]} ms, with 95\% credible interval [\Sexpr{mu_targetmismatch[2]},\Sexpr{mu_targetmismatch[3]}] ms, which is consistent with an overall facilitation effect. These estimates are remarkably consistent with the facilitatory effects observed in the two experiments by \cite{CunningsSturt2018} ($-22$ ms, $[-4,-42]$ ms,  and $-19$ ms, $[1,-40]$ ms). As discussed earlier, Cunnings and Sturt's experiments involved a plausibility manipulation, not the number feature; this could mean that such facilitatory effects are a hallmark of configurations in which the features on the item targeted for retrieval don't fully match all the retrieval cues.

Almost all the data displayed in Figure~\ref{fig:agrmtattrnc01} comes from languages like English and Spanish \citep[an exception is][who investigated Arabic]{TuckerIdrissiAlmeida2015}. English and Spanish have relatively impoverished case marking systems. What happens if the grammatical subject and object are unambiguously case-marked? If case marking allows the parsing system to sufficiently distinguish between the nouns, the agreement attraction effect should be weakened when the nouns have distinctive \index{case marking} case marking. \cite{ALV2020} tested this hypothesis using \index{Armenian} Armenian, a language with subject-verb agreement and rich case marking. In a series of experiments (forced choice and self-paced reading), they found that although distinctive case marking on subject and object nouns led to facilitation in processing, there was no indication that distinctive case marking  attenuates the \index{agreement attraction} agreement attraction effect. \cite{ALV2020} explained the absence of an interaction between case marking and agreement attraction in terms of predictive parsing processes. As shown schematically in Figure~\ref{fig:serinecase}, once the nouns have been read, the parser predicts a verb phrase with the subject and object \index{subcategorization} subcategorization features already linked to the previously processed nouns. For example, if the reader encounters a sentence like \textit{The painters that the sculptor\dots}, a singular-marked verb is predicted, but the subcategorization frame of the  verb is already filled with the  indices corresponding to the subject and object nouns. Now, if a plural-marked verb is encountered, only the number marking of the predicted chunk needs to be modified to integrate the verb with the predicted verb phrase chunk. After that integration, agreement attraction may happen in the manner that \cite{WagersLauPhillips2009} suggest. If case marking only plays a role during prediction as suggested above, 
this may explain why Avetisyan et al.\ find no indication that distinctive case marking attenuates the agreement attraction effect.  

\begin{figure}[!htbp]
\centering
\includegraphics[height=8cm,angle=-90]{figures/serine}
\caption{The role of case marking in agreement attraction configurations. The figure is re-used here under a CC-BY4.0 license and is available from https://doi.org/10.6084/m9.figshare.11440854.v1.}\label{fig:serinecase}
\end{figure} 

The number attraction examples discussed above involve  ungrammatical sentences.
Grammatical versions of the number agreement configuration have also been investigated. Examples are shown below.

 \begin{exe} 
\ex
\begin{xlist}
\item \label{example1gr}
The keys to the cabinets are on the table.
\item \label{example2gr}
The keys to the cabinet are on the table.
\end{xlist}
\end{exe}

<<matchnumagrmt,echo=FALSE>>=
MatchNumAgrmt<-subset(dat,DepType=="agreement" & TargetType=="Match")

datMatchNumAgrmt<-list(y=MatchNumAgrmt$Effect,
                       s=MatchNumAgrmt$SE,
                       n=dim(MatchNumAgrmt)[1])

fit <- stan(file='StanModels/rema2.stan', data=datMatchNumAgrmt,
            iter=2000, chains=4, seed=987654321,
            control = list(adapt_delta = 0.99))

paramnames<-c("mu","tau")
params<-extract(fit,pars=paramnames)

#print(fit,pars=paramnames)
mu_targetmatchnum<-round(c(mean(params$mu),quantile(params$mu,prob=c(0.025,0.975))))
@

 Here, the general claim in the reading literature \citep{lago2015agreement} is that no difference is seen between the two conditions. If we examine the estimates from these studies, 
  we again see a wide range of variability, with all possible outcomes being observed; see Figure~\ref{fig:matchnumagrmt}. 
The mean of the posterior distribution of this effect
(the reading time at the auxiliary in (\ref{example2gr}) minus the reading time at the auxiliary in (\ref{example1gr})  across all these studies (some studies used the post-critical region) is   
\Sexpr{mu_targetmatchnum[1]} ms, with 95\% credible interval [\Sexpr{mu_targetmatchnum[2]},\Sexpr{mu_targetmatchnum[3]}] ms.

\begin{figure}[!htbp]
\centering
<<matchnumagrmtplot,echo=FALSE>>=
plotmeanSE(d=MatchNumAgrmt,title="Target match \n number agreement")
@
\caption{Target match number agreement effects in reading studies.}\label{fig:matchnumagrmt}
\end{figure}

The tendency towards a speedup in constructions like (\ref{example2gr}) could have a trivial explanation: differences in spillover from the preceding region. In (\ref{example2gr}) the word before the auxiliary is \textit{cabinet}, whereas in (\ref{example1gr}) it is  \textit{cabinets}. The reading time of the plural noun will be longer than the singular just because of the word length difference, and this difference could be spilling over onto the auxiliary. So this observed speedup can perhaps be disregarded. 

Based on the studies from their lab, Wagers and colleagues conclude that there is no difference in processing in the two grammatical agreement attraction conditions  shown in  (\ref{example1gr}, \ref{example2gr}). Wagers et al.\ explain this null effect as follows. The subject noun predicts a verb with a particular number marking, and this prediction is validated when the verb is encountered. In such a situation, no retrieval process is triggered.  This proposal has some difficulties. A great deal of work on English \citep{Gibson2000,grodner,Bartek2011} has consistently shown that even in grammatical constructions, a retrieval process is triggered. It seems implausible that retrieval is not triggered only in this one particular case, where the number feature is involved.

How strong is the evidence for the null results reported in the Dillon et al., Wagers et al., and Lago et al.\ studies? When \index{p-value} p-values are greater than $0.05$, this is not necessarily evidence that the null hypothesis is true. As  discussed in section \ref{typem},when \index{power} power is low, it is hardly surprising that repeated experiments show null results. This point has somehow been lost in the course of translating statistical theory to  psychological and linguistic applications. Instead of concluding that they have no evidence for an effect, researchers will incorrectly conclude that ``absence of evidence is evidence of absence''. 

What would have happened if statistical power were higher than in the studies mentioned above? The Dillon et al., Wagers et al., and Lago et al.\  studies generally have small sample sizes, leading to power far below 80\%. \index{power}
 \cite{NicenboimEtAlCogSci2018} increased power by increasing sample size to 185 subjects, and by increasing the strength of the interference manipulation. Their design involved grammatical German sentences with number interference. Here, a subject noun and a verb always have two nouns intervening between them. In the high-interference condition, all three nouns match the number  feature that is on the verb; in the low-interference condition, only the subject noun has the number feature that is on the verb. Thus, this design seeks to increase the magnitude of the number interference effect by increasing the \index{fan effect} fan, i.e., increasing the number of nouns that match the retrieval cues.

 \begin{exe}
    \ex  \label{ex:brunoexp1}
    \begin{xlist}
        \ex \textsc{High Interference} \label{ex:brunoHI}
        \gll \textbf{Der} \textbf{Wohlt\"ater}, der den Assistenten {} des
        Direktors \textbf{begr\"usst} \textbf{hatte}, sass sp\"ater im
        Spendenausschuss.\\
        \textbf{The.sg.nom} \textbf{philanthropist}, who.sg.nom
        the.\underline{sg}.acc assistant (of) the.\underline{sg}.gen director
        \textbf{greeted} \textbf{had.sg}, sat.sg {later} {in the} {donations
        committee}.\\
        \glt ‘The philanthropist, who had greeted the assistant of the director,
        sat later in the donations committee.'
        \ex \textsc{Low Interference} \label{ex:brunoLI}
        \gll \textbf{Der} \textbf{Wohlt\"ater}, der die Assistenten {} der
        Direktoren  \textbf{begr\"usst} \textbf{hatte}, sass sp\"ater im
        Spendenausschuss.\\
        \textbf{The.sg.nom} \textbf{philanthropist}, who.sg.nom
        the.\underline{pl}.acc assistant(s) (of) the.\underline{pl}.gen
        director(s) \textbf{greeted} \textbf{had.sg}, sat.sg {later} {in the}
        {donations committee}.\\
        \glt ‘The philanthropist, who had greeted the assistants of the
        directors, sat later in the donations committee.'
    \end{xlist}
\end{exe}

This larger-sample study suggests that the magnitude of the \index{cue-based retrieval} cue-based retrieval effect in  grammatical sentences involving number agreement may be smaller compared to the effect observed in ungrammatical agreement attraction configurations.  Nicenboim et al.\ demonstrate that if the number of distractor  nouns is increased from one to two, a small interference effect can be observed at the verb \textit{begr\"usst hatte}, `greeted had', in  sentences like (\ref{ex:brunoHI})  compared to (\ref{ex:brunoLI}). The authors found that with two distractors present, the interference effect is approximately 9 ms with a 95\% credible interval of 0 to 18 ms. What could be the reason for smaller interference effect in this case?  Nicenboim et al.\ argue that feature percolation (the mechanism assumed in the Marking and Morphing model) and cue-based retrieval may be acting in opposite directions. It follows that if one increases the magnitude of the interference effect, the effect should be detectable. This  proposal has yet to be  tested with new experimental designs, and is an interesting avenue for future research.
  
\section{Reflexives and reciprocals}

\cite{Sturt2003} carried out an eye tracking study that investigated the processing of direct object reflexives. He suggested that when the parser encounters a \index{reflexive} reflexive,  in the first moments of processing, the antecedent is chosen using principle A of the binding theory.   
 This implies that if any other noun phrases are present that are not syntactically licensed as antecedents of the reflexive, these would never be considered as possible antecedents even if the gender marking on the reflexive matches these noun phrases. Two examples are shown below  to illustrate  the two basic configurations that have been studied in the literature. These examples are adapted from Sturt's paper.
 
\begin{exe} 
\ex
\begin{xlist}
\item Proactive \label{reflpro}\\
Jonathan/Jennifer remembered that the surgeon had pricked himself with a used syringe needle.
  \item Retroactive \label{reflretro}\\
  The surgeon  who Jonathan/Jennifer  met had pricked himself with a used syringe needle.
\end{xlist}
\end{exe}
 
Example~(\ref{reflpro}) shows a \index{proactive interference} proactive interference configuration: the reflexive \textit{himself} requires the subject of the local clause, that is, \textit{surgeon}, as the legal antecedent. However, the proper noun \textit{Jonathan} matches in gender with the reflexive. Under the Sturt account, in the first moments of processing, compared to the baseline where the distractor noun (e.g., \textit{Jennifer}) doesn't match the gender of the reflexive \textit{himself}, the masculine marked distractor noun \textit{Jonathan} would never be considered as an antecedent. 
Example~(\ref{reflretro}) shows a \index{retroactive interference} retroactive interference configuration:  the distractor noun \textit{Jonathan} appears between the subject, which is the antecedent of the reflexive, and the reflexive \textit{himself}. 

In both  configurations, one can investigate the effect of the distractor noun by comparing sentences that either have a masculine distractor noun such as \textit{Jonathan},  or a feminine distractor noun  such as \textit{Jennifer}.  Sturt found no evidence that the reflexive was mistakenly associated with the distractor noun  at the earliest moments of processing, that is, in first-pass reading times.
As  Sturt puts it (page 542), \index{Principle A} ``Principle A of the \index{binding theory} binding theory operates at the very earliest stages of processing; \dots the gender of the ungrammatical antecedent [the distractor noun] had no effect on early processing, although it affected processing during later stages.''
In other words, at the earliest moments of processing, based on these \index{null results} null results, reflexives are assumed to be immune to the effects of interference.

 Recall that earlier we had seen in subject-verb dependencies that interference effects are robustly seen.
 In the grammatical subject-verb dependencies investigated by Van Dyke and colleagues, we robustly see inhibitory effects, and 
in ungrammatical subject verb dependencies with number agreement between the distractor and verb, we see a relatively clear indication of facilitation effects. Since the majority of these studies involve self-paced reading, we cannot say whether these inhibitory and facilitatory effects reflect the earliest moments of processing. 
An exception is the eyetracking study by \cite{VanDyke2007}; but here too,  first-pass reading time seems to show no interference effects (see Figure~\ref{fig:jvddataplot}). However, in a recent larger-sample eyetracking study involving English, \cite{MertzenEtAlAMLaP2019} did find the predicted inhibitory interference effects in first-pass reading times.

Is the processing of \index{reflexives} reflexives different from those of subject-verb constructions? The answer would be yes if interference effect was seen in subject-verb constructions but not in reflexive constructions. In particular, at the earliest moments of processing, e.g., in first-pass reading times, we would expect to see interference effects in  subject-verb constructions but not in reflexives. \cite{DillonMishlerSloggett2013} were the first to directly compare interference effects in these two dependency types  (their experiment 1).  They compared subject-verb number agreement constructions with reflexives. See (\ref{dillon13agrmt}, \ref{dillon13refl}).

\begin{exe}
\ex \label{dillon13agrmt}
\begin{xlist}
\item Grammatical \\
\textbf{The new executive} who oversaw \textbf{the middle manager} apparently \textbf{was} dishonest about the company's profits
\item Grammatical \\
\textbf{The new executive} who oversaw the middle managers apparently was dishonest about the company's profits
\item Ungrammatical \\
*The new executive who oversaw the middle manager apparently \textbf{were} dishonest about the company's profits
\item  Ungrammatical \\
*The new executive who oversaw \textbf{the middle managers} apparently \textbf{were} dishonest about the company's profits
\end{xlist}
\end{exe}



\begin{exe}
\ex \label{dillon13refl}
\begin{xlist}
\item 
Grammatical \\
\textbf{The new executive} who oversaw \textbf{the middle manager} apparently doubted \textbf{himself} on most major decisions
\item
Grammatical\\ 
\textbf{The new executive} who oversaw the middle managers apparently doubted \textbf{himself} on most major decisions
\item
Ungrammatical \\
*The new executive who oversaw the middle manager apparently doubted \textbf{themselves} on most major decisions
\item 
Ungrammatical \\
*The new executive who oversaw \textbf{the middle managers} apparently doubted \textbf{themselves} on most major decisions
\end{xlist}
\end{exe}

Dillon generously provided the data from his study. This allowed us to  determine whether, in early vs.\ late measures, any difference is seen between agreement and reflexives. We first defined nested contrasts (in grammatical and ungrammatical sentences separately) as shown in Table~\ref{dillon13nestedcoding}. Note that Dillon and colleagues used a different contrast coding than we did (main effects and interactions of grammaticality and intrusion); the details of these differences are discussed in \cite{JaegerMertzenVanDykeVasishth2019}. 

\begin{table}[!htbp]
\begin{center}
\begin{tabular}{ccccccccc}
      & \multicolumn{4}{c}{Agreement} &  \multicolumn{4}{c}{Reflexives} \\
      & \multicolumn{2}{c}{Gram} & \multicolumn{2}{c}{Ungram} & \multicolumn{2}{c}{Gram} & \multicolumn{2}{c}{Ungram} \\  
      & No intr & Intr & No intr & Intr & No intr & Intr & No intr & Intr \\   
dep   & -0.5  & -0.5  & -0.5  & -0.5  &  0.5  &  0.5  &  0.5  &  0.5\\
intr.au &  0  &  0  & -0.5  &  0.5  &  0  &  0  &  0  &  0\\
intr.ag & -0.5  &  0.5  &  0  &  0 &    0  &  0  &  0  &  0\\
intr.ru & 0   & 0   & 0   & 0  &   0    & 0 &  -0.5 &   0.5\\
intr.rg & 0   & 0   & 0   & 0  &  -0.5  &  0.5  & 0 &   0\\
\end{tabular}
\end{center}
\caption{Nested contrast coding to investigate the effect of intrusion in grammatical and ungrammatical agreement and reflexive constructions. The contrast dep is the main effect of dependency type (agreement or reflexive).}
\label{dillon13nestedcoding}
\end{table}%

\index{eyetracking}
We analysed all dependent measures that have been invoked as indexing \index{early processes} early processes in the dependencies considered in this chapter: first-pass reading time and regression probability \citep{DillonMishlerSloggett2013}, and regression path duration \citep{CunningsSturt2018}. As shown in Figure \ref{fig:dillonresults}, the only clear effect is in total reading times in ungrammatical agreement dependencies. None of the dependent measures that are claimed to index early processes show any effects in either agreement or reflexive dependencies. 
Thus, from these data at least, there is no reason to believe that interference effects \textit{ever} occur in early measures in \textit{any} dependency, as claimed by \cite{Sturt2003}. It is therefore not clear why reflexive processing is seen as special and different from any other dependency. One could conclude that all dependencies uniformly show an absence of interference effects in early measures.

<<loaddillon13data,echo=FALSE>>=
orig <- read.table("data/data_experiment1_jml.txt",header=TRUE)
orig$subj <- factor(orig$subj)
orig$item <- factor(orig$item)
orig$cond <- factor(orig$cond)
# rename conditions to match our data
levels(orig$cond) <- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
# cast data to wide format to have the same data structure as in the analysis of our data above
library(reshape2)
orig <- dcast(orig, subj+item+cond+region ~ fixationtype, value.var = "value")

orig <- orig[, c('subj', 'item', 'cond', 'region', 'fp', 'tt', 'pr')]
# use same col names as for our data
colnames(orig) <- c('subj', 'item', 'cond', 'roi', 'FPRT', 'TFT', 'FPR')

Nsubj_orig <- length(unique(factor(orig$subj)))
Nitem_orig <- length(unique(factor(subset(orig, cond!='filler')$item)))

# Condition Labels (using our labels; same contrasts as above in analysis of our data); for documentation of contrasts see above. 

orig$Dep <- ifelse(orig$cond %in% c('a', 'b', 'c', 'd'), .5, -.5) # main effect of dependency type: agr=0.5, refl=-0.5
orig$Gram <- ifelse(orig$cond %in% c('a', 'b', 'e', 'f'), -.5, .5) # main effect of grammaticality: gram=-.5, ungram=.5
orig$Int_gram <- ifelse(orig$cond %in% c('a','e'), .5, ifelse(orig$cond %in% c('b', 'f'), -.5, 0) ) # interference in grammatical sentences: distr-match=0.5, distr-mismatch=-0.5
orig$Int_ungram <- ifelse(orig$cond %in% c('d', 'h'), .5, ifelse(orig$cond %in% c('c', 'g'), -.5, 0)) # interference in ungrammatical sentences: distr-match=0.5, distr-mismatch=-0.5
orig$DepxInt_gram <-ifelse(orig$cond %in% c('a', 'f'), .5, ifelse(orig$cond %in% c('b', 'e'), -.5, 0))
orig$DepxInt_ungram <- ifelse(orig$cond %in% c('d', 'g'), .5, ifelse(orig$cond %in% c('c', 'h'), -.5, 0))
orig$DepxGram <- ifelse(orig$cond %in% c('c', 'd', 'e', 'f'), .5, -.5)


orig$Int_gram_refl <- ifelse(orig$cond %in% c('e'), .5, ifelse(orig$cond %in% c('f'), -.5, 0))
orig$Int_gram_agr <- ifelse(orig$cond %in% c('a'), .5, ifelse(orig$cond %in% c('b'), -.5, 0))
orig$Int_ungram_refl <- ifelse(orig$cond %in% c('h'), .5, ifelse(orig$cond %in% c('g'), -.5, 0))
orig$Int_ungram_agr <- ifelse(orig$cond %in% c('d'), .5, ifelse(orig$cond %in% c('c'), -.5, 0))

# in original data, critical region is 
crit_orig <- subset(orig, roi==5 & cond!='filler') 
crit_orig<-subset(crit_orig,TFT!="NA")
@

<<fitdillonmodel,echo=FALSE,message=FALSE,warning=FALSE,results="asis",cache=TRUE,eval=FALSE>>=
library(brms)
priors<-c(set_prior("normal(0,10)", 
                    class = "Intercept"),
          set_prior("normal(0,1)", 
                    class = "b"),
                      set_prior("normal(0,1)", 
                                class = "sd"),
          set_prior("lkj(2)", class = "cor"))

m_dillon<-brm(TFT~1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr + (1+1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|subj) + (1+1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|item),crit_orig,family=lognormal(),prior = priors,
            warmup = 1000, iter = 2000, 
            chains = 4,
            cores = 4,
            control = list(adapt_delta = 0.95))

save(m_dillon,file="data/m_dillon.Rda")
@

<<dillonmeansplot,echo=FALSE>>=
load(file="data/m_dillon.Rda")
m_post<-posterior_samples(m_dillon,pars=c("b_Intercept","b_Int_ungram_refl","b_Int_ungram_agr"))
## mean effects:
post_refl<-exp(m_post[,1]+m_post[,2]/2)-exp(m_post[,1]-m_post[,2]/2)
post_agr<-exp(m_post[,1]+m_post[,3]/2)-exp(m_post[,1]-m_post[,3]/2)
refl_df<-data.frame(posterior=post_refl)
refl_quant<-quantile(refl_df$posterior,prob=c(0.025,0.975))
refl_df$dependency<-"reflexive"
agr_df<-data.frame(posterior=post_agr)
agr_quant<-quantile(agr_df$posterior,prob=c(0.025,0.975))
agr_df$dependency<-"agreement"

agr_refl_means_df<-rbind(refl_df,agr_df)

dillonmeanplot<-ggplot(agr_refl_means_df,
       aes(x=posterior,fill=dependency))+
  geom_density(stat="density",alpha=0.5)+
#    geom_line(aes(linetype=dependency))+
  #scale_color_grey()+scale_fill_grey()+
  xlab("Estimate (ms)")+
geom_vline(xintercept=0)+start_y_at_zero()
@

<<dilloninddiffs,echo=FALSE>>=
u0id<-paste0("r_subj[",unique(crit_orig$subj), ",Intercept]")
u0<-posterior_samples(m_dillon,
                      pars = u0id,
                      exact_match = TRUE)
u1_agr<-posterior_samples(m_dillon,
                      pars = parnames(m_dillon)[746:785],
                      exact_match = TRUE)
u1_refl<-posterior_samples(m_dillon,
                      pars = parnames(m_dillon)[706:745],
                      exact_match = TRUE)

## compute subject level estimates:
agr_subj<-refl_subj<-matrix(rep(NA,4000*40),ncol=40)
for(i in 1:40){
 refl_subj[,i]<-exp(m_post[,1]+u0[,i]+(u1_refl[,i]+m_post[,2]))-
    exp(m_post[,1]+u0[,i]-(u1_refl[,i]+m_post[,2]))
 agr_subj[,i]<-exp(m_post[,1]+u0[,i]+(u1_refl[,i]+m_post[,3]))-
    exp(m_post[,1]+u0[,i]-(u1_refl[,i]+m_post[,3]))
}

agr_subj<-data.frame(agr_subj)
colnames(agr_subj)<-factor(paste("s",1:40,sep=""))
agr_subj_long <- gather(agr_subj, subject, posterior, s1:s40, factor_key=TRUE)
agr_means<-colMeans(agr_subj)
agr_subj<-agr_subj[,order(agr_means)]

refl_subj<-data.frame(refl_subj)
colnames(refl_subj)<-factor(paste("s",1:40,sep=""))
refl_subj_long <- gather(refl_subj, subject, posterior, s1:s40, factor_key=TRUE)
refl_means<-colMeans(refl_subj)
refl_subj<-refl_subj[,order(refl_means)]

## interval plots:
color_scheme_set("gray")
p_refl<-mcmc_intervals(refl_subj,prob_outer = 0.95, 
                         point_est="mean")+
  geom_vline(xintercept=0)+#xlim(-500,200)+
  xlab("Estimate (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("Dillon et al 2013 Expt 1: \n Ungrammatical reflexives")+magnifytext(sze=12)

p_agr<-mcmc_intervals(agr_subj,prob_outer = 0.95, 
                         point_est="mean")+
  geom_vline(xintercept=0)+#xlim(-500,200)+
  xlab("Estimate (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("Ungrammatical agreement")+magnifytext(sze=12)

#dillonindplot<-multiplot(p_refl,p_agr,cols=2)

## ridges plot
agr_subj_long$dependency<-"agreement"
refl_subj_long$dependency<-"reflexive"

agr_refl_long<-rbind(agr_subj_long,refl_subj_long)
agr_refl_long$dependency<-factor(agr_refl_long$dependency)

dillonindplotridges<-ggplot(agr_refl_long,
                      aes(y=subject))+
  geom_density_ridges(
    aes(x=posterior,fill=dependency),
    scale=1,
    alpha=0.5, color="white")+xlim(c(-500,300))+
  #scale_color_grey()+scale_fill_grey()+
  geom_vline(xintercept=0)+xlab("Estimate (ms)")
@

<<dillonrep,echo=FALSE>>=
d <- read.table(file='data/dataJMVV.txt', sep = '\t')
d$subj <- factor(d$subj)
d$item <- factor(d$item)

#### Define contrasts 
# main effects of dependency and grammaticality and their interaction (applied in Model 1 and 2)
d$Dep <- ifelse(d$cond %in% c('a', 'b', 'c', 'd'), .5, -.5) # main effect of dependency type: agr=0.5, refl=-0.5
d$Gram <- ifelse(d$cond %in% c('a', 'b', 'e', 'f'), -.5, .5) # main effect of grammaticality: gram=-.5, ungram=.5
d$DepxGram <- ifelse(d$cond %in% c('c', 'd', 'e', 'f'), .5, -.5)

# interference effect within grammatical and within ungrammatical conditions, and their interaction with dependency (applied in Model 1)
d$Int_gram <- ifelse(d$cond %in% c('a','e'), .5, ifelse(d$cond %in% c('b', 'f'), -.5, 0) ) # interference in grammatical sentences: distr-match=0.5, distr-mismatch=-0.5
d$Int_ungram <- ifelse(d$cond %in% c('d', 'h'), .5, ifelse(d$cond %in% c('c', 'g'), -.5, 0)) # interference in ungrammatical sentences: distr-match=0.5, distr-mismatch=-0.5
d$DepxInt_gram <-ifelse(d$cond %in% c('a', 'f'), .5, ifelse(d$cond %in% c('b', 'e'), -.5, 0))
d$DepxInt_ungram <- ifelse(d$cond %in% c('d', 'g'), .5, ifelse(d$cond %in% c('c', 'h'), -.5, 0))

# pairwise comparisons: interference effects nested within grammaticality and dependency (applied in Model 2)
d$Int_gram_refl <- ifelse(d$cond %in% c('e'), .5, ifelse(d$cond %in% c('f'), -.5, 0))
d$Int_gram_agr <- ifelse(d$cond %in% c('a'), .5, ifelse(d$cond %in% c('b'), -.5, 0))
d$Int_ungram_refl <- ifelse(d$cond %in% c('h'), .5, ifelse(d$cond %in% c('g'), -.5, 0))
d$Int_ungram_agr <- ifelse(d$cond %in% c('d'), .5, ifelse(d$cond %in% c('c'), -.5, 0))
crit <- subset(d, roi==12 & cond!='filler') 

crit<-subset(crit,TFT>0)
#length(unique(crit$subj))
@

<<dillonrepbrmsanalysis,echo=FALSE,eval=FALSE>>=
m_drep<-brm(TFT~1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr + (1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|subj) + (1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|item),crit,
            family=lognormal(),prior = priors,
            warmup = 1000, iter = 2000, 
            chains = 4,
            cores = 4,
            control = list(adapt_delta = 0.99))
summary(m_drep)
save(m_drep,file="data/m_drep.Rda")
@

<<dillonrepplot,echo=FALSE>>=
load(file="data/m_drep.Rda")
m_post<-posterior_samples(m_drep,pars=c("b_Intercept","b_Int_ungram_refl","b_Int_ungram_agr"))
## mean effects:
post_refl<-exp(m_post[,1]+m_post[,2]/2)-exp(m_post[,1]-m_post[,2]/2)
post_agr<-exp(m_post[,1]+m_post[,3]/2)-exp(m_post[,1]-m_post[,3]/2)
refl_df<-data.frame(posterior=post_refl)
refl_quant<-quantile(refl_df$posterior,prob=c(0.025,0.975))
refl_df$dependency<-"reflexive"
agr_df<-data.frame(posterior=post_agr)
agr_quant<-quantile(agr_df$posterior,prob=c(0.025,0.975))
agr_df$dependency<-"agreement"

agr_refl_means_df<-rbind(refl_df,agr_df)

dillonrepmeanplot<-ggplot(agr_refl_means_df,
       aes(x=posterior,fill=dependency))+
  geom_density(stat="density",alpha=0.5)+
#  geom_line(aes(linetype=dependency))+
  #scale_color_grey()+scale_fill_grey()+
  xlab("Estimate (ms)")+
geom_vline(xintercept=0)+start_y_at_zero()
@

<<dillonrepinddiffs,echo=FALSE>>=
u0id<-paste0("r_subj[",unique(crit$subj), ",Intercept]")
u0<-posterior_samples(m_drep,
                      pars = u0id,
                      exact_match = TRUE)
u1_agr<-posterior_samples(m_drep,
                      pars = parnames(m_drep)[1733:(1733+180)],
                      exact_match = TRUE)
u1_refl<-posterior_samples(m_drep,
                      pars = parnames(m_drep)[1552:(1552+180)],
                      exact_match = TRUE)

## compute subject level estimates:
agr_subj<-refl_subj<-matrix(rep(NA,4000*181),
                            ncol=181)
for(i in 1:181){
 refl_subj[,i]<-exp(m_post[,1]+u0[,i]+(u1_refl[,i]+m_post[,2]))-
    exp(m_post[,1]+u0[,i]-(u1_refl[,i]+m_post[,2]))
 agr_subj[,i]<-exp(m_post[,1]+u0[,i]+(u1_refl[,i]+m_post[,3]))-
    exp(m_post[,1]+u0[,i]-(u1_refl[,i]+m_post[,3]))
}

agr_subj<-data.frame(agr_subj)
colnames(agr_subj)<-factor(paste("s",1:181,sep=""))
agr_subj_long <- gather(agr_subj, subject, posterior, s1:s181, factor_key=TRUE)
agr_means<-colMeans(agr_subj)
agr_subj<-agr_subj[,order(agr_means)]

refl_subj<-data.frame(refl_subj)
colnames(refl_subj)<-factor(paste("s",1:181,sep=""))
refl_subj_long <- gather(refl_subj, subject, posterior, s1:s181, factor_key=TRUE)
refl_means<-colMeans(refl_subj)
refl_subj<-refl_subj[,order(refl_means)]

## interval plots:
color_scheme_set("gray")
p_reflrep<-mcmc_intervals(refl_subj,prob_outer = 0.95, 
                         point_est="mean")+
  geom_vline(xintercept=0)+#xlim(-500,200)+
  xlab("Estimate (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("Jäger et al 2020: \n Ungrammatical reflexives")+scale_color_grey()+scale_fill_grey()+magnifytext(sze=12)

p_agrrep<-mcmc_intervals(agr_subj,prob_outer = 0.95, 
                         point_est="mean")+
  geom_vline(xintercept=0)+#xlim(-500,200)+
  xlab("Estimate (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("Ungrammatical agreement")+scale_color_grey()+scale_fill_grey()+magnifytext(sze=12)

#dillonindplot<-multiplot(p_reflrep,p_agrrep,cols=2)

## ridges plot
agr_subj_long$dependency<-"agreement"
refl_subj_long$dependency<-"reflexive"

agr_refl_long<-rbind(agr_subj_long,refl_subj_long)
agr_refl_long$dependency<-factor(agr_refl_long$dependency)

dillonrepindplotridges<-ggplot(agr_refl_long,
                      aes(y=subject))+
  geom_density_ridges(
    aes(x=posterior,fill=dependency),
    scale=1,
    alpha=0.8, color="white")+xlim(c(-200,50))+
  #scale_color_grey()+scale_fill_grey()+
  geom_vline(xintercept=0)+  
  theme(axis.text.y = element_blank())
@


\begin{figure}[!hbtp]
\centering
<<echo=FALSE,fig.width=9,fig.height=11>>=
(dillonmeanplot) /
  (p_refl + p_agr)
@
\caption{Summary for total reading time dependent measures of the Dillon et al.\ (2013) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 40 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals.}\label{fig:dillonresults}
\end{figure}

\begin{figure}[!hbtp]
\centering
<<echo=FALSE,fig.width=9,fig.height=11>>=
(dillonrepmeanplot) /
  (p_reflrep + p_agrrep)
@
\caption{Summary for total reading time dependent measures of the J{\"a}ger et al.\ (2020) comparisons for ungrammatical sentences involving agreement and reflexives. The sample size was 181 participants. The upper plot shows the posterior distributions of the facilitatory interference effect in agreement and reflexives, and the lower plots show the individual-level estimates of the effect, with 80 and 95\% credible intervals.}\label{fig:dillonrepresults}
\end{figure}

In their paper, Dillon and colleagues argue that reflexives and agreement attraction constructions exhibit different interference profiles in ungrammatical constructions. In order to argue for a difference between agreement and reflexives with respect to the interference manipulation, an interaction must be demonstrated between dependency type and the interference manipulation. However, such an interaction was not seen \citep{JaegerMertzenVanDykeVasishth2019}.  

Thus, although the experiment design had the potential to demonstrate that dependency type determines whether interference occurs, the data don't seem to provide a basis for a conclusion. 

A major issue in the Dillon et al.\ study was that the sample size was quite small. 
We attempted to replicate the key results with a larger sample size (181 participants). This work is reported in full in \cite{JaegerMertzenVanDykeVasishth2019}.
Figure~\ref{fig:dillonrepresults} shows the results at the critical region (the auxiliary or reflexive). Figure~\ref{fig:dillonrepresults} shows that both agreement and reflexives in ungrammatical conditions seem to show similar \index{facilitatory interference} facilitatory interference effects in total reading times.

\subsection{Individual-level effects in the Dillon et al.\ design}

Figures~\ref{fig:dillonresults} and \ref{fig:dillonrepresults} show an interesting consistency across the original Dillon et al.\ study and the J\"ager et al.\ replication attempt: Essentially all the subjects show facilitatory interference effects in both agreement and reflexive constructions, in both experiments. In both studies, the magnitude of the effect varies in the two dependencies from subject to subject, but the sign is consistently negative. This is a potentially interesting pattern that could have a theoretical explanation. For example, some subjects might show very large facilitatory interference effects because  they are engaged in \index{good-enough processing} good-enough processing, or are not using syntactic constraints to complete dependencies to the same extent as other subjects, who show smaller facilitatory interference effects. This modulation of the effect size for individual subjects can be modelled in the \cite{LewisVasishth2005} architecture, as we show in section \ref{lv05predictions}.

\subsection{A sensitivity analysis on the ungrammatical agreement and reflexives conditions using informative priors}

An important objection to the replication data is that we do not use all available information in the models.
All the statistical models fit in \cite{JaegerMertzenVanDykeVasishth2019} used \index{mildly informative priors} mildly informative, \index{regularizing priors} regularizing priors, which effectively assume an agnostic starting point \citep{SchadEtAlWorkflow}. However, one of the key advantages of \index{Bayesian methods} Bayesian methods, which \cite{JaegerMertzenVanDykeVasishth2019} did not take advantage of, is that \index{prior knowledge} prior knowledge or beliefs about the plausible values of a parameter can be quantitatively taken into consideration by using an informative prior. 

Priors may arise from different sources, an obvious one being a body of empirical data on the specific issue in question.  When empirical data are scarce, other sources can be \index{expert opinion} expert opinion, which has been proposed in medical statistics \citep{ohagan2006uncertain,OakleyOHagan}, or via extensions of existing theories.  

Speaking informally, the posterior mean can be seen as a weighted sum of the prior mean and the sample mean, weighted by the relative precision (inverse of the variance) of the prior and the data. If the prior has relatively higher precision, it will dominate in determining the posterior mean, and if the data has higher precision (this is a function of standard deviation and the sample size), then the data will dominate in determining the posterior mean. A consequence of this fact is that when we have a very strong prior belief, expressed through a distribution with a relatively small standard deviation, even large amounts of data may not shift the posterior mean away from the prior mean. 

Hence, when investigating a controversial research question, it may be desirable to quantitatively take into account opposing theoretical views by using a representative spectrum of different priors. In this context, medical statisticians like \cite{spiegelhalter2004bayesian} have proposed the use of a \index{community of priors} ``community of priors'': opposing perspectives of researchers are  incorporated in the data analysis by using different priors.  In this way, one can use \index{agnostic priors} \textit{agnostic priors} (mildly informative priors), \textit{enthusiastic priors} that support a particular position, and \index{adversarial priors} \index{skeptical priors} \textit{adversarial or skeptical priors} that represent alternative positions. The different posterior distributions from the data can then be examined in the light of these priors, and the researcher can draw their own conclusion. 

We can examine next how agnostic, adversarial, and enthusiastic priors affect the posterior distributions of the effects of interest in the replication data. 
The case of ungrammatical agreement constructions is relatively uncontroversial and will therefore not show any influence of priors. 
More interesting is the effect of different prior specifications on the interference effects in ungrammatical reflexive conditions. How sensitive are these effects to the three types of priors?

We carried out a sensitivity analysis on the estimates for the  ungrammatical conditions, defining priors that represent three sources of beliefs. The different priors are summarized in Table~\ref{tab:sensitivityanalysis}. 

\begin{enumerate}
\item \textbf{Mildly informative priors (Agnostic prior)} As a baseline, we used a mildly informative prior for both the agreement and reflexive conditions. This prior represents an agnostic starting point where no information is incorporated from any prior knowledge.
\item \textbf{Meta-analysis priors (Adversarial prior for reflexives)}
We derived posterior distributions of the interference effect in ungrammatical agreement and reflexive conditions using data from existing reading time studies \citep{JaegerEngelmannVasishth2017}. These studies represent a synthesis of the evidence available from self-paced reading and eye-tracking studies on agreement and reflexives. Because the dependent measure of interest in our studies is total fixation time, the estimates from the eye-tracking studies are based on total fixation times. We refer to this prior as an adversarial prior because the estimate for ungrammatical reflexives is N(9,10.75), which is a relatively tight prior for the reflexives interference effect in our replication study.  A great deal of data would be needed to shift the posterior mean such that a facilitatory interference effect is seen. 
\item \textbf{LV05 priors (enthusiastic prior)} As a prior representing the equal cue-weighting retrieval proposal, we used a normal approximation of the range of predicted effects from the \cite{EngelmannJaegerVasishth2019} model. 
\end{enumerate}

\begin{table}[!htbp]
\begin{center}
\begin{tabular}{llll}
\multicolumn{4}{c}{\textbf{Sensitivity analysis}}\\
Condition & Source for Prior & Prior (ms) & Posterior (ms) \\
\hline
Agreement  & Mildly informative & N(0,7600) & -22 [-46,1]\\
(Ungram) & Meta-analysis  & N(-32,8.5) & -25 [-36,-14]\\
  & LV05 Model   &  N(-26,13) & -22 [-34,-7]\\
\hline                            
Reflexives  & Mildly informative & N(0,7600) & -24 [-50,2] \\
(Ungram) & Meta-analysis & N(9,10.75) & -3 [-17,12]\\ 
  & LV05 Model & N(-26,13) &  -22 [-38,-6]\\
 \hline                            
 \end{tabular}
\end{center}
\caption{Summary of the sensitivity analysis, investigating the effect of incorporating prior knowledge from: mildly informative priors; a meta-analysis of existing reading data on ungrammatical agreement and reflexives; and  the model predictions in Engelmann, J\"ager, and Vasishth, 2019. The dependent measure in the analysis is total fixation time and the posterior estimates are back-transformed to the ms scale from log ms. The priors are shown in the ms scales.}\label{tab:sensitivityanalysis}
\end{table}%

The results of this sensitivity analysis are shown in Table \ref{tab:sensitivityanalysis}.  Agreement conditions show similar facilitatory interference effects regardless of the prior chosen. 
This confirms that the agreement interference effect is robust to the choice of prior. For reflexives, the situation is different. 
The reflexive conditions show \index{facilitatory interference} facilitatory interference effects only when we use mildly informative priors and the LV05 predictions as priors.  With the relatively tight meta-analysis prior N(9,10.75), we see no indication of facilitatory interference effects in the replication data. 
Thus, for reflexives, the conclusion one can draw from these data is not as clear as for agreement; the conclusion  depends on the researcher's prior belief.  

\section{Concluding remarks}

The reading studies that have investigated different types of dependency constructions show some limited evidence for inhibitory and facilitatory interference, but what stands out from the reviewing the published evidence \citep{JaegerEngelmannVasishth2017} is the generally low statistical power of the published studies. If the meta-analytical estimates of inhibitory and facilitatory interference effects are accurate estimates of the true underlying effects, then none of the published reading studies so far can be considered properly powered for detecting the effects. We discuss the implications of this point about low power at length in several papers \citep{VasishthMertzenJaegerGelman2018,nicenboimexploratory,JaegerMertzenVanDykeVasishth2019,NicenboimPreactivation2019}.

This is a disappointing empirical starting point for evaluating the computational models considered in this book. As discussed in the previous chapter, one of the \citep{rp} criteria for a persuasive model fit---higher precision  data---has not yet been met in the literature.  Nevertheless, given the data that are available, it is possible to draw some initial conclusions  about the models' performance. That is what the rest of this book tries to achieve. Our hope is that some day there will be higher precision benchmark data for evaluating sentence processing models of the sort discussed here.      