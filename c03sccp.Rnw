\chapter{The core ACT-R-based model of retrieval processes} \label{c02}

% -*- root: ../phdthesis-FelixEngelmann.Rnw -*-

Any comprehensive theory of sentence comprehension needs to explain the mechanisms behind the formation of dependencies between non-adjacent words such as a verb and its subject. This process necessarily involves storing and accessing information in working memory.
There is a large body of evidence for a content-addressable memory architecture underlying human cognition in general \citep{WatkinsWatkins1975, AndersonLebiere1998,AndersonEtAl2004,Ratcliff1978} and sentence processing in particular \citep{McElree2000,McElreeForakerDyer2003, VanDykeLewis2003, LewisVasishth2005, VanDykeMcElree2011}. 

In a content-addressable memory, a cue-based retrieval mechanism can activate certain items in parallel on the basis of how well their properties, i.e., their \textit{features}, agree with a set of requirements, i.e. \textit{cues}, which are determined by the type of dependency.
This stands in contrast to search mechanisms which assume that items in memory are checked based on their location in memory, e.g., their serial order position \citep{Sternberg1966,Sternberg1969,BerwickWeinberg1984} or their position in a syntactic tree \citep{Sturt2003}. 

A cue-based model of sentence parsing has been described in 
\cite{VanDykeLewis2003}, \cite{LewisVasishth2005}, \cite{LewisVasishthVanDyke2006}, and \cite{VasishthLewis2006}. 
\cite{LewisVasishth2005} implemented the model in the cognitive architecture \emph{Adaptive Control of Thought Rational} (ACT-R, \citealp{AndersonLebiere1998, AndersonEtAl2004}) with the objective of grounding the means of language processing in general cognitive mechanisms.
The parser uses rapid associative memory retrievals to form inter-word dependencies, incrementally building a structural sentence representation. The success and latency of the retrieval process depends on the activation of syntactic representations, which is affected by time-based decay and interference from similar items.

\section{ACT-R}
ACT-R is a comprehensive, implemented theory which integrates processes of working memory access, rule-guided behavior, learning, sensual input, and motor control. 
It is a constantly developing framework that incorporates  findings from experimental work in various areas of cognitive psychology. 
ACT-R consists of a long-term memory of declarative and procedural knowledge and short-term buffers with limited capacity, representing a limited focus of attention \citep{McElree2006,Cowan2001,Miller1956}. 
Procedural knowledge is realized in the form of a production system \citep{Newell1973,Newell1978} that consists of condition-action pairs that operate on short-term, or \emph{working} memory. 

The contents of short-term memory buffers serve as conditions that trigger productions to fire. The result of a condition --- the manipulated buffer contents --- serve as condition for other productions. Hence, the  sequence of events is defined through condition-action specifications that operate by the serial firing of productions. 
At the same time, associated items are related by a mechanism of spreading activation that affects an individual item's activation dependent on the presence of related items. Memory items, so-called \emph{chunks}, enter the buffers by being retrieved from declarative memory. 
Memory items are accessed by a cue-based retrieval mechanism on the basis of their activation, which is subject to decay, reactivation, similarity-based interference, and noise.

Next, the equations that underlie ACT-R content-addressable memory access will be explained in a --- sometimes simplified --- way as they are relevant for the model of sentence comprehension described in \cite{LewisVasishth2005}.

In ACT-R, the probability and latency of retrieving a memory item
%, called a \textit{chunk}, 
is determined by its activation value. An item's activation fluctuates over time as the result of decay, reactivation, and noise. At the time of a retrieval request, a limited amount of activation spreads among all items in relation to their match with the retrieval specification, which is defined by a comparison of an item's \textit{features} with the retrieval \textit{cues}.

An item's final activation value is the sum of four components: A base-level $B_i$, which includes decay and frequency of use, the spreading activation $S_i$, which includes similarity-based interference, a penalty component $P_i$ for mismatches with the retrieval specification, and a random noise component $\varepsilon$.
 % The sum of these components yield the chunk activation at retrieval time: $A_i = B_i + S_i + P_i + \epsilon_i$.
% \begin{equation}\label{eq:act}
% 	A_i = B_i + S_i + P_i + \epsilon_i
% \end{equation}
The base-level activation $B_i$ is computed from a \textit{base-level constant} $\beta_i$ and the item's history of use:
\begin{equation}\label{eq:base}
	B_i = \log\left (\sum_{j=1}^n t_j^{-d}\right) + \beta_i
\end{equation}
where $n$ is the number of times the item was accessed in memory, $t_j$ is the time since the $j$th access, and $d$ is the \textit{decay parameter}. An item's activation decreases over time, with a decay parameter of $0.5$ by default, and receives a reactivation boost when it is accessed. 

At the time of a retrieval request, activation is spread from each retrieval cue to all matching items. This activation, however, is limited for each cue and distributed among the items that share the requested feature, i.e., the \emph{competitors}. The number of items competing for activation from a certain cue is called the \textit{fan}. An item with a high fan will thus receive less spreading activation than one with no competitors, i.e., it is inhibited by similarity-based interference or the so-called \textit{fan effect}.\footnote{Note that the description of ACT-R for the present purpose is simplified to reflect the way that it was used in the model of \cite{LewisVasishth2005}. In default ACT-R, spreading activation is not a property of retrieval cues per se. Rather, any buffer's content can spread activation to related items. Usually, the chunks in the goal buffer are the sources of spreading activation and, hence, of the fan effect. In the \cite{LewisVasishth2005} parser, the retrieval cues are always mirrored in the goal buffer, such that the model behaves as if spreading activation is specific to retrieval cues.}
The spreading activation component $S_i$ of item $i$ is summed over all cues $j \in J$ in the retrieval specification: 
\begin{equation}\label{eq:spread}
	S_i = \sum_j W_{j} S_{ji}
\end{equation}
where $W_{j}$ is the amount of activation from the cue $j$ and $S_{ji}$ is the strength of association between cue $j$ and item $i$. $S_{ji}$ is a function of the fan of item $i$ for cue $j$:%, which is the number of competitors that are similar with respect to cue $j$:
\begin{equation}\label{eq:fan}
	S_{ji} = S - \log(\textit{fan}_{ji})
\end{equation}
where $S$ is the \textit{maximum associative strength} (MAS). The fan of item $i$ for cue $j$ is defined by the number of competing items in memory that match the feature associated with $j$: $\textit{fan}_{ji} = 1+\textit{items}_j$.\footnote{In fact, all \textit{slots} in all memory items containing the feature are counted. For simplicity, we assume here that a linguistically relevant item will have a certain feature in only one slot.}
As a consequence, the spreading activation component $S_i$ increases the item's activation by Equation (\ref{eq:spread}) for each matching retrieval cue and reduces its activation by Equation (\ref{eq:fan}) for each distractor item that also (partially) matches the retrieval cues. Note that (\ref{eq:fan}) is the core equation of similarity-based interference in ACT-R as it defines the influence of competitors on an item's activation at the time of retrieval.

The final activation component assigns a penalty for mismatches. Some activation is subtracted for each retrieval cue $j$ that is not matched:
\begin{equation}\label{eq:pm}
	P_i = \sum_j PM_{ji}
\end{equation}
$P$ is the \textit{mismatch penalty parameter} (MP). $M_{ji}$ is the similarity between cue value $j$ and the value in the corresponding slot of item $i$. The similarity $M_{ji}$ is a value between $0$ (identity) and $-1$ (maximum difference).
This way, the more dissimilar a feature value of an item is to the cue value, the more activation is subtracted for this item.
If, for example, one defines some similarity between the color values \textit{red} and \textit{orange}, orange items would be less penalized than, e.g., blue items when cueing for a \actrcue{red}.

The item that is finally retrieved in a particular trial is the one that happens to have the highest activation. The time to retrieve an item $i$ is a function of its activation $A_i$:
\begin{equation}\label{eq:rt}
	RT = Fe^{-(f\times A_i)}
\end{equation}
where $F$ is the \textit{latency factor} (LF) and $f$ the \textit{latency exponent}. 
If no item has an activation above a certain threshold $\tau$, retrieval fails. The duration of a failed retrieval is calculated by the same equation (\ref{eq:rt}) with $A_i$ substituted with $\tau$.


\section{The Lewis \& Vasishth (2005) model}
The computational model of parsing difficulty developed by \cite{LewisVasishth2005} adopts ACT-R's general principles, a limited focus of attention and cue-based retrieval of memory items subject to fluctuating activation as a function of decay and retrieval history and similarity-based retrieval interference. An essential property of cue-based retrieval in contrast to structural search is that serial order information is not used in the search mechanism \citep{McElree2006,Ratcliff1978}. \cite{LewisVasishth2005} argue that this serves the speed of language processing where most dependencies can be established without serial order information, purely based on the items features and recency in terms of activation decay over time. The lack of immediate serial order information in incremental sentence processing  explains severe comprehension difficulty in cases where this information is needed, such as in double center-embeddings such as Example~(\ref{ex:centeremb}):

\begin{exe}
\ex \label{ex:centeremb}
The book that the editor who the receptionist married admired ripped.
\end{exe}  
%

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\textwidth]{figures/lv05-fig1-structure}
	\caption{Figure~1 of \cite{LewisVasishth2005}. Chunk representation.}
	\label{fig:lv05chunks}
\end{figure}

The model of \cite{LewisVasishth2005} implements knowledge of parsing in the form of production rules that incrementally build a structural representation in the fashion of a left-corner parser following X-bar syntax rules \citep{Chomsky1986}. 
Figure~\ref{fig:lv05chunks} from \cite{LewisVasishth2005} shows how sentence structure is represented in memory. Syntactic constituents are stored as single chunks being related to each other through feature slots for \emph{specifier}, \emph{complement}, and \emph{head}.
New structure is built at a new input word and then attached into previously built structure by retrieving a syntactic object that matches certain search cues like gender, number, syntactic category, and also information as to whether the relevant constituent is embedded or contains a gap waiting to be filled. 
%% TODO: example?
%
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\textwidth]{figures/lv05-fig2-buffers}
	\caption{Figure~2 of \cite{LewisVasishth2005}. Processing cycle.}
	\label{fig:lv05buffers}
\end{figure}
%
The productions essentially operate on four buffers, each holding one chunk: A control buffer (the goal buffer), a lexical buffer holding the lexicon entry corresponding to the current word, a retrieval buffer holding the syntactic chunk retrieved from memory, and a buffer for creating new structure.
%``These chunks also double as a representa- tion of the information in the control stack; a feature “next- goal” on each constituent chunk specifies the goal-category that should be pursued once the constituent is complete.''
The goal buffer contains some syntactic expectation in the form of a syntactic category that is necessary in order to complete the currently pursued structure.
Figure~\ref{fig:lv05buffers} from \cite{LewisVasishth2005} illustrates the cycle carried out at each input word: First, the corresponding lexical entry is accessed in the lexicon in declarative memory. Based on the lexical entry and on the current goal category, the cues for retrieving a matching constituent are specified and retrieval is initiated. Finally, a new syntactic node is created and attached to the one retrieved. Attention is then sent to the next word. The essential step is memory retrieval. Through ACT-R's independently motivated principles of cue-based working memory access, the simulations in \cite{LewisVasishth2005} provide quantitative predictions for effects of distance, structural interference, and embedding type in sentence comprehension.

% TODO: ambiguity resolution

% Using the model's predictions of parsing duration,  explained effects of distance and structural interference in sentence processing in terms of independently motivated principles of working memory access.  
The parsing architecture has been further used to model important aspects of sentence comprehension such as anti-locality \citep{VasishthLewis2006}, intrusive interference in negative polarity constructions \citep{VasishthBruessowLewis2008}, interference effects in reflexive processing \citep{PatilVasishthLewis2012,ParkerPhillips2014,JaegerEngelmannVasishth2015} and subject-verb processing
\citep{WagersLauPhillips2009,DillonMishlerSloggett2013}, and impaired sentence comprehension in aphasia \citep{PatilEtAl2016,MaetzigEtAltopics2018}.

\subsection{A priori predictions of the model} \label{lv05predictions}

Figures~\ref{fig:plotmatch} and \ref{fig:plotmismatch} show the range of predicted retrieval time (in milliseconds) for target match and mismatch conditions respectively, for a range of parameter values. 

<<predictions,echo=FALSE,include=FALSE>>=
## cue weight 1:
load("data/lv05pspaceEVcuewt1.Rd")
means1<-lv05pspaceEVcuewt1
## cue weight 2:
load("data/lv05pspaceEVcuewt2.Rd")
means2<-lv05pspaceEVcuewt2
## cue weight 4:
load("data/lv05pspaceEVcuewt4.Rd")
means4<-lv05pspaceEVcuewt4

means<-rbind(means1,means2,means4)

means$Target <- factor(means$Target, labels=c("Target-Match", 
                                              "Target-Mismatch"))

match<-subset(means,Target=='Target-Match')
mismatch<-subset(means,Target=='Target-Mismatch')

match_reduced<-match[,c(3,5,7,9,10,11,19)]
#dim(match_reduced)
#head(match_reduced)
#summary(match_reduced)
## plot only the predictions for the LF parameter range actually used in EJV2019 paper.

match_reduced$ans<-factor(match_reduced$ans)
#levels(match_reduced$ans)[levels(match_reduced$ans)==0.1]  <- "Noise: 0.1"
#levels(match_reduced$ans)[levels(match_reduced$ans)==0.2]  <- "Noise: 0.2"
#levels(match_reduced$ans)[levels(match_reduced$ans)==0.3]  <- "Noise: 0.3"

match_reduced$mp<-factor(match_reduced$mp)
#levels(match_reduced$mp)[levels(match_reduced$mp)=="0.15"]  <- "Mismatch penalty: 0.15"
#levels(match_reduced$mp)[levels(match_reduced$mp)=="0.25"]  <- "Mismatch penalty: 0.25"
#levels(match_reduced$mp)[levels(match_reduced$mp)=="0.35"]  <- "Mismatch penalty: 0.35"

match_reduced$threshold<-factor(match_reduced$rth)
#match_reduced$mas<-factor(match_reduced$mas)

match_reduced$cueweighting<-factor(match_reduced$cueweighting)
levels(match_reduced$cueweighting)[levels(match_reduced$cueweighting)=="1"]  <- "Cue-weights: 1:1"
levels(match_reduced$cueweighting)[levels(match_reduced$cueweighting)=="2"]  <- "Cue-weights: 2:1"
levels(match_reduced$cueweighting)[levels(match_reduced$cueweighting)=="4"]  <- "Cue-weights: 4:1"


plot_match<-ggplot(match_reduced, aes(x=lf, 
                                      y=Effect, 
                         color = mas)) +
  #scale_shape_manual(values=c(0,16,2))+
  #scale_colour_manual(values=c("gray10","gray30","gray60"))+
  #scale_colour_gradient(low="gray10", high="gray60",trans="reverse")+
  geom_point(size=3,position=position_jitter(width=0.01, height=0.01))+
  #facet_wrap( ~ factor(ans)+factor(mp), nrow=3)+
    theme_bw()+xlab("latency factor")+ylab("Interference  effect  (ms)")+theme(axis.title.y = element_text(angle = 90))+ggtitle("Target match")+theme(
    legend.position = c(.1, .95),
    legend.justification = c("left", "top"),
    legend.box.just = "left",
    legend.margin = margin(6, 6, 6, 6)
    )

plot_match+facet_wrap( ~ cueweighting, ncol=3)+
  theme(strip.text = element_text(face="bold", size=rel(1.5)),
              strip.background = element_rect(fill="lightblue", colour="black",size=1))

## mismatch data:
mismatch_reduced<-mismatch[,c(3,5,7,9,10,11,19)]

mismatch_reduced$ans<-factor(mismatch_reduced$ans)
#levels(mismatch_reduced$ans)[levels(mismatch_reduced$ans)==0.1]  <- "Noise: 0.1"
#levels(mismatch_reduced$ans)[levels(mismatch_reduced$ans)==0.2]  <- "Noise: 0.2"
#levels(mismatch_reduced$ans)[levels(mismatch_reduced$ans)==0.3]  <- "Noise: 0.3"

mismatch_reduced$mp<-factor(mismatch_reduced$mp)
#levels(mismatch_reduced$mp)[levels(mismatch_reduced$mp)=="0.15"]  <- "Mismatch penalty: 0.15"
#levels(mismatch_reduced$mp)[levels(mismatch_reduced$mp)=="0.25"]  <- "Mismatch penalty: 0.25"
#levels(mismatch_reduced$mp)[levels(mismatch_reduced$mp)=="0.35"]  <- "Mismatch penalty: 0.35"

mismatch_reduced$threshold<-factor(mismatch_reduced$rth)
#mismatch_reduced$mas<-factor(mismatch_reduced$mas)

mismatch_reduced$cueweighting<-factor(mismatch_reduced$cueweighting)
levels(mismatch_reduced$cueweighting)[levels(mismatch_reduced$cueweighting)=="1"]  <- "Cue-weights: 1:1"
levels(mismatch_reduced$cueweighting)[levels(mismatch_reduced$cueweighting)=="2"]  <- "Cue-weights: 2:1"
levels(mismatch_reduced$cueweighting)[levels(mismatch_reduced$cueweighting)=="4"]  <- "Cue-weights: 4:1"

plot_mismatch<-ggplot(mismatch_reduced, aes(x=lf, 
                                      y=Effect, 
                         #shape = mas, 
                         color = mas)) +
  #scale_shape_manual(values=c(0,16,2))+
  #scale_colour_manual(values=c("gray10","gray30","gray60"))+
  #scale_colour_gradient(low="gray10", high="gray60",trans="reverse")+
  geom_point(size=3,position=position_jitter(width=0.01, height=0.01))+
  #facet_wrap( ~ factor(ans)+factor(mp), nrow=3)+
    theme_bw()+magnifytext(sze=20)+xlab("latency factor")+
  ylab("Interference effect (ms)")+
  theme(axis.title.y = element_text(angle = 90))+ggtitle("Target mismatch")+
  theme(
    legend.position = c(.95, .5),
    legend.justification = c("right", "top"),
    legend.box.just = "left",
    legend.margin = margin(6, 6, 6, 6)
    )

plot_mismatch+facet_wrap( ~ cueweighting, ncol=3)+
  theme(strip.text = element_text(face="bold", size=rel(1.5)),
              strip.background = element_rect(fill="lightblue", colour="black",size=1))

#multiplot(plot_match,plot_mismatch,cols=2)
@



\begin{figure}[!htbp]
\centering
\includegraphics[height=18cm,width=15cm]{figures/priorpredictions}
\caption{Predicted reading times of the LV05 model for the target-match and mismatch configurations, where the noise parameter has value 0.2; the mismatch penalty parameter has value 0.15; retrieval threshold has value -1.5;  the LF parameter values come from a Normal distribution with mean 0.3 and standard deviation 0.1; and the maximum associative strength comes from a Normal distribution with mean 1.5 and standard deviation 0.25.}\label{fig:plotmatch}
\end{figure}

%\include{c02coremodelevalSCCPVasishthEngelmann.tex}
%%begin
\subsection{Predictions of the Lewis \& Vasishth (2005) model for target-match and target-mismatch configurations} \label{core03predictions}

\begin{figure}[!htbp]
\includegraphics[width=\textwidth]{figures/tableLV05pred}
    \caption{\revFE{Spreading activation according to ACT-R/LV05 in the four conditions shown in Example~\ref{ex:sturt03:exp2}.}
    Line weights indicate the amount of spreading activation from a cue to an item. Black oval boxes represent a feature match.
    % features receiving the maximum spreading activation. 
    Gray oval boxes indicate features matching an `overloaded' cue (\actrcue{MASC} in b), and white boxes indicate a mismatch. The figure is by Engelmann and Vasishth, 2019; available at http://dx.doi.org/10.6084/m9.figshare.9305456 under a CC-BY4.0 license.}
    \label{fig:ACTRpred}
\end{figure}

See Figure~\ref{fig:ACTRpred} for a graphical representation of the model predictions for Example~\ref{ex:sturt03:exp2}. The oval boxes indicate matching (black or gray) or mismatching (white) features of an item with respect to the retrieval cues. The darker the boxes, the better the match of the item and the higher its \textbf{activation level}.
The relative activation levels of memory items in ACT-R determine which item will be retrieved.
\revVI{All items available in memory enter into a race at the time of retrieval, such that the one which happens to have the highest activation is retrieved.} 
Thus, only one ``winning'' item is ever retrieved in any one trial. The higher the activation of the ``winning'' item, the faster the retrieval time. 
Each item $i$ has a \textbf{base-level activation} $B_i$  that reflects past usage by accounting for all reactivation events ($t_j$ represents the time elapsed since the $j$-th activation) and a time-based decay with rate $d$ (this usually has the default value $0.5$ in ACT-R):% (\ref{eq:bl}).

\begin{eqnarray}
  % A_i = B_i + S_i + \epsilon \label{eq:act}\\
  B_i = \text{ln}(\sum_{j=1}^n t_j^{-d}) + \beta_i \label{eq:bl}
\end{eqnarray}

% \begin{equation}
%     \textit{RT} = Fe^{-(f\times A_i)} \label{eq:rt}
% \end{equation}

\noindent
In the above equation, $\beta_i$ is the resting-state activation for item $i$, and $n$ indexes the number of times that the item $i$ has been retrieved in the past.

In addition to the base-level activation, \textbf{spreading activation} is added to every (partially) matching item at the time of retrieval. The spreading activation component is the main source of similarity-based interference effects in ACT-R. 
An item receives spreading activation from all matching cues $j$ depending on the \emph{associative strength} $S_{ji}$ between cue $j$ and item $i$ and the cue's weight $W_{j}$; see Equations~\ref{eq:spread} and \ref{eq:assoc}. $W_j$ is standardly set to \revFE{$1/\textit{number of cues}$}, meaning that all cues are weighted equally. We are adopting this standard assumption throughout this work.  The implications of cue-weighting are discussed in \citep{VasishthEtAlTiCS2019,JaegerMertzenVanDykeVasishth2019}. 

\begin{equation}
      S_i = \sum_j W_{j} S_{ji} \label{eq:spread}
\end{equation}

The arrows in Figure~\ref{fig:ACTRpred} show how activation from the retrieval cues is distributed to the target and the distractor based on their features. The thickness of the lines with arrows indicates the amount of spreading activation that is added to an item due to that feature.
In Figure~\ref{fig:ACTRpred}a (cf.\ Example~\ref{ex:sturt03:exp2}a), the target is a full match for the set of retrieval cues, \actrcue{masc} and \actrcue{ccom}. Both cues are also \emph{unambiguous} because they are matched by the target only and not by the distractor. The target thus receives the maximal amount of spreading activation at retrieval. By contrast, 
in the interference condition b in Figure~\ref{fig:ACTRpred} and Example~\ref{ex:sturt03:exp2}, the gender cue is matched by the distractor in addition to the target. Thus, the \actrcue{MASC} cue is now \emph{ambiguous}, or ``overloaded'' \citep{WatkinsWatkins1975}. \revFE{This \textbf{cue overload} has the consequence} that the activation from this cue is now split between the target and the distractor. 
This follows from Equation \ref{eq:assoc}: The associative strength between a cue and an item is reduced in relation to the \emph{fan} --- the number of items associated with the cue (\textit{MAS} is the value of the \emph{maximum associative strength}).

\begin{equation}
  S_{ji} = \textit{MAS} - \text{ln}(\textit{fan}_{j}) \label{eq:assoc}%\\
  % \textit{fan}_{ji} = 1+\textit{items}_j \label{eq:fan}
\end{equation}

Each cue distributes the \emph{limited} available activation equally between all matching items (with the maximally available amount being $W_j\times\textit{MAS}$).
The more competitor items are present that match a cue $j$, the weaker the association $S_{ji}$ of this cue with the item $i$. In other words, each competitor \revFE{reduces the spreading activation to the target by some amount and thus makes it harder to be distinguished} from the other items.
This is called the \textbf{fan effect} \citep{anderson1974retrieval}. 
In our example (Figure~\ref{fig:ACTRpred} and Example~\ref{ex:sturt03:exp2}), the fan effect causes a reduction of the spreading activation received by the target in b in comparison with a, thus reducing the target's total activation, which is the sum of the base-level $B_i$ and the spreading activation $S_i$ plus Gaussian noise $\epsilon_i$, where $\epsilon_i$ is sampled from a normal distribution with mean 0 and some standard deviation $\sigma$ (Equation~\ref{eq:act}). 

\begin{equation}
  A_i = B_i + S_i + \epsilon_i  \hbox{, where } \epsilon_i \sim Normal(0,\sigma)  \label{eq:act}
  % B_i = \text{ln}(\sum_{j=1}^n t_j^{-d}) + \beta_i \label{eq:bl}
\end{equation}

A decrease in activation causes the retrieval time \revFE{(also called \emph{retrieval latency})} \textit{RT}$_i$ to increase. As shown in Equation~\ref{eq:rt}, the \revFE{retrieval latency} of an item is a negative exponential function of its activation at the time of retrieval, where $F$ and $f$ are two scaling parameters --- the \emph{latency factor} and the \emph{latency exponent}, respectively.

\begin{equation}
  \textit{RT}_i = Fe^{-(f\times A_i)} \label{eq:rt}
\end{equation}

Hence, the similarity in gender between target and distractor in target-match configurations shown in Figure~\ref{fig:ACTRpred} a vs.\ b predicts a slower retrieval latency due to the fan effect, \revFE{i.e., inhibitory interference}.
\revFE{
At any retrieval event, only the item with the highest activation at that moment is retrieved, and only when its activation is equal or above the retrieval threshold $\tau$. Therefore, the processing time at the word where the retrieval is triggered is dependent only on the time it takes to retrieve the item that happens to have a higher activation, i.e., the winner.
Due to the Gaussian noise component in Equation~\ref{eq:act}, activation fluctuates, such that there is always the possibility --- depending on the relative difference in activation between target and distractor --- of a \textbf{misretrieval}, i.e., that the distractor is erroneously retrieved instead of the target. 
Therefore, because of the increased distractor activation in \ref{fig:ACTRpred}b, there is a higher probability for misretrievals in b compared to a.}\footnote{%
In an alternative model of cue-based retrieval proposed by \cite{McElree2003}, the direct-access model, interference is only reflected in a decreased retrieval probability of the target but not in retrieval time. 
  Effects observed in reading times are then explained as a by-product of changes in the retrieval probabilities. The idea here is that misretrievals may trigger a reanalysis process that inflates reading times \citep{McElree1993}. For an implementation and quantitative comparison of the direct-access model \citep{McElree2003} with the LV05 model, see \cite{NicenboimRetrieval2018}.}


\revIV{In target-mismatch configurations (c and d of Fig.~\ref{fig:ACTRpred} and Ex.~\ref{ex:sturt03:exp2}), the predictions for retrieval latencies are different from those in target-match configurations.}
In c and d, the target is only a partial match as it does not exhibit the correct gender feature \match{fem}. When the distractor matches the gender in d, there is, however, no reduction in the target's activation. The reason is that both cues \actrcue{fem} and \actrcue{ccom} are only matched by one item each and are thus not ambiguous. Hence, no fan effect and no inhibitory interference is predicted.
However, since target and distractor now both receive the same amount of spreading activation --- each matches exactly one cue --- their activation levels are relatively close to each other. 
Because activation fluctuates due to the random noise component in Equation~\ref{eq:act}, \revV{when two items receive the same amount of spreading activation from their match with the retrieval cues, the winning item at the time of retrieval is chosen randomly with a probability of around 0.5}.
Since the winner is always the item with the highest activation --- i.e., the shortest retrieval latency --- at the time of retrieval, this fulfills the conditions of a \emph{race process}. As shown in Figure~\ref{fig:raceproc}, in a race process, when the finishing times of two items' retrieval times can be described by distributions that have similar means, the retrieval times of the winner (which can differ from trial to trial) will have a distribution that has a smaller mean than the means of the two items' retrieval time distributions. This is called \textbf{statistical facilitation} \citep{raab1962division}. A race process therefore has the effect that, \textit{on average} over multiple trials, the retrieval latency is shorter when the two competing items have similar mean retrieval times than when there is a clear winner due to a bigger difference in retrieval latency as is the case in condition c \citep[e.g.,][]{LogacevVasishth2015}.


\begin{figure}[!htbp]
\centering
\includegraphics[width=.9\textwidth]{figures/fig-raceproc1}
\caption{An illustration of a race process involving two distributions that represent retrieval time distributions of two items. When the two distributions have similar means (Figure A), the distribution of the retrieval times of the winner (which may differ from trial to trial) will have a distribution with a mean that is lower than the mean of the two distributions involved in the race (statistical facilitation). When one distribution has a much smaller mean than the other distribution's mean (Figure B), the distribution of the winner's retrieval times will have the same mean as that of the distribution of the item with the smaller mean.}\label{fig:raceproc}
\end{figure}


Because of this statistical facilitation, the prediction for target-mismatch configurations in Figure \ref{fig:lv05plots}d vs. \ref{fig:lv05plots}c is a speed-up on average over multiple trials, i.e., facilitatory interference.




\subsection{Comparison of the LV05 prediction space with the results of the meta-analysis}


\begin{figure}[htbp]
\centering
\includegraphics[width=.8\textwidth]{figures/fig-lv05plots1} 
\caption{Prediction space for the interference effect in ACT-R in target-match (circles, solid line) and target-mismatch configurations (triangles, broken line). Interference is plotted in terms of the difference in mean retrieval latencies between the interference (distractor-match) and the no-interference (distractor-mismatch) condition, and as a function of the latency factor $F$. Positive values indicate longer mean retrieval latencies in the interference condition (\emph{inhibitory interference}) due to cue-overload (fan effect) from a partially matching distractor; negative values indicate shorter mean retrieval latencies in the interference condition (\emph{facilitatory interference}) due to retrievals of the partially matching distractor on trials where the distractor is highly activated and hence fast. Each individual data point represents the mean interference effect of 6,000 iterations with one out of 10,980 different parameter settings (each in target-match and target-mismatch configurations; i.e., there are 21,960 data points plotted in total). Each parameter setting is a combination of the following parameter values: latency factor $\protect F \in \{0, 0.01, ..., 0.6\}$, noise parameter $\protect \textit{ANS} \in \{0.1, 0.2, 0.3\}$, maximum associative strength $\protect \textit{MAS} \in \{1,2,3,4\}$, mismatch penalty $\protect \textit{MP} \in \{0,1,2\}$, retrieval threshold $\protect \tau \in \{-2,-1.5,...,0\}$.}\label{fig:lv05plots}
\end{figure}

\subsubsection{Methods}
\label{sec:generalmethods}
All simulations part of the present work were run in \R{} \citep{R2016} using the ACT-R equations specified above or --- for the extended model --- specified on pages \pageref{sec:impl}ff. Additional components of the model that were left out in order not to disrupt the reading flow are provided in Appendix~\ref{sec:modelappendix}. All model parameters and their values --- if not specified otherwise --- are summarized in Appendix Table~\ref{tbl:params}. 
Simulations were run over a number of trials (and in some cases for a number of parameter values) such that results always represent means. 
Each iteration generated retrieval time predictions for the four conditions shown in Figure~\ref{fig:ACTRpred}, which were simulated by specifying the respective match between cues and target and distractor respectively as follows: 
At retrieval, two memory items were available and two retrieval cues were specified. The first (structural) cue was matched by one memory item in all conditions, which distinguished this item as the target.\footnote{We acknowledge that the representation of the structural binding requirement as a single cue is a simplification. Theoretically, anaphor binding would require an item to be c-commanding and within the anaphor's binding domain. In some of the studies simulated here, the distractor mismatches both of the requirements and in some studies it mismatches only one of them. 
	However, the number of overloaded cues that stay unchanged across conditions (i.e., match the same items in all conditions) does not affect the predictions because an interference effect arises in the model due to the difference in matched cues between conditions. In the case where the distractor mismatches two structural cues instead of one, the distractor would receive less spreading activation in all conditions. As a consequence, the predicted sizes of the effects would be smaller. Qualitatively, however, the results would not change.}
The second cue was matched by the target in conditions a and b (target-match) and by the distractor in conditions b and d (distractor-match).
The predicted interference effect was determined for target-match and target-mismatch configurations separately by subtracting the retrieval latency in the distractor-mismatch condition (no interference) from that of the distractor-match condition (interference).  


\subsubsection{Results}
Figure~\ref{fig:lv05plots} shows the range of possible predictions for the interference effect in target-match and target-mismatch configurations based on the four conditions shown in Figure~\ref{fig:ACTRpred}.
The simulations covered range of values for the most relevant ACT-R parameters (see figure caption), which were chosen such that the simulated parameter space included all values commonly used in ACT-R simulations.

Values above zero indicate \emph{inhibitory} interference (slow-down) and values below zero indicate \emph{facilitatory} interference (speed-up). 
Along the x-axis of Figure~\ref{fig:lv05plots}, increasing values of the latency factor $F$ are plotted, which is usually the most freely varied parameter in ACT-R models and simply scales the retrieval latency. 
While there is variation in the mean interference effect along different parameter values, the figure clearly shows that the predictions of the LV05 model are restricted to \emph{inhibitory interference} in \emph{target-match} configurations (caused by the fan effect) and \emph{facilitatory interference} in \emph{target-mismatch} configurations (caused by the race process between target and distractor).\footnote{
\revisedII{
	Note that, in Figure~\ref{fig:lv05plots}, there are $334$ out of $10980$ simulated data points in target-mismatch configurations that show \textit{inhibitory} interference. These are associated with a specific parameter configuration, namely, with a high retrieval threshold ($0$) and a low maximum associative strength ($1$). These outcomes are therefore most likely related to retrieval failures. For this reason, and because the effects are small and make up only $3\%$ of target-mismatch data points, we do not consider inhibitory target-mismatch effects a systematic prediction of LV05.
}
}


% TODO: Include cunnings and sturt


How well do these predictions fare compared to the evidence published in the literature? It turns out that the answer is: not very well. 
\revSV{
A comprehensive systematic review and meta-analysis of reading studies on interference by \cite{JaegerEngelmannVasishth2017} provides a basis for comparing model predictions with available data. This meta-analysis took into account $77$ published experimental comparisons that investigated target-match and target-mismatch configurations for three dependency types.
Table~\ref{tab:resultsMeta1} summarizes the quantitative results of the meta-analysis.
The table shows the mean effect estimates   
and 95\% credible intervals, which mark the uncertainty of the estimates.\footnote{
	95\% credible intervals are computed within the Bayesian data analysis framework \citep{Gelman14}. \revIV{The range specified by a 95\% credible interval contains the true value of the estimated parameter with 95\% certainty, given the model and the data.}
}  
}

In \cite{JaegerEngelmannVasishth2017}, subject-verb dependencies were divided into \textit{agreement} dependencies \citep[e.g.,][]{WagersLauPhillips2009,Pearlmutter1999} and \textit{non-agreement} dependencies \citep[e.g.,][]{VanDyke2007,VanDykeMcElree2011}, because these constitute two distinct lines of research and usually show different patterns. While agreement studies have focused on effects of number attraction, non-agreement studies investigated interference effects involving other semantic and syntactic cues.
Reflexive-antecedent and reciprocal-antecedent dependencies were treated as one category in the meta-analysis because both follow a similar syntactic constraint and the data of only two publications on reciprocals were available when the \cite{JaegerEngelmannVasishth2017} article was published.

Clearly, the model cannot account for all the findings of the meta-analysis shown in Table~\ref{tab:resultsMeta1}. 
In \emph{target-match} configurations, the predicted inhibitory effect was found only for non-agreement subject-verb dependencies. The other dependency types did not provide enough evidence for any effect in target-match configurations; however, these cases may not necessarily be problematic for the model because of the generally low power of the published studies  \citep[see][for discussion]{NicenboimEtAlCogSci2018,JaegerEngelmannVasishth2017,VasishthMertzenJaegerGelman2018,JaegerMertzenVanDykeVasishth2019}. 
Most problematic for the model predictions in target-match configurations are individual studies that found a facilitatory effect. 
For \emph{target-mismatch} configurations, the prediction of a facilitatory effect is only supported by subject-verb agreement studies; reflexive-/reciprocal-antecedent dependencies show inhibition. For non-agreement subject-verb dependencies, no target-mismatch data were available at the time of the meta-analysis. However, two recent studies show evidence for the predicted facilitatory effect in target-mismatch configurations in reflexives \citep{parker2017reflexive} and in non-agreement subject-verb dependencies \citep{CunningsSturt2018}. \revised{Furthermore, we have recently established in a relatively large-sample (181 participants) eyetracking experiment \citep{JaegerMertzenVanDykeVasishth2019} that in total fixation time, target-mismatch configurations in English reflexives show facilitation effects, as predicted by the ACT-R model. Compare this to one of the studies in the meta-analysis  \citep{DillonMishlerSloggett2013}, which had a relatively small sample size (40 participants) and found no evidence for facilitatory interference in the target-mismatch reflexive construction.}

As discussed in \cite{JaegerEngelmannVasishth2017}, one important observation here is that in both 
target-match and target-mismatch configurations, the individual results of different studies show a considerable range of variability, ranging from facilitatory to inhibitory interference.
Later, we explore to what extent an extension of LV05 with independently motivated assumptions can explain the observed variability.
We will do this in two parts: We first look at the principal consequences of taking into account item prominence, i.e., the strength of the distractor's representation in memory relative to the target's, and then explore possible cases and consequences of multi-associative cues. In both sections, we compare empirical evidence with the prediction space of the revised model that we present. By accounting for item prominence and cue associations on the level of individual studies, the revised model is able to explain some of the facilitatory effects in subject-verb agreement target-match configurations and inhibitory effects in reflexive/reciprocal dependency target-mismatch configurations (as indicated in columns six and seven in Table~\ref{tab:resultsMeta1}). The apparent absence of a clear effect in the results of the meta-analysis for reflexive/reciprocal dependency target-match configurations can be explained by a mixture of inhibitory and facilitatory effects predicted by the revised model in a principled way as a result of different levels of distractor prominence in individual studies.
We then spell out how our revisions to the model are implemented and, finally, present quantitative simulations of the individual studies included in the \cite{JaegerEngelmannVasishth2017} meta-analysis, comparing the estimates from the empirical data with the results of both LV05 and the revised model.
%%END of paper extract

%% start of new modeling post 2019

\newpage

\section{Modelling average effects and subject-level variability}

In this section, we illustrate how model fit can be carried out using a Bayesian parameter estimation approach called Approximate Bayesian Computation. The ABC approach is useful when the model cannot easily be  expressed as a likelihood. In the discussion below, we demonstrate how ABC could be used in future work to evaluate model predictions, for both average effects and for  individual-level effects.

The section below reuses material from \cite{VasishthMethodsX2019}, copyright Elsevier, and is reproduced with permission.
%%to-do: add permission number.

\subsection{Bayesian parameter estimation}

In the Bayesian parameter estimation framework, given a vector of data $y$ and a vector of model parameters $\theta$ that have prior distributions $p(\theta)$ defined on them, a likelihood function for the data $p(y\mid \theta)$ and the priors allow us to compute the posterior distribution of the parameters given the data,  $p(\theta\mid y)$. This is possible because of Bayes' rule, which states that the posterior is proportional to the likelihood times the prior:

\begin{equation}
p(\theta\mid y ) \propto p(y\mid \theta)p(\theta)
\end{equation}

The posterior distributions of parameters are generally computed using Monte Carlo Markov Chain methods. Examples are Gibbs sampling, Metropolis-Hastings, and (more recently) Hamiltonian Monte Carlo \citep{lunn2012bugs,Gelman14}.

The likelihood and the priors together constitute the model, which we will call $\mathcal{M}$ hereafter. Given a particular model  $\mathcal{M}$, one important question wee usually have is: what predictions does the model make? The model makes two kinds of predictions: a priori predictions, before any data have been taken into account; and a posteriori predictions, after the data have been taken into account.  The distributions of these two kinds of predictions are called \textit{prior predictive distributions}, and \textit{posterior predictive distributions}, respectively. 

The prior predictive distribution can be computed by drawing random samples of the parameters $\tilde{\theta}$ from $p(\theta)$, and then using these values to simulate data $\tilde{y}$ from the likelihood $p(y\mid \tilde{\theta})$. 

The posterior predictive distribution $p(y_{pred}\mid y)$ can be computed once we have the posterior distribution of the parameters, $p(\theta \mid y)$. Here, we assume that past and future observations are conditionally independent given $\theta$.

\begin{equation}
p(y_{pred}\mid y) = \int p(y_{pred} \mid \theta) p(\theta \mid y)\, d\theta
\end{equation}

An important point to note here is that we are conditioning $y_{pred}$ only on $y$. We do not condition on the unknown parameters $\theta$; we simply integrate these unknown parameters out. This allows us to take the uncertainty of the posterior distributions of the parameters into account, giving us more realistic estimates of the predictions from the model. Contrast this with a situation where we condition on, e.g.,  maximum likelihood estimates of the parameters; that is,  we condition on a point value, not taking the uncertainty of that estimate into account.

\subsection{Approximate Bayesian Computation}

Approximate Bayesian Computation (ABC) \citep{SissonABC} is a method for estimating posterior distributions of parameters in a model. ABC is useful when Bayes' rule cannot be employed to draw samples from the posterior distributions; this situation arises when the generative model cannot be easily expressed as a likelihood function. For extensive treatments of the theory and practical aspects of ABC, see \cite{SissonABC,palestro2018likelihood}.  The algorithm used here is rejection sampling; see Listing~\ref{alg:abcrejection} for pseudo-code describing the algorithm.

\begin{algorithm}[H]
\SetAlgoLined
%\KwResult{Write here the result }
\KwIn{Tolerance bounds $lower$ and $upper$ from data}
\Begin{\For{$i$ in 1:N\_Simulations}{
  Take one sample from prior $\pi(\theta)$\;
  Generate predicted mean effect $\tilde{\bar{y}} \sim Model(\theta)$\;
  \If{$lower \leq \tilde{\bar{y}} \leq upper$}{
  $\hbox{Save } \theta \hbox{ value as sample from posterior}$\;
  }
  \Else{Discard $\theta$ sample\;
  }
}
}
\caption{ABC using rejection sampling. Shown is the case where we need to sample posterior values for a single parameter $\theta$. Each iteration of the  algorithm consists of drawing a single random sample from a prior distribution for the parameter (here, $Beta(2,6)$), and then generating the predicted mean effect from the model using that sampled parameter value. If the predicted mean effect is near the observed data (in our implementation, if the predicted effect lies within one standard error of the mean effect of interest), then accept the sampled parameter value; otherwise reject that sampled value. This process is repeated until we have sufficient samples from the posterior distribution of the parameter. These samples therefore constitute the posterior distribution of the parameter.} \label{alg:abcrejection}
\end{algorithm}

\subsubsection{Step 1: Define a prior for the parameter}

We begin by defining a prior distribution on the latency factor in the cue-based retrieval model. Several priors can be considered here: a Uniform prior or a Beta prior are examples. For illustration, we use the Beta(2,6) prior. As shown in Figure~\ref{fig:betaprior}, this is a relatively uninformative prior which downweights very small and very large values of the latency factor parameter.

\begin{figure}[!htbp]
\centering
<<betaprior,echo=FALSE,eval=TRUE,fig.height=5>>=
library(ggplot2)
x_temp<-rbeta(1000000,2,6)
latency_factor_prior<-data.frame(x_temp=x_temp)
prior_lf<-ggplot(latency_factor_prior,aes(x=x_temp))+geom_histogram(aes(y=..density..),position="identity",fill="gray",binwidth=0.01)+theme_bw()+theme(strip.text.x = element_text(size = 16, colour = "black", angle = 0))+
  xlab("latency factor")+
  ggtitle("Prior on latency factor")+theme_bw()+
  magnifytext(sze=12)
prior_lf
@
\caption{A Beta(2,6) prior on the latency factor.}\label{fig:betaprior}
\end{figure}


\subsubsection{The estimates from data for ungrammatical conditions}

In the ungrammatical conditions of the \cite{DillonMishlerSloggett2013} data, the estimate of the interference effect in agreement conditions is -60 ms, Credible interval (CrI) [-112, -5] ms. Taking a normal approximation, this implies an effect coming from the distribution $Normal(-60,33^2)$.
Similarly, the estimate of the interference effect in reflexive conditions is -18 ms, CrI [-72, 36] ms, which corresponds approximately to the $Normal(-18,27^2)$.

We can use these normal approximations to define a lower and upper bound for the ABC algorithm: one standard deviation about the observed mean. The acceptance criterion of the ABC algorithm is that the predicted value generated by the model lies within one standard deviation of the sample mean from the data.

<<dillonestimates,echo=FALSE>>=
## our data from one subject in one pair of conditions (difference in means):
xbar_au_d13<- -60
## 1 SD above and below mean
lower_au_d13 <- -93
upper_au_d13 <- -27

xbar_ru_d13<- -18
## 1 SD above and below mean
lower_ru_d13 <- -45
upper_ru_d13 <- 9
@

In the \cite{JaegerMertzenVanDykeVasishth2019} data, 
the estimate of the interference effect in agreement conditions is -22 [-46, 3], which can be approximated by the  $Normal(-22,13^2)$. The estimate in reflexive conditions is -23 [-48, 2], which can be approximated as the  $Normal(-23,13^2)$.
  
<<dillonerepstimates,echo=FALSE>>=
## our data from one subject in one pair of conditions (difference in means):
xbar_au_d13rep<- -22
## 1 SD above and below mean
lower_au_d13rep <- -35
upper_au_d13rep <- -9

xbar_ru_d13rep<- -23
## 1 SD above and below mean
lower_ru_d13rep <- -36
upper_ru_d13rep <- -10
@

\subsubsection{Step 2: Compute posterior distributions of the latency factor using ABC rejection sampling}

Figure~\ref{fig:lfvalues} shows the posterior distributions of the latency factor parameter for ungrammatical agreement and reflexive conditions in \cite{DillonMishlerSloggett2013} and \cite{JaegerMertzenVanDykeVasishth2019}. The estimates for the \cite{DillonMishlerSloggett2013} data-set have wider uncertainty than those for \cite{JaegerMertzenVanDykeVasishth2019} because the uncertainty of the facilitatory interference effects in the data is relatively large.

<<loaddata,echo=FALSE>>=
load("models/au_lf_D13.Rda")
au_lf_D13<-lf_posterior[-which(lf_posterior==-1)]
load("models/ru_lf_D13.Rda")
ru_lf_D13<-lf_posterior[-which(lf_posterior==-1)]
load("models/au_lf_D13rep.Rda")
au_lf_D13rep<-lf_posterior[-which(lf_posterior==-1)]
load("models/ru_lf_D13rep.Rda")
ru_lf_D13rep<-lf_posterior[-which(lf_posterior==-1)]

condition<-c(rep("agreement",length(au_lf_D13)),
rep("reflexive",length(ru_lf_D13)),
rep("agreement",length(au_lf_D13rep)),
rep("reflexive",length(ru_lf_D13rep)))

expt<-c(rep("Dillon et al, 2013",length(au_lf_D13)),
rep("Dillon et al, 2013",length(ru_lf_D13)),
rep("Jäger et al, 2019",length(au_lf_D13rep)),
rep("Jäger et al, 2019",length(ru_lf_D13rep)))

lf<-c(au_lf_D13,ru_lf_D13,au_lf_D13rep,ru_lf_D13rep)

lf_data<-data.frame(expt=expt,condition=condition,lf=lf)

#round(with(lf_data,tapply(lf,IND=list(expt,condition),mean)),4)
@

\begin{figure}[!htbp]
\centering
<<plotlf,echo=FALSE,fig.width=7,fig.height=5>>=
ggplot(lf_data,aes(x=lf,y=..density..)) +
  xlab("latency factor")+
  geom_histogram(position="identity",binwidth=0.025,fill="gray")+
  geom_density()+
  facet_grid(.~expt+condition)+theme_bw()+magnifytext()
@
\caption{The posterior distributions of the latency factor parameters for agreement and reflexive conditions using the original Dillon et al., 2013 data (40 participants, 48 items) and our own Jäger et al., 2019 replication data (181 participants, 48 items).}\label{fig:lfvalues}
\end{figure}

\subsubsection{Step 3: Generate posterior predicted data}

Having estimated the posterior distributions of the latency factor for the two data-sets in the two conditions (agreement and reflexives), we can now  generate posterior predicted data from the model. We use the posterior distributions of the latency factor to generate the posterior predictive distribution of the interference effect in these experimental conditions.
These posterior predictive distributions are shown in Figure~\ref{fig:ppmeansvalues}. 

\begin{figure}[!htbp]
\centering
<<plotppdistrns,echo=FALSE,fig.width=7,fig.height=5>>=
load("models/au_predicted_meansD13.Rda")
load("models/ru_predicted_meansD13.Rda")
load("models/au_predicted_meansD13rep.Rda")
load("models/ru_predicted_meansD13rep.Rda")

ppmeans<-c(au_predicted_means,ru_predicted_means,au_predicted_means_rep,ru_predicted_means_rep)


condition<-c(rep("agreement",length(au_predicted_means)),
             rep("reflexive",length(ru_predicted_means)),
             rep("agreement",length(au_predicted_means_rep)),
             rep("reflexive",length(ru_predicted_means_rep)))

expt <- c(rep("Dillon et al., 2013",length(au_predicted_means)),
          rep("Dillon et al., 2013",length(ru_predicted_means)),
          rep("Jäger et al, 2019",length(au_predicted_means_rep)),
          rep("Jäger et al, 2019",length(ru_predicted_means_rep))
          )


ppmeans_df<-data.frame(expt,condition,ppmeans)

ggplot(ppmeans_df,aes(x=ppmeans,y=..density..)) +
  xlab("Predicted facilitatory interference effect (ms)")+
  geom_histogram(position="identity",binwidth=10,fill="gray")+
  geom_density()+
  facet_grid(.~expt+condition)+theme_bw()+magnifytext()
@
\caption{The posterior predictive distributions of the facilitatory interference in ungrammatical agreement and reflexive conditions, derived using the posterior distributions of the latency factor parameter.}\label{fig:ppmeansvalues}
\end{figure}

The ABC method can be generalized using other, more efficent sampling approaches (e.g., Metropolis-Hastings) to sample the posterior from more than one parameter. The method can be computationally expensive but the advantages afforded by taking parameter uncertainty into account in the predictions is very valuable.

In future work, we plan to use ABC for more extensive modelling of individual-level differences.

to-do add refs to Yadav et al work.

\newpage

\subsection{Modelling target match effects}

\subsection{Modelling target mismatch effects} \label{tgtmismatch}

\begin{figure}[!htbp]
\centering
<<ridgeplot,echo=FALSE,fig.width=9,fig.height=10>>=
## precomputed above:
load("data/data_model.Rda")
load("data/data_model_dillonrep.Rda")
modelquantiles<-quantile(subset(data_model,expt=="model")$posterior,prob=c(0.025,0.975))

expt_dillonrep<-subset(data_model_dillonrep,expt==11)
#head(expt_dillonrep)
expt_dillonrep$expt<-factor("repl (n=181)")
data_model11studies<-rbind(data_model,expt_dillonrep)

scl<-1
ggplot(data_model11studies, 
       aes(x = posterior, y = factor(expt),height = ..density..
           )) +
  geom_density_ridges(scale = scl
                      ,stat = "density",
                      rel_min_height = 0.01) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  #scale_fill_brewer(palette = "PuBuGn") +
  theme_ridges() + theme(legend.position = "none")+
  xlab("agreement attraction effect")+
  ylab("expt")+
  geom_vline(xintercept=0,col="gray")+
  ## meta-analysis based on frequentist estimates
  geom_vline(xintercept=-9)+
  geom_vline(xintercept=-36)+
    magnifytext(sze=14)
@
\caption{Ridgeplots showing the distributions of the effect of interest from 10 published reading experiments (eyetracking and self-paced reading) on agreement attraction; the studies are ordered by the mean of the posterior. Also shown is the model's  probability distribution of the predicted effect, computed using a large-sample (n=181) data-set investigating agreement attraction; 
for reference, we also show the posterior distribution of the agreement attraction effect in the large-sample study. The black vertical lines mark the 95\% confidence interval of a meta-analysis estimate computed using all published reading studies that were available in 2016 that  investigated agreement attraction. The figure is available from  https://doi.org/10.6084/m9.figshare.10281911.v1; it is re-used here under a CC-BY4.0 license.} \label{fig:agrmtattrn}
\end{figure}
%to-do: rewrite above caption

\section{Modelling subject-level variability}

Reflexives TRT from Dillon 

Model ind diffs in agrmt attrn data (new: Serine)

Model ind diffs in grammatical agrmt attrn + Cunnings and Sturt plausible + Dani SBI data, ind diffs

<<loaddillonrepdata,echo=FALSE>>=
dillonrep<-read.table("data/Dillon_replication_data.txt",header=TRUE)
@

<<dillonrep_inddiff,echo=FALSE,message=FALSE,warning=FALSE,results='asis',eval=FALSE>>=
#head(dillonrep)

priors <- c(set_prior("normal(0, 10)", 
                      class = "Intercept"),
            set_prior("normal(0, 1)", class = "b"),
            set_prior("normal(0, 1)", class = "sd"),
            set_prior("lkj(2)", class = "cor"))

M1_tft_dillonrep<-brm(TFT~1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr+(1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|subj)+(1+Dep+Gram+DepxGram+Int_gram_refl+Int_gram_agr+Int_ungram_refl+Int_ungram_agr|item),data=subset(dillonrep,TFT>0),
                 family=lognormal(),
                 prior=priors,
                 warmup=1000,
                 iter=2000,
                 #save_all_pars=TRUE,
                control = list(adapt_delta = 0.99,
                               max_treedepth=15))
save(M1_tft_dillonrep,file="data/M1_tft_dillonrep.Rda")
@

<<dillonreploadcompiledmodel,echo=FALSE>>=
load("data/M1_tft_dillonrep.Rda")
@

<<dillonrepinddiffplot,echo=FALSE>>=
post<-posterior_samples(M1_tft_dillonrep)
## extract estimates:
alpha<-post$b_Intercept
beta_ru<-post$b_Int_ungram_refl
beta_au<-post$b_Int_ungram_agr

## mean effect ungram reflexives:
mean_ru<-exp(alpha+beta_ru*0.5)-exp(alpha-beta_ru*0.5)
mean_au<-exp(alpha+beta_au*0.5)-exp(alpha-beta_au*0.5)
mean_ru_quantile<-quantile(mean_ru,prob=c(0.025,0.975))
mean_au_quantile<-quantile(mean_au,prob=c(0.025,0.975))

subj_re<-posterior_samples(M1_tft_dillonrep,"^r_subj")

subjlist<- unique(dillonrep$subj)
nsubj<-length(subjlist)

subjdiff_ru<-subjdiff_au<-matrix(rep(NA,nsubj*4000),nrow=nsubj)

for(i in 1:nsubj){
subjdiff_ru[i,] <- exp(alpha + subj_re[,i]  + (beta_ru+subj_re[,i+nsubj*6])*.5) - exp(alpha + subj_re[,i] - (beta_ru+subj_re[,i+nsubj*6])*0.5)
}

subjdiff_ru<-t(subjdiff_ru)

subjdiff_ru<-as.data.frame(subjdiff_ru)
#colnames(subjdiff_ru)<-paste("s",subjlist,sep="")
mns_ru <- colMeans(subjdiff_ru)
subjdiff_ru<-subjdiff_ru[,order(mns_ru)]

ACTRpredictionmatch<-quantile(match_reduced$Effect,prob=c(0.025,0.5,0.975))

ACTRprediction<-quantile(mismatch_reduced$Effect,prob=c(0.025,0.5,0.975))

color_scheme_set("gray")
plot_ru<-mcmc_intervals(subjdiff_ru)+
  geom_vline(xintercept=0)+#xlim(-90,25)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("participant")+
  theme(axis.title.y = element_text(angle = 90))+ggtitle("Ungrammatical reflexives")+
  #annotate("segment", x=ACTRprediction[1], xend=ACTRprediction[3], y=185, yend=185,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  #annotate("text", x=-40, y=184, label="Predicted range",family="serif",fontface="bold", colour="darkred", size=5)+
  #annotate("segment", x=mean_ru_quantile[1], xend=mean_ru_quantile[2], y=-2, yend=-2,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  #annotate("text", x=-25, y=0, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)+
  geom_vline(xintercept=ACTRprediction[1],size=1,col="white")+
  geom_vline(xintercept=ACTRprediction[3],size=1,col="white")

## ungrammatical agreement:
for(i in 1:nsubj){
subjdiff_au[i,] <- exp(alpha + subj_re[,i]  + (beta_au+subj_re[,i+nsubj*7])*.5) - exp(alpha + subj_re[,i] - (beta_au+subj_re[,i+nsubj*7])*0.5)
}


subjdiff_au<-t(subjdiff_au)

subjdiff_au<-as.data.frame(subjdiff_au)
colnames(subjdiff_au)<-paste("s",subjlist,sep="")
mns_au <- colMeans(subjdiff_au)
subjdiff_au<-subjdiff_au[,order(mns_au)]

plot_au<-mcmc_intervals(subjdiff_au)+
  geom_vline(xintercept=0)+#xlim(-90,25)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("")+
  theme(axis.title.y = element_text(angle = 0))+ggtitle("Ungrammatical agreement")+
  #annotate("segment", x=ACTRprediction[1], xend=ACTRprediction[3], y=185, yend=185,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  #annotate("text", x=-40, y=188, label="Predicted range",family="serif",fontface="bold", colour="darkred", size=5)+
  #annotate("segment", x=mean_au_quantile[1], xend=mean_au_quantile[2], y=-2, yend=-2,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  #annotate("text", x=-25, y=-3.5, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)
  geom_vline(xintercept=ACTRprediction[1],size=1,col="white")+
  geom_vline(xintercept=ACTRprediction[3],size=1,col="white")
#multiplot(plot_ru,plot_au,cols=2)
@

\begin{figure}[!htbp]
\centering
\includegraphics[height=18cm,width=15cm]{figures/dillonrepinddiffplots}
\caption{Individual-level facilitatory interference effects in the Dillon replication study. Show are individual participant-level estimates of the interference effect (median and 90\% credible intervals). The white vertical lines show the bounds of the predicted range of effects according to the activation-based model.}\label{fig:dillonrepinddiffplots}
\end{figure}

<<cunningssturt2018preprocessdata,echo=FALSE>>=
# Analysis for Experiment 1
# Import rawdata
exp1.rawdata <- read.table("data/CunningsE1.txt")

# Rename columns
colnames(exp1.rawdata) = c("subject", "item", "region", "measure", "condition", "rt")

# Rename regions
exp1.rawdata$region <- ifelse(exp1.rawdata$region == 2, "verb", "spillover")

# Rename conditions from 1-4 to a-d (based on example 6a-d in paper)
exp1.rawdata$condition <- ifelse(exp1.rawdata$condition == 1, "a", ifelse(exp1.rawdata$condition == 2, "b", ifelse(exp1.rawdata$condition == 3, "c", "d")))

# Create column with 0s removed
exp1.rawdata$nozero <- ifelse(exp1.rawdata$rt == 0, NA, exp1.rawdata$rt)

# Create 2-way factors from condition column
exp1.rawdata$target <- ifelse(exp1.rawdata$condition == "a" | exp1.rawdata$condition == "b", "plaus", "implaus")
exp1.rawdata$distractor <- ifelse(exp1.rawdata$condition == "a" | exp1.rawdata$condition == "c", "plaus", "implaus")

# Create columns with sum coded factors
exp1.rawdata$s_target <- ifelse(exp1.rawdata$target == "plaus", -1, 1)
exp1.rawdata$s_distractor <- ifelse(exp1.rawdata$distractor == "plaus", -1, 1)
exp1.rawdata$s_region <- ifelse(exp1.rawdata$region == "verb", -1, 1)

exp1.tt<-subset(exp1.rawdata,measure=="tt")
exp1.tt$region<-factor(exp1.tt$region)
exp1.tt.crit<-subset(exp1.tt,region=="verb")

#head(exp1.tt.crit)
## nested contrasts:
## plausible target, +1 plaus distr, -1 implaus distractor
## Positive coef means slowdown
exp1.tt.crit$plaus_int<-ifelse(exp1.tt.crit$target=="plaus" & exp1.tt.crit$distractor=="plaus",1,ifelse(exp1.tt.crit$target=="plaus" & exp1.tt.crit$distractor=="implaus",-1,0))
exp1.tt.crit$implaus_int<-ifelse(exp1.tt.crit$target=="implaus" & exp1.tt.crit$distractor=="plaus",1,ifelse(exp1.tt.crit$target=="implaus" & exp1.tt.crit$distractor=="implaus",-1,0))
exp1.tt.crit$MEplaus<-ifelse(exp1.tt.crit$target=="plaus",1,-1)

#xtabs(~condition+plaus_int,exp1.tt.crit)
#xtabs(~condition+implaus_int,exp1.tt.crit)
#xtabs(~condition+MEplaus,exp1.tt.crit)

# Analysis for Experiment 2
# Import rawdata
exp2.rawdata <- read.table("data/CunningsE2.txt")

# Rename columns
colnames(exp2.rawdata) <- c("subject", "item", "region", "measure", "condition", "rt")

# Rename regions
exp2.rawdata$region <- ifelse(exp2.rawdata$region == 2, "verb", "spillover")

# Rename conditions from 1-4 to a-d (based on example 9a-d in paper)
exp2.rawdata$condition <- ifelse(exp2.rawdata$condition == 1, "a", ifelse(exp2.rawdata$condition == 2, "b", ifelse(exp2.rawdata$condition == 3, "c", "d")))

# Create column with 0s removed
exp2.rawdata$nozero <- ifelse(exp2.rawdata$rt == 0, NA, exp2.rawdata$rt)


# Create 2-way factors from condition column
exp2.rawdata$target <- ifelse(exp2.rawdata$condition == "a" | exp2.rawdata$condition == "b", "plaus", "implaus")
exp2.rawdata$distractor <- ifelse(exp2.rawdata$condition == "a" | exp2.rawdata$condition == "c", "plaus", "implaus")

# Create columns with sum coded factors
exp2.rawdata$s_target <- ifelse(exp2.rawdata$target == "plaus", -1, 1)
exp2.rawdata$s_distractor <- ifelse(exp2.rawdata$distractor == "plaus", -1, 1)
exp2.rawdata$s_region <- ifelse(exp2.rawdata$region == "verb", -1, 1)

# Reorder some columns
exp2.rawdata <- exp2.rawdata[c(1, 2, 3, 4, 5, 8, 9, 12, 10, 11, 6, 7)]

# Create separate dataframe for TFT
exp2.tt = exp2.rawdata[exp2.rawdata$measure == "tt",]
exp2.tt$region<-factor(exp2.tt$region)
exp2.tt.crit<-subset(exp2.tt,region=="verb")

#head(exp2.tt.crit)
## nested contrasts:
## plausible target, +1 plaus distr, -1 implaus distractor
## Positive coef means slowdown
exp2.tt.crit$plaus_int<-ifelse(exp2.tt.crit$target=="plaus" & exp2.tt.crit$distractor=="plaus",1,ifelse(exp2.tt.crit$target=="plaus" & exp2.tt.crit$distractor=="implaus",-1,0))
exp2.tt.crit$implaus_int<-ifelse(exp2.tt.crit$target=="implaus" & exp2.tt.crit$distractor=="plaus",1,ifelse(exp2.tt.crit$target=="implaus" & exp2.tt.crit$distractor=="implaus",-1,0))
exp2.tt.crit$MEplaus<-ifelse(exp2.tt.crit$target=="plaus",1,-1)
@

<<cunningssturt2018model,echo=FALSE,eval=FALSE>>=
M1_tft_CS18<-brm(nozero~1+plaus_int + implaus_int + MEplaus +  
                   (1+plaus_int + implaus_int + MEplaus|subject)+
                   (1+plaus_int + implaus_int + MEplaus|item),
                 data=exp1.tt.crit,
                 family=lognormal(),
                 prior=priors,
                 warmup=1000,
                 iter=2000,
                 #save_all_pars=TRUE,
                control = list(adapt_delta = 0.99,
                               max_treedepth=15))

#summary(M1_tft_CS18)
save(M1_tft_CS18,file="data/M1_tft_CS18.Rda")

M2_tft_CS18<-brm(nozero~1+plaus_int + implaus_int + MEplaus +  
                   (1+plaus_int + implaus_int + MEplaus|subject)+
                   (1+plaus_int + implaus_int + MEplaus|item),
                 data=exp2.tt.crit,
                 family=lognormal(),
                 prior=priors,
                 warmup=1000,
                 iter=2000,
                 #save_all_pars=TRUE,
                control = list(adapt_delta = 0.99,
                               max_treedepth=15))

save(M2_tft_CS18,file="data/M2_tft_CS18.Rda")

@

<<CS18E1inddiffplot,echo=FALSE>>=
load("data/M1_tft_CS18.Rda")
post<-posterior_samples(M1_tft_CS18)
## extract estimates:
alpha<-post$b_Intercept
beta_pl<-post$b_plaus_int
beta_impl<-post$b_implaus_int

## mean int effect in plausible target:
meanplaus<-exp(alpha+beta_pl)-exp(alpha-beta_pl)
meanplaus_quantile<-quantile(meanplaus,prob=c(0.025,0.975))

## mean int effect in implausible target:
meanimplaus<-exp(alpha+beta_impl)-exp(alpha-beta_impl)
meanimplaus_quantile<-quantile(meanimplaus,prob=c(0.025,0.975))

subj_re<-posterior_samples(M1_tft_CS18,"^r_subj")

subjlist<- unique(exp1.tt.crit$subject)
nsubj<-length(subjlist)

subjdiff_pl<-subjdiff_impl<-matrix(rep(NA,nsubj*4000),nrow=nsubj)

for(i in 1:nsubj){
subjdiff_pl[i,] <- exp(alpha + subj_re[,i]  + (beta_pl+subj_re[,i+nsubj])) - exp(alpha + subj_re[,i] - (beta_pl+subj_re[,i+nsubj]))
subjdiff_impl[i,] <- exp(alpha + subj_re[,i]  + (beta_impl+subj_re[,i+2*nsubj])) - exp(alpha + subj_re[,i] - (beta_impl+subj_re[,i+2*nsubj]))
}

## plausible target plot:
subjdiff_pl<-t(subjdiff_pl)
subjdiff_pl<-as.data.frame(subjdiff_pl)
colnames(subjdiff_pl)<-factor(subjlist)
mns_pl <- colMeans(subjdiff_pl)
subjdiff_pl<-subjdiff_pl[,order(mns_pl)]

plot_plE1<-mcmc_areas(subjdiff_pl)+
  geom_vline(xintercept=0)+xlim(-300,200)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  #theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("E1: Plausible target")+
  annotate("segment", x=ACTRpredictionmatch[1], xend=ACTRpredictionmatch[3], y=49, yend=49,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=35, y=50, label="Predicted range",family="serif",
                 fontface="bold", colour="darkred", size=5)+
  annotate("segment", x=meanplaus_quantile[1], xend=meanplaus_quantile[2], y=0, yend=0,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-7, y=-1, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)

## implausible target plot:
subjdiff_impl<-t(subjdiff_impl)
subjdiff_impl<-as.data.frame(subjdiff_impl)
colnames(subjdiff_impl)<-factor(subjlist)
mns_impl <- colMeans(subjdiff_impl)
subjdiff_impl<-subjdiff_impl[,order(mns_impl)]

plot_implE1<-mcmc_areas(subjdiff_impl)+
  geom_vline(xintercept=0)+xlim(-300,200)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  #theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 90))+
  ggtitle("Expt1: Implausible target")+
  annotate("segment", x=ACTRprediction[1], xend=ACTRprediction[3], y=49, yend=49,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-20, y=50, label="Predicted range",family="serif",
                 fontface="bold", colour="darkred", size=5)+
  annotate("segment", x=meanimplaus_quantile[1], xend=meanimplaus_quantile[2], y=0, yend=0,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-10, y=-1, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)
#multiplot(plot_plE1,plot_implE1,cols=2)
@

\begin{figure}[!htbp]
\centering
\includegraphics[height=18cm,width=15cm]{figures/E1CS18inddiffplots}
\caption{Individual-level interference effects in the Cunnings and Sturt 2018 study, Experiment 1.}\label{fig:CS18E1inddiffplots}
\end{figure}

<<CS18E2inddiffplot,echo=FALSE>>=
load("data/M2_tft_CS18.Rda")
post<-posterior_samples(M2_tft_CS18)
## extract estimates:
alpha<-post$b_Intercept
beta_pl<-post$b_plaus_int
beta_impl<-post$b_implaus_int

## mean int effect in plausible target:
meanplaus<-exp(alpha+beta_pl)-exp(alpha-beta_pl)
meanplaus_quantile<-quantile(meanplaus,prob=c(0.025,0.975))

## mean int effect in implausible target:
meanimplaus<-exp(alpha+beta_impl)-exp(alpha-beta_impl)
meanimplaus_quantile<-quantile(meanimplaus,prob=c(0.025,0.975))

subj_re<-posterior_samples(M2_tft_CS18,"^r_subj")

subjlist<- unique(exp2.tt.crit$subject)
nsubj<-length(subjlist)

subjdiff_pl<-subjdiff_impl<-matrix(rep(NA,nsubj*4000),nrow=nsubj)

for(i in 1:nsubj){
subjdiff_pl[i,] <- exp(alpha + subj_re[,i]  + (beta_pl+subj_re[,i+nsubj])) - exp(alpha + subj_re[,i] - (beta_pl+subj_re[,i+nsubj]))
subjdiff_impl[i,] <- exp(alpha + subj_re[,i]  + (beta_impl+subj_re[,i+2*nsubj])) - exp(alpha + subj_re[,i] - (beta_impl+subj_re[,i+2*nsubj]))
}

## plausible target plot:
subjdiff_pl<-t(subjdiff_pl)
subjdiff_pl<-as.data.frame(subjdiff_pl)
colnames(subjdiff_pl)<-paste("s",subjlist,sep="")
mns_pl <- colMeans(subjdiff_pl)
subjdiff_pl<-subjdiff_pl[,order(mns_pl)]

plot_plE2<-mcmc_areas(subjdiff_pl)+
  geom_vline(xintercept=0)+xlim(-400,250)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  #theme(axis.text.y = element_blank())+
  ylab("subject")+
  theme(axis.title.y = element_text(angle = 0))+
  ggtitle("Expt 2: Plausible target")+
  annotate("segment", x=ACTRpredictionmatch[1], xend=ACTRpredictionmatch[3], y=49, yend=49,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=35, y=50, label="Predicted range",family="serif",
                 fontface="bold", colour="darkred", size=5)+
  annotate("segment", x=meanplaus_quantile[1], xend=meanplaus_quantile[2], y=0, yend=0,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-7, y=-1, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)

## implausible target plot:
subjdiff_impl<-t(subjdiff_impl)
subjdiff_impl<-as.data.frame(subjdiff_impl)
colnames(subjdiff_impl)<-paste("s",subjlist,sep="")
mns_impl <- colMeans(subjdiff_impl)
subjdiff_impl<-subjdiff_impl[,order(mns_impl)]

plot_implE2<-mcmc_areas(subjdiff_impl)+
  geom_vline(xintercept=0)+xlim(-400,250)+
  xlab("Interference effect (ms)")+
  magnifytext(sze=16)+
  theme(axis.text.y = element_blank())+
  ylab("subject")+
  #theme(axis.title.y = element_text(angle = 0))+
  ggtitle("Expt2: Implausible target")+
  annotate("segment", x=ACTRprediction[1], xend=ACTRprediction[3], y=49, yend=49,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-30, y=50, label="Predicted range",family="serif",
                 fontface="bold", colour="darkred", size=5)+
  annotate("segment", x=meanimplaus_quantile[1], xend=meanimplaus_quantile[2], y=0, yend=0,arrow=arrow(ends="both", angle=90, length=unit(.2,"cm")))+
  annotate("text", x=-20, y=-1, label="Mean effect",family="serif",fontface="bold", colour="darkred", size=5)
#multiplot(plot_plE2,plot_implE2,cols=2)
@





